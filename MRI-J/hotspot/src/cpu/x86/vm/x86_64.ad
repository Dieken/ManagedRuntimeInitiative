//
// Copyright 2003-2007 Sun Microsystems, Inc.  All Rights Reserved.
// DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
//
// This code is free software; you can redistribute it and/or modify it
// under the terms of the GNU General Public License version 2 only, as
// published by the Free Software Foundation.
//
// This code is distributed in the hope that it will be useful, but WITHOUT
// ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
// version 2 for more details (a copy is included in the LICENSE file that
// accompanied this code).
//
// You should have received a copy of the GNU General Public License version
// 2 along with this work; if not, write to the Free Software Foundation,
// Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
//
// Please contact Sun Microsystems, Inc., 4150 Network Circle, Santa Clara,
// CA 95054 USA or visit www.sun.com if you need additional information or
// have any questions.
//  
//


// This file is a derivative work resulting from (and including) modifications
// made by Azul Systems, Inc.  The date of such changes is 2010.
// Copyright 2010 Azul Systems, Inc.  All Rights Reserved.
//
// Please contact Azul Systems, Inc., 1600 Plymouth Street, Mountain View, 
// CA 94043 USA, or visit www.azulsystems.com if you need additional information 
// or have any questions.

// AMD64 Architecture Description File

source_hpp %{
#include "addnode.hpp"
#include "assembler_pd.hpp"
#include "block.hpp"
#include "javaClasses.hpp"
#include "machnode.hpp"
#include "macro.hpp"
#include "memnode.hpp"
#include "regalloc.hpp"
#include "rootnode.hpp"
#include "sharedRuntime.hpp"
#include "subnode.hpp"
#include "frame_pd.inline.hpp"
#include "register_pd.inline.hpp"
%}

//----------REGISTER DEFINITION BLOCK------------------------------------------
// This information is used by the matcher and the register allocator to
// describe individual registers and classes of registers within the target
// archtecture.

register %{
//----------Architecture Description Register Definitions----------------------
// General Registers
// "reg_def"  name ( register save type, C convention save type,
//                   ideal register type, encoding );
// Register Save Types:
//
// NS  = No-Save:       The register allocator assumes that these registers
//                      can be used without saving upon entry to the method, &
//                      that they do not need to be saved at call sites.
//
// SOC = Save-On-Call:  The register allocator assumes that these registers
//                      can be used without saving upon entry to the method,
//                      but that they must be saved at call sites.
//
// SOE = Save-On-Entry: The register allocator assumes that these registers
//                      must be saved before using them upon entry to the
//                      method, but they do not need to be saved at call
//                      sites.
//
// AS  = Always-Save:   The register allocator assumes that these registers
//                      must be saved before using them upon entry to the
//                      method, & that they must be saved at call sites.
//
// Ideal Register Type is used to determine how to save & restore a
// register.  Op_RegI will get spilled with LoadI/StoreI, Op_RegP will get
// spilled with LoadP/StoreP.  If the register supports both, use Op_RegI.
//
// The encoding number is the actual bit-pattern placed into the opcodes.

// General Registers
reg_def RAX(SOC,Op_RegL,0);
reg_def RCX(SOC,Op_RegL,1);
reg_def RDX(SOC,Op_RegL,2);
reg_def RBX(SOE,Op_RegL,3);
reg_def RSP(NS,Op_RegL,4);
reg_def RBP(SOE,Op_RegL,5);
reg_def RSI(SOC,Op_RegL,6);
reg_def RDI(SOC,Op_RegL,7);
reg_def R08(SOC,Op_RegL,8);
reg_def R09(SOC,Op_RegL,9);
reg_def R10(SOC,Op_RegL,10);
reg_def R11(SOC,Op_RegL,11);
reg_def R12(SOE,Op_RegL,12);
reg_def R13(SOE,Op_RegL,13);
reg_def R14(SOE,Op_RegL,14);
reg_def R15(SOE,Op_RegL,15);

// Floating Point Registers

// XMM registers.  128-bit registers or 4 words each, labeled (a)-d.
// Word a in each register holds a Float, words ab hold a Double.  We
// currently do not use the SIMD capabilities, so registers cd are
// unused at the moment.
// Linux ABI:   No register preserved across function calls
//              XMM0-XMM7 might hold parameters
reg_def XMM00(SOC, Op_RegD, 16);
reg_def XMM01(SOC, Op_RegD, 17);
reg_def XMM02(SOC, Op_RegD, 18);
reg_def XMM03(SOC, Op_RegD, 19);
reg_def XMM04(SOC, Op_RegD, 20);
reg_def XMM05(SOC, Op_RegD, 21);
reg_def XMM06(SOC, Op_RegD, 22);
reg_def XMM07(SOC, Op_RegD, 23);
reg_def XMM08(SOC, Op_RegD, 24);
reg_def XMM09(SOC, Op_RegD, 25);
reg_def XMM10(SOC, Op_RegD, 26);
reg_def XMM11(SOC, Op_RegD, 27);
reg_def XMM12(SOC, Op_RegD, 28);
reg_def XMM13(SOC, Op_RegD, 29);
reg_def XMM14(SOC, Op_RegD, 30);
reg_def XMM15(SOC, Op_RegD, 31);

reg_def RFLAGS(SOC, Op_RegFlags, 32);

alloc_class chunk0(RAX,
                   RCX,
                   RDX,
                   RBX,
                   RSP,
                   RBP,
                   RSI,
                   RDI,
                   R08,
                   R09,
                   R10,
                   R11,
                   R12,
                   R13,
                   R14,
                   R15,
// probably use 8-15 first on Linux
                   XMM00,  
                   XMM01,  
                   XMM02,  
                   XMM03,  
                   XMM04,  
                   XMM05,  
                   XMM06,  
                   XMM07,  
                   XMM08,  
                   XMM09,  
                   XMM10, 
                   XMM11, 
                   XMM12, 
                   XMM13, 
                   XMM14, 
                   XMM15);

alloc_class chunk1(RFLAGS);


//----------Architecture Description Register Classes--------------------------
// Several register classes are automatically defined based upon information in
// this architecture description.
// 1) reg_class inline_cache_reg           ( /* as def'd in frame section */ )
// 3) reg_class stack_slots( /* one chunk of stack-based "registers" */ )
//

// Class for all pointer registers (including RSP)
reg_class any_reg(RAX,
                  RDX,
                  RBP,
                  RDI,
                  RSI,
                  RCX,
                  RBX,
                  RSP,
                  R08,
                  R09,
                  R10,
                  R11,
                  R12,
                  R13,
                  R14,
                  R15);

// Class for all pointer registers except RSP
reg_class ptr_reg(RAX,
                  RDX,
                  RBP,
                  RDI,
                  RSI,
                  RCX,
                  RBX,
                  R08,
                  R09,
                  R10,
                  R11,
                  R12,
                  R13,
                  R14,
                  R15);

// Class for all pointer registers except RAX and RSP
reg_class ptr_no_rax_reg(RDX,
RBP,
RDI,
RSI,
RCX,
RBX,
R08
R09
R10,
R11,
R12,
R13,
R14,
R15);

// Singleton class for RAX pointer register
reg_class ptr_rax_reg(RAX);

// Singleton class for RBX pointer register
reg_class ptr_rbx_reg(RBX);
reg_class ptr_rcx_reg(RCX);

// Singleton class for RSI pointer register
reg_class ptr_rsi_reg(RSI);

// Singleton class for RDI pointer register
reg_class ptr_rdi_reg(RDI);

// Singleton class for stack pointer
reg_class ptr_rsp_reg(RSP);

reg_class ptr_r10_reg(R10);

// Class for all long registers (except RSP)
reg_class long_reg(RAX,
                   RDX,
                   RBP,
                   RDI,
                   RSI,
                   RCX,
                   RBX,
                   R08,
                   R09,
                   R10,
                   R11,
                   R12,
                   R13,
                   R14,
                   R15);

// Class for all long registers except RAX, RDX (and RSP)
reg_class long_no_rax_rdx_reg(RBP,
                              RDI,
                              RSI,
                              RCX,
                              RBX,
                              R08,
                              R09,
                              R10,
                              R11,
                              R12,
                              R13,
                              R14,
                              R15);

// Class for all long registers except RCX (and RSP)
reg_class long_no_rcx_reg(RBP,
                          RDI,
                          RSI,
                          RAX,
                          RDX,
                          RBX,
                          R08,
                          R09,
                          R10,
                          R11,
                          R12,
                          R13,
                          R14,
                          R15);

// Class for all long registers except RAX (and RSP)
reg_class long_no_rax_reg(RBP,
                          RDX,
                          RDI,
                          RSI,
                          RCX,
                          RBX,
                          R08,
                          R09,
                          R10,
                          R11,
                          R12,
                          R13,
                          R14,
                          R15);
 
// Singleton class for RAX long register
reg_class long_rax_reg(RAX);

// Singleton class for RCX long register
reg_class long_rcx_reg(RCX);

// Singleton class for RDX long register
reg_class long_rdx_reg(RDX);

// Class for all int registers (except RSP)
reg_class int_reg(RAX,
                  RDX,
                  RBP,
                  RDI,
                  RSI,
                  RCX,
                  RBX,
                  R08,
                  R09,
                  R10,
                  R11,
                  R12,
                  R13,
R14,
                  R15);

// Class for all int registers except RCX (and RSP)
reg_class int_no_rcx_reg(RAX,
                         RDX,
                         RBP,
                         RDI,
                         RSI,
                         RBX,
                         R08,
                         R09,
                         R10,
                         R11,
                         R12,
                         R13,
R14,
                         R15);

// Class for all int registers except RAX, RDX (and RSP)
reg_class int_no_rax_rdx_reg(RBP,
                             RDI,
                             RSI,
                             RCX,
                             RBX,
                             R08,
                             R09,
                             R10,
                             R11,
                             R12,
                             R13,
R14,
                             R15);

// Singleton class for RAX int register
reg_class int_rax_reg(RAX);

// Singleton class for RBX int register
reg_class int_rbx_reg(RBX);

// Singleton class for RCX int register
reg_class int_rcx_reg(RCX);

// Singleton class for RCX int register
reg_class int_rdx_reg(RDX);

// Singleton class for RCX int register
reg_class int_rdi_reg(RDI);
reg_class int_rsi_reg(RSI);
reg_class int_r09_reg(R09);
reg_class  fp_f15_reg(XMM15);

// Singleton class for instruction pointer
// reg_class ip_reg(RIP);

// Singleton class for condition codes
reg_class int_flags(RFLAGS);

// Class for all float registers
reg_class float_reg(XMM00,
                    XMM01,
                    XMM02,
                    XMM03,
                    XMM04,
                    XMM05,
                    XMM06,
                    XMM07,
                    XMM08,
                    XMM09,
                    XMM10,
                    XMM11,
                    XMM12,
                    XMM13,
                    XMM14,
                    XMM15);

// Class for all double registers
reg_class double_reg(XMM00,
                     XMM01,
                     XMM02,
                     XMM03,
                     XMM04,
                     XMM05,
                     XMM06,
                     XMM07,
                     XMM08,
                     XMM09,
                     XMM10,
                     XMM11,
                     XMM12,
                     XMM13,
                     XMM14,
                     XMM15);

// Kill all registers 'gen_prim_arraycopy' kills, which calls the C 
// function memmove (memcopy) and thus kills the standard caller-save set.
 reg_class arraycopy_prim_kills( RAX, RDX, RSI, RDI, RFLAGS, XMM00, XMM01, XMM02, XMM03, XMM04, XMM05, XMM06, XMM07, XMM08, XMM09, XMM10, XMM11, XMM12, XMM13, XMM14, XMM15 );
 reg_class arraycopy_oop_kills( RAX, RCX, RDX, RSI, RDI, R08, R09, R10, R11, RFLAGS, XMM00, XMM01, XMM02, XMM03, XMM04, XMM05, XMM06, XMM07, XMM08, XMM09, XMM10, XMM11, XMM12, XMM13, XMM14, XMM15 );

 // MachLVBs kill flags at least
reg_class machlvb_kills(RFLAGS);

%}

//----------SOURCE BLOCK-------------------------------------------------------
// This is a block of C++ code which provides values, functions, and
// definitions necessary in the rest of the architecture description
source %{

#define __ ra_->C->_masm.

// EMIT_RM()
void emit_rm(int f1,int f2,int f3)
{
  unsigned char c = (unsigned char) ((f1 << 6) | (f2 << 3) | f3);
  Unimplemented();
  //*(cbuf.code_end()) = c;
  //cbuf.set_code_end(cbuf.code_end() + 1);
}

// EMIT_CC()
void emit_cc(int f1,int f2)
{
  unsigned char c = (unsigned char) (f1 | f2);
  Unimplemented();
  //*(cbuf.code_end()) = c;
  //cbuf.set_code_end(cbuf.code_end() + 1);
}

// EMIT_OPCODE()
void emit_opcode(int code)
{
  Unimplemented();
  //*(cbuf.code_end()) = (unsigned char) code;
  //cbuf.set_code_end(cbuf.code_end() + 1);
}

// EMIT_OPCODE() w/ relocation information
void emit_opcode(int code,int offset,int format)
{
emit_opcode(code);
}

// EMIT_D8()
void emit_d8(int d8)
{
  Unimplemented();
  //*(cbuf.code_end()) = (unsigned char) d8;
  //cbuf.set_code_end(cbuf.code_end() + 1);
}

// EMIT_D16()
void emit_d16(int d16)
{
  Unimplemented();
  //*((short *)(cbuf.code_end())) = d16;
  //cbuf.set_code_end(cbuf.code_end() + 2);
}

// EMIT_D32()
void emit_d32(int d32)
{
  Unimplemented();
  //*((int *)(cbuf.code_end())) = d32;
  //cbuf.set_code_end(cbuf.code_end() + 4);
}

// EMIT_D64()
void emit_d64(int64_t d64)
{
  Unimplemented();
  //*((int64_t*) (cbuf.code_end())) = d64;
  //cbuf.set_code_end(cbuf.code_end() + 8);
}

// Access stack slot for load or store
void store_to_stackslot(int opcode,int rm_field,int disp)
{
emit_opcode(opcode);//(e.g., FILD   [RSP+src])
  if (-0x80 <= disp && disp < 0x80) {
emit_rm(0x01,rm_field,RSP_enc);//R/M byte
emit_rm(0x00,RSP_enc,RSP_enc);//SIB byte
emit_d8(disp);//Displacement  // R/M byte
  } else {
emit_rm(0x02,rm_field,RSP_enc);//R/M byte
emit_rm(0x00,RSP_enc,RSP_enc);//SIB byte
emit_d32(disp);//Displacement // R/M byte
  }
}

   // rRegI ereg, memory mem) %{    // emit_reg_mem
void encode_RegMem(int reg,
                   int base, int index, int scale, int disp, bool disp_is_oop)
{
  Unimplemented();
}

void encode_copy(int dstenc, int srcenc)
{
  Unimplemented();
}

void encode_CopyXD( int dst_encoding, int src_encoding ) {
  Unimplemented();
}


//=============================================================================
void MachPrologNode::emit(PhaseRegAlloc*ra_)const{

  // WARNING: Initial instruction MUST be 5 bytes or longer so that
  // NativeJump::patch_verified_entry will be able to patch out the entry
  // code safely. The fldcw is ok at 6 bytes, the push to verify stack
  // depth is ok at 5 bytes, the frame allocation can be either 3 or
  // 6 bytes. So if we don't do the fldcw or the push then we must
  // use the 6 byte frame allocation even if we have no frame. :-(
  // If method sets FPU control word do it now  
  int framebytes = ra_->_framesize<<3;
  __ sub8i(RSP,framebytes-8/*exclude return adr*/);
}

//=============================================================================
void MachEpilogNode::emit(PhaseRegAlloc*ra_)const{
int framebytes=ra_->_framesize<<3;
  __ add8i(RSP,framebytes-8/*exclude return adr*/);
}

const Pipeline* MachEpilogNode::pipeline() const {
  return MachNode::pipeline_class();
}

//=============================================================================
void MachSpillCopyNode::implementation(PhaseRegAlloc*ra_)const{
  // Get registers to move
OptoReg::Name src=ra_->get_reg(in(1));
OptoReg::Name dst=ra_->get_reg(this);
  
  // Self copy, no move
  if( src == dst ) return;

  const int doff = OptoReg::is_stack(dst) ? ra_->reg2offset(dst) : -99;

if(OptoReg::is_stack(src)){//<- mem
    const int soff = ra_->reg2offset(src);
if(OptoReg::is_stack(dst)){//mem <- mem, always 64 bits
      __ push(RSP,soff);
      __ pop (RSP,doff);
    } else {
      VReg::VR dvreg = OptoReg::as_VReg(dst);
      if( is_gpr(dvreg) ) {        // gpr <- mem
        if( _type->isa_int() ) __ ldz4(reg2gpr(dvreg),RSP,soff);
        else                   __ ld8 (reg2gpr(dvreg),RSP,soff);
      } else {                     // fpr <- mem
        assert0( is_fpr(dvreg) );
        if( _type->base() == Type::FloatBot ) __ ld4(reg2fpr(dvreg),RSP,soff);
        else                                  __ ld8(reg2fpr(dvreg),RSP,soff);
      }
    }
return;
  } 

  VReg::VR svreg = OptoReg::as_VReg(src);
  if( is_gpr(svreg) ) {            //     <- gpr
if(OptoReg::is_stack(dst)){//mem <- gpr
      if( _type->isa_int() ) __ st4(RSP,doff,reg2gpr(svreg));
      else                   __ st8(RSP,doff,reg2gpr(svreg));
    } else {
      VReg::VR dvreg = OptoReg::as_VReg(dst);
      if( is_gpr(dvreg) ) {        // gpr <- gpr
        if( _type->isa_int() ) __ mov4(reg2gpr(dvreg),reg2gpr(svreg));
        else                   __ mov8(reg2gpr(dvreg),reg2gpr(svreg));
      } else {                     // fpr <- gpr
        assert0( is_fpr(dvreg) );
        if( _type->base() == Type::FloatBot ) __ mov4(reg2fpr(dvreg),reg2gpr(svreg));
        else                                  __ mov8(reg2fpr(dvreg),reg2gpr(svreg));
      }
    }
return;
  } 


  assert0( is_fpr(svreg) );        //     <- fpr
if(OptoReg::is_stack(dst)){//mem <- fpr
    if( _type->base() == Type::FloatBot ) __ st4(RSP,doff,reg2fpr(svreg));
    else                                  __ st8(RSP,doff,reg2fpr(svreg));
  } else {
    VReg::VR dvreg = OptoReg::as_VReg(dst);
    if( is_gpr(dvreg) ) {          // gpr <- fpr
      if( _type->isa_int() ) __ mov4(reg2gpr(dvreg),reg2fpr(svreg));
      else                   __ mov8(reg2gpr(dvreg),reg2fpr(svreg));
    } else {                       // fpr <- fpr
      assert0( is_fpr(dvreg) );
      if( _type->base() == Type::FloatBot ) __ mov4(reg2fpr(dvreg),reg2fpr(svreg));
      else                                  __ mov8(reg2fpr(dvreg),reg2fpr(svreg));
    }
  }

}

void MachSpillCopyNode::emit(PhaseRegAlloc *ra_) const {
  implementation(ra_);
}

//=============================================================================
void MachNopNode::emit(PhaseRegAlloc*ra_) const {
  __ nop(_count);
}

//=============================================================================
void MachNullNode::emit(PhaseRegAlloc *ra_ ) const {
  Unimplemented();
  //int reg = ra_->get_encode(this);
  //emitB_19_0(cbuf,reg,0);
}

const Pipeline*MachNullNode::pipeline()const{
return addL_rRegNode::pipeline_class();
}


//=============================================================================
void ArrayCopySrcNode::emit(PhaseRegAlloc *ra_) const {}

void ArrayCopyNode::emit(PhaseRegAlloc *ra_) const { 
  if( UseSBA && ((ArrayCopySrcNode*)in(1))->_scale == 0 ) {
    Unimplemented();
  //  Label goslow, done;
  //  // Verify stack-compatible copies.  Must be first because it has the oop-map.
  //  __ svb( R21, 0, R19 );  // Verify compatible copies.
  //  __ pushframe( R19 );
  //  // Stack-to-stack copies do not need to do LVBs or card-marks.
  //  // Simply use the fast by-8 copy.  Note that after the above
  //  // SVB I either have 2 compatible stack-refs or no stack-refs.
  //  __ extracti(R5, R0, objectRef::space_shift, objectRef::space_bits-1, 0);
  //  __ bnei(R5, (uint64_t)objectRef::stack_space_id, goslow);
  //  __ js  ( CAST_FROM_FN_PTR(address, StubRoutines::x86::arraycopy_8()) );
  //  __ br  ( done );
  //  __ bind( goslow );
  //  __ js  ( CAST_FROM_FN_PTR(address, StubRoutines::x86::arraycopy_a()) );
  //  __ bind( done );
  }
  // compute shift and offset to scale position by
  assert0( arrayOopDesc::base_offset_in_bytes(T_LONG) == arrayOopDesc::base_offset_in_bytes(T_OBJECT) );
  int shf = "301x2xxx3"[((ArrayCopySrcNode*)in(1))->_scale] - '0';
  static BasicType bts[4] = { T_BYTE, T_SHORT, T_INT, T_LONG };
  // RSI=srcref, RAX=srcpos, RDI=dstref, RCX=dstpos, RDX=length
  int off = arrayOopDesc::base_offset_in_bytes(bts[shf]);
  if( in(1/*ACsrc*/)->in(4/*dst off*/)->is_Con() ) {
    __ add8i( RSI, (in(1)->in(4)->bottom_type()->is_int()->get_con() << shf)+off );
  } else {
    __ lea  ( RSI, RSI, off, RAX, shf );
  }
  if( in(5/*dst off*/)->is_Con() ) {
    __ add8i( RDI, (in(5)->bottom_type()->is_int()->get_con() << shf)+off );
  } else {
    __ lea  ( RDI, RDI, off, RCX, shf );
  }
address x=0;
  switch(((ArrayCopySrcNode*)in(1))->_scale) {
    // fast-path oop copy still needs read/write barriers, but is known compatible.
    // Leaf call, no GC requirements
  case 0: x=StubRoutines     ::object_arraycopy(); break;
  case 1: x=StubRoutines::x86::_prim_arraycopy1; break;
  case 2: x=StubRoutines::x86::_prim_arraycopy2; break;
  case 4: x=StubRoutines::x86::_prim_arraycopy4; break;
  case 8: x=StubRoutines::x86::_prim_arraycopy8; break;
  }
__ call(x);
}

const RegMask&ArrayCopySrcNode::in_RegMask(uint idx)const{
  switch( idx ) {
  case 0: return RegMask::Empty;
  case 1: return RegMask::Empty;
  case 2: return RegMask::Empty;
  case 3: return PTR_RSI_REG_mask; // src
  case 4: return INT_RAX_REG_mask; // src off
  default: ShouldNotReachHere();  return RegMask::Empty;
  }
}

const RegMask&ArrayCopyNode::in_RegMask(uint idx)const{
  switch( idx ) {
  case 0: return RegMask::Empty;
  case 1: return RegMask::Empty;
  case 2: return RegMask::Empty;
  case 3: return RegMask::Empty;
  case 4: return PTR_RDI_REG_mask; // dst
  case 5: return INT_RCX_REG_mask; // dst off
  case 6: return INT_RDX_REG_mask; // len
  default: 
    assert0( UseSBA && idx >= (uint)base_derived_idx() ); // SBA and a base/derived pair spanning the arraycopy
    return *Compile::current()->matcher()->idealreg2spillmask[Op_RegP];
  }
}

const RegMask &ArrayCopyNode::kill_RegMask() const {
  return ((ArrayCopySrcNode*)in(1))->_scale ? ARRAYCOPY_PRIM_KILLS_mask : ARRAYCOPY_OOP_KILLS_mask;
}

//=============================================================================

void MachLVBNode::emit(PhaseRegAlloc *ra_) const {
__ pushf();

  if( UseLVBs ) {
    unsigned idx1 = 2;
    unsigned idx2 = 2;

OptoReg::Name dst=ra_->get_reg(this);

    MachNode *value = in(1)->as_Mach();

    // This case is applicable when value (Klass/Oop) is not loaded from 
    // rather is embedded in the type information of a constant node.
    if( req() == 3 ) {
      assert( _opnds[1]->num_edges() == 0,
"Missing base address ~ inconsistent with MachOper");
      assert( value->ideal_Opcode() == Op_ConP && bottom_type()->isa_oopptr(),
"Trying to LVB a non-oopptr");
       const TypeOopPtr *to = bottom_type()->is_oopptr();
ciObject*cio=to->const_oop();
       const int idx = cio->is_klass()
                       ? ((ciKlass*)cio)->klassId() : ciEnv::get_OopTable_index(cio->encoding());

       intptr_t ktb_adr = (intptr_t)KlassTable::getKlassTableBase()+(idx<<3);
       __ lvb(RInOuts::a, reg2gpr(OptoReg::as_VReg(dst)),
              _opnds[2]->reg(ra_,this, idx2 + _opnds[1]->num_edges()),
              RKeepIns::a, noreg, ktb_adr, true );
    }
    else {
      if( value->ideal_Opcode() ==  Op_KID2Klass ) {
        intptr_t ktb_adr = (intptr_t)KlassTable::getKlassTableBase();
        __ lvb(RInOuts::a,
               reg2gpr(OptoReg::as_VReg(dst)),
               _opnds[2]->reg(ra_,this, idx2 + _opnds[1]->num_edges()),
               RKeepIns::a, noreg, ktb_adr, _opnds[1]->reg(ra_,this,idx1), 3, true);
      }
      else {
        __ lvb(RInOuts::a,
               reg2gpr(OptoReg::as_VReg(dst)),
               _opnds[2]->reg(ra_,this, idx2 + _opnds[1]->num_edges()),
               RKeepIns::a,
               _opnds[1]->base(ra_,this,idx1),
               _opnds[1]->disp(ra_,this,idx1),
               _opnds[1]->index(ra_,this,idx1),
               _opnds[1]->scale(), true);
      }
    }
  }
  else if( RefPoisoning ) {
OptoReg::Name dst=ra_->get_reg(this);
    __ unpoison(reg2gpr(OptoReg::as_VReg(dst)));
  }

__ popf();
}

// Register masks are copied the input LD8
const RegMask&MachLVBNode::in_RegMask(uint idx)const{
  if( idx == 0 ) return RegMask::Empty;
  return *Matcher::idealreg2regmask[Op_RegP];
}

const RegMask&MachLVBNode::out_RegMask()const{
  return *Matcher::idealreg2regmask[Op_RegP];
}

const RegMask &MachLVBNode::kill_RegMask() const {
  return MACHLVB_KILLS_mask;  
}

const Pipeline*MachLVBNode::pipeline()const{
return addL_rRegNode::pipeline_class();
}

//=============================================================================
// This is UltraSparc specific, true just means we have fast l2f conversion
const bool Matcher::convL2FSupported(void) {
  return true;
}

// Vector width in bytes
const uint Matcher::vector_width_in_bytes(void) {
  return 8;
}

// Vector ideal reg
const uint Matcher::vector_ideal_reg(void) {
  return Op_RegD;
}

// The ecx parameter to rep stosq for the ClearArray node is in words.
const bool Matcher::init_array_count_is_in_bytes = false;

// Threshold size for cleararray.
const int Matcher::init_array_short_size = 8 * BytesPerLong;

// Should the Matcher clone shifts on addressing modes, expecting them
// to be subsumed into complex addressing expressions or compute them
// into registers?  True for Intel but false for most RISCs
const bool Matcher::clone_shift_expressions = true;

// Is it better to copy float constants, or load them directly from
// memory?  Intel can load a float constant from a direct address,
// requiring no extra registers.  Most RISCs will have to materialize
// an address into a register first, so they would do better to copy
// the constant from stack.
const bool Matcher::rematerialize_float_constants=true;

// No-op on amd64
void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {}

// Advertise here if the CPU requires explicit rounding operations to
// implement the UseStrictFP mode.
const bool Matcher::strict_fp_requires_explicit_rounding = true;

// Register for DIVI projection of divmodI
RegMask Matcher::divI_proj_mask() {
  return INT_RAX_REG_mask;
}

// Register for MODI projection of divmodI
RegMask Matcher::modI_proj_mask() {
  return INT_RDX_REG_mask;
}

// Register for DIVL projection of divmodL
RegMask Matcher::divL_proj_mask() {
  return LONG_RAX_REG_mask;
}

// Register for MODL projection of divmodL
RegMask Matcher::modL_proj_mask() {
  return LONG_RDX_REG_mask;
}

void Compile::pd_compiler2_init() {  
  guarantee(CodeEntryAlignment >= InteriorEntryAlignment, "" );
}

%}


//----------FRAME--------------------------------------------------------------
// Definition of frame structure and management information.
//
//  S T A C K   L A Y O U T    Allocators stack-slot number
//                             |   (to get allocators register number
//  G  Owned by    |        |  v    add OptoReg::stack0())
//  r   CALLER     |        |
//  o     |        |        |
//  w     V        |        |
//  t   -----------+--------+----> Matcher::_in_arg_limit, unaligned
//  h     ^        |   in   |  4
//        |        |  args  |  3   Holes in incoming args owned by SELF
//  |     |        |        |  2
//  |     |        +--------+
//  V     |        | old out|      Empty on Intel, window on Sparc
//        |    old |preserve|      
//        |     SP-+--------+----> Matcher::_old_SP, 16b aligned
//        |        |   in   |  1   area for Intel ret address
//     Owned by    |preserve|      Empty on Sparc.
//       SELF      +--------+
//        |        |  pad2  |  0   pad to align old SP
//        |        +--------+   
//        |        |        | 10
//        |        | spills |  9   spills
//        V        |        |  8   (pad0 slot for callee)
//      -----------+--------+----> Matcher::_out_arg_limit, unaligned
//        ^        |  out   |  7
//        |        |  args  |  6   Holes in outgoing args owned by CALLER
//     Owned by    +--------+
//      CALLEE     | new out|      Empty on Intel, window on Sparc
//        |    new |preserve|  5   
//        |     SP-+--------+----> Matcher::_new_SP, 16b aligned
//        |        |        |
//
// Note 1: Only region 5-7 is determined by the allocator.  Region 0-2 is
//         known from SELF's arguments and the Java calling convention.
//         Region 3-4 is determined per call site.
// Note 2: If the calling convention leaves holes in the incoming argument
//         area, those holes are owned by SELF.  Holes in the outgoing area
//         are owned by the CALLEE.  Holes should not be nessecary in the
//         incoming area, as the Java calling convention is completely under
//         the control of the AD file.  Doubles can be sorted and packed to
//         avoid holes.
// Note 3: Region 0-2 is even aligned, with pad0 as needed.  Region 3-4 is
//         even aligned with pad0 as needed.
//         region 3-7 is even aligned; it may be padded out more so that
//         the region from SP to FP meets the minimum stack alignment.

frame
%{
  // Optional: name the operand used by cisc-spilling to access
  // [stack_pointer + offset]
  cisc_spilling_operand_name(indOffset32);

  // Compiled code's Frame Pointer
  frame_pointer(RSP);

  // Stack alignment requirement
stack_alignment(16);//Alignment size in bytes (128-bit -> 16 bytes)

  // Number of stack slots between incoming argument block and the start of
  // a new frame.  The PROLOG must add this many slots to the stack.  The
  // EPILOG must remove this many slots.  x86 needs a slot for the 
  // return address.
in_preserve_stack_slots(1);

  // Number of stack slots between the outgoing argument block and the lowest
  // part of the old frame. 
  out_preserve_stack_slots(0);

  // The after-PROLOG location of the return address.  Location of
  // return address specifies a type (REG or STACK) and a number
  // representing the register number (i.e. - use a register name) or
  // stack slot.
  // Ret Addr is on stack in slot 0
  return_addr(STACK 0);

  // Body of function which returns an integer array locating
  // arguments either in registers or in stack slots.  Passed an array
  // of ideal registers called "sig" and a "length" count.  Stack-slot
  // offsets are based on outgoing arguments, i.e. a CALLER setting up
  // arguments for a CALLEE.  Incoming stack arguments are
  // automatically biased by the preserve_stack_slots field above.

  calling_convention %{
    // No difference between ingoing/outgoing just pass false
    SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
  %}

  // Location of compiled Java return values.  Same as C for now.
return_value%{
assert(ideal_reg>=Op_RegI&&ideal_reg<=Op_RegL,"only return normal values");
static const VReg::VR lo[Op_RegL+1]={
VReg::Bad,
VReg::Bad,
gpr2reg(RAX),//Op_RegI
gpr2reg(RAX),//Op_RegP
fpr2reg(F00),//Op_RegF
fpr2reg(F00),//Op_RegD
      gpr2reg(RAX)   // Op_RegL
    };
return lo[ideal_reg];
  %}
%}

//----------ATTRIBUTES---------------------------------------------------------
//----------Operand Attributes-------------------------------------------------
op_attrib op_cost(0);        // Required cost attribute

//----------Instruction Attributes---------------------------------------------
ins_attrib ins_cost(100);       // Required cost attribute

//----------OPERANDS-----------------------------------------------------------
// Operand definitions must precede instruction definitions for correct parsing
// in the ADLC because operands constitute user defined types which are used in
// instruction definitions.

//----------Simple Operands----------------------------------------------------
// Immediate Operands
// Integer Immediate
operand immI()%{
  match(ConI);
  op_cost(10);
  interface(CONST_INTER);
%}

// Constant for test vs zero
operand immI0()%{
  predicate(n->get_int() == 0);
  match(ConI);
  op_cost(0);
  interface(CONST_INTER);
%}

// Constant for increment
operand immI1()%{
  predicate(n->get_int() == 1);
  match(ConI);
  op_cost(0);
  interface(CONST_INTER);
%}

// Constant for decrement
operand immI_M1()%{
  predicate(n->get_int() == -1);
  match(ConI);
  op_cost(0);
  interface(CONST_INTER);
%}

// Valid scale values for addressing modes
operand immI2()%{
  predicate(0 <= n->get_int() && (n->get_int() <= 3));
  match(ConI);
  interface(CONST_INTER);
%}

operand immI8() %{
  predicate((-0x80 <= n->get_int()) && (n->get_int() < 0x80));
  match(ConI);
  op_cost(5);
  interface(CONST_INTER);
%}

operand immI16() %{
  predicate((-32768 <= n->get_int()) && (n->get_int() <= 32767));
  match(ConI);
  op_cost(10);
  interface(CONST_INTER);
%}

operand immIPos()%{
predicate((0<=n->get_int())&&(n->get_int()<=0x7FFFFFFF));
match(ConI);
op_cost(10);
  interface(CONST_INTER);
%}

// Constant for long shifts
operand immI_32()%{
  predicate( n->get_int() == 32 );
  match(ConI);
  op_cost(0);
  interface(CONST_INTER);
%}

// Constant for long shifts
operand immI_64()%{
  predicate( n->get_int() == 64 );
  match(ConI);
  op_cost(0);
  interface(CONST_INTER);
%}

// Pointer Immediate
operand immP()%{
  match(ConP);
  op_cost(10);
  interface(CONST_INTER);
%}

// NULL Pointer Immediate
operand immP0()%{
  predicate(n->get_ptr() == 0);
  match(ConP);
  op_cost(5);
  interface(CONST_INTER);
%}

operand immP31()%{
  predicate(!n->as_Type()->type()->isa_oopptr()
            && (n->get_ptr() >> 31) == 0);
  match(ConP);
  op_cost(5);
  interface(CONST_INTER);
%}


// Long Immediate
operand immL()%{
  match(ConL);
  op_cost(20);
  interface(CONST_INTER);
%}

// Long Immediate 8-bit
operand immL8()%{
  predicate(-0x80L <= n->get_long() && n->get_long() < 0x80L);
  match(ConL);
  op_cost(5);
  interface(CONST_INTER);
%}

// Long Immediate 32-bit unsigned
operand immUL32()%{
  predicate(n->get_long() == (unsigned int) (n->get_long()));
  match(ConL);
  op_cost(10);
  interface(CONST_INTER);
%}

// Long Immediate 32-bit signed
operand immL32()%{
  predicate(n->get_long() == (int) (n->get_long()));
  match(ConL);
  op_cost(15);
  interface(CONST_INTER);
%}

// Long Immediate zero
operand immL0()
%{
  predicate(n->get_long() == 0L);
  match(ConL);

  op_cost(10);
  interface(CONST_INTER);
%}

// Constant for increment
operand immL1()
%{
  predicate(n->get_long() == 1);
  match(ConL);

  interface(CONST_INTER);
%}

// Constant for decrement
operand immL_M1()
%{
  predicate(n->get_long() == -1);
  match(ConL);

  interface(CONST_INTER);
%}

// Long Immediate: the value 10
operand immL10()
%{
  predicate(n->get_long() == 10);
  match(ConL);

  interface(CONST_INTER);
%}

// Long immediate from 0 to 127.
// Used for a shorter form of long mul by 10.
operand immL_127()
%{
  predicate(0 <= n->get_long() && n->get_long() < 0x80);
  match(ConL);

  op_cost(10);
  interface(CONST_INTER);
%}

// Long Immediate: low 32-bit mask
operand immL_32bits()%{
  predicate(n->get_long() == 0xFFFFFFFFL);
  match(ConL);
  op_cost(20);
  interface(CONST_INTER);
%}

// Float Immediate zero
operand immF0()%{
  predicate(jint_cast(n->getf()) == 0);
  match(ConF);
  op_cost(5);
  interface(CONST_INTER);
%}

// Float Immediate
operand immF()%{
  match(ConF);
  op_cost(15);
  interface(CONST_INTER);
%}

operand immF_mem()%{
  predicate(MacroAssembler::float_constant(n->getf())!=0);
match(ConF);
op_cost(5);
  interface(CONST_INTER);
%}

// Double Immediate zero
operand immD0()%{
  predicate(jlong_cast(n->getd()) == 0);
  match(ConD);
  op_cost(5);
  interface(CONST_INTER);
%}

operand immD_mem()%{
  predicate(MacroAssembler::double_constant(n->getd())!=0);
match(ConD);
op_cost(5);
  interface(CONST_INTER);
%}

// Double Immediate
operand immD()%{
  match(ConD);
  op_cost(15);
  interface(CONST_INTER);
%}

// Immediates for special shifts (sign extend)

// Constants for increment
operand immI_16()%{
  predicate(n->get_int() == 16);
  match(ConI);

  interface(CONST_INTER);
%}

operand immI_24() %{
  predicate(n->get_int() == 24);
  match(ConI);

  interface(CONST_INTER);
%}

// Constant for byte-wide masking
operand immI_255()%{
  predicate(n->get_int() == 255);
  match(ConI);
  interface(CONST_INTER);
%}

// Constant for short-wide masking
operand immI_65535()%{
  predicate(n->get_int() == 65535);
  match(ConI);
  interface(CONST_INTER);
%}

// Constant for byte-wide masking
operand immL_255()
%{
  predicate(n->get_long() == 255);
  match(ConL);

  interface(CONST_INTER);
%}

// Constant for short-wide masking
operand immL_65535()
%{
  predicate(n->get_long() == 65535);
  match(ConL);

  interface(CONST_INTER);
%}

// Register Operands
// Integer Register
operand rRegI()%{
  constraint(ALLOC_IN_RC(int_reg));
  match(RegI);
  match(rax_RegI);
  match(rbx_RegI);
  match(rcx_RegI);
  match(rdx_RegI);
  match(rdi_RegI);
match(r09_RegI);
match(no_rcx_RegI);
  interface(REG_INTER);
%}

// Special Registers
operand rax_RegI()%{
  constraint(ALLOC_IN_RC(int_rax_reg));
  match(RegI);
  match(rRegI);
  interface(REG_INTER);
%}

// Special Registers
operand rbx_RegI()%{
  constraint(ALLOC_IN_RC(int_rbx_reg));
  match(RegI);
  match(rRegI);
  interface(REG_INTER);
%}

operand rcx_RegI()%{
  constraint(ALLOC_IN_RC(int_rcx_reg));
  match(RegI);
  match(rRegI);
  interface(REG_INTER);
%}

operand rdx_RegI()%{
  constraint(ALLOC_IN_RC(int_rdx_reg));
  match(RegI);
  match(rRegI);
  interface(REG_INTER);
%}

operand rdi_RegI()%{
  constraint(ALLOC_IN_RC(int_rdi_reg));
  match(RegI);
  match(rRegI);
  interface(REG_INTER);
%}

operand rsi_RegI()%{
constraint(ALLOC_IN_RC(int_rsi_reg));
  match(RegI);
match(rRegI);
  interface(REG_INTER);
%}

operand r09_RegI()%{
constraint(ALLOC_IN_RC(int_r09_reg));
  match(RegI);
match(rRegI);
  interface(REG_INTER);
%}

operand no_rcx_RegI()%{
  constraint(ALLOC_IN_RC(int_no_rcx_reg));
  match(RegI);
  match(rRegI);
  match(rax_RegI);
  match(rbx_RegI);
  match(rdx_RegI);
  match(rdi_RegI);
  interface(REG_INTER);
%}

operand no_rax_rdx_RegI()%{
  constraint(ALLOC_IN_RC(int_no_rax_rdx_reg));
  match(RegI);
  match(rbx_RegI);
  match(rcx_RegI);
  match(rdi_RegI);
match(r09_RegI);
  interface(REG_INTER);
%}

// Pointer Register
operand any_RegP()%{
  constraint(ALLOC_IN_RC(any_reg));
  match(RegP);
  match(rax_RegP);
  match(rdi_RegP);
  match(rsi_RegP);
match(r09_RegP);
  match(rRegP);
  interface(REG_INTER);
%}

operand rRegP()%{
  constraint(ALLOC_IN_RC(ptr_reg));
  match(RegP);
  match(rax_RegP);
  match(rdi_RegP);
  match(rsi_RegP);
match(r09_RegP);
  interface(REG_INTER);
%}

// Special Registers
// Return a pointer value
operand rax_RegP()%{
  constraint(ALLOC_IN_RC(ptr_rax_reg));
  match(RegP);
  match(rRegP);
  interface(REG_INTER);
%}

operand rcx_RegP()%{
constraint(ALLOC_IN_RC(ptr_rcx_reg));
  match(RegP);
  match(rRegP);
  interface(REG_INTER);
%}

operand rsi_RegP()%{
  constraint(ALLOC_IN_RC(ptr_rsi_reg));
  match(RegP);
  match(rRegP);
  interface(REG_INTER);
%}

// Used in rep stosq
operand rdi_RegP()%{
  constraint(ALLOC_IN_RC(ptr_rdi_reg));
  match(RegP);
  match(rRegP);
  interface(REG_INTER);
%}

operand r09_RegP()%{
constraint(ALLOC_IN_RC(int_r09_reg));
  match(RegP);
  match(rRegP);
  interface(REG_INTER);
%}

operand rRegL()%{
  constraint(ALLOC_IN_RC(long_reg));
  match(RegL);
  match(rax_RegL);
match(rcx_RegL);
  match(rdx_RegL);
match(no_rcx_RegL);
  interface(REG_INTER);
%}

// Special Registers
operand no_rax_rdx_RegL()
%{
  constraint(ALLOC_IN_RC(long_no_rax_rdx_reg));
  match(RegL);
  match(rRegL);

  interface(REG_INTER);
%}

operand no_rax_RegL()
%{
  constraint(ALLOC_IN_RC(long_no_rax_rdx_reg));
  match(RegL);
  match(rRegL);
  match(rdx_RegL);

  interface(REG_INTER);
%}

operand no_rcx_RegL()%{
  constraint(ALLOC_IN_RC(long_no_rcx_reg));
  match(RegL);
  match(rRegL);

  interface(REG_INTER);
%}

operand rax_RegL()%{
  constraint(ALLOC_IN_RC(long_rax_reg));
  match(RegL);
  match(rRegL);
  interface(REG_INTER);
%}

operand rcx_RegL()%{
  constraint(ALLOC_IN_RC(long_rcx_reg));
  match(RegL);
  match(rRegL);
  interface(REG_INTER);
%}

operand rdx_RegL()%{
  constraint(ALLOC_IN_RC(long_rdx_reg));
  match(RegL);
  match(rRegL);
  interface(REG_INTER);
%}

// Flags register, used as output of compare instructions
operand rFlagsReg()%{
  constraint(ALLOC_IN_RC(int_flags));
  match(RegFlags);
  interface(REG_INTER);
%}

// Flags register, used as output of 'test' instructions
operand rFlagsRegEQ()%{
  constraint(ALLOC_IN_RC(int_flags));
  match(RegFlags);
  interface(REG_INTER);
%}

// Flags register, used as output of 'btx' instructions
operand rFlagsRegEQ2Carry()%{
  constraint(ALLOC_IN_RC(int_flags));
  match(RegFlags);
  interface(REG_INTER);
%}


// Flags register, used as output of FLOATING POINT compare instructions
operand rFlagsRegU()%{
  constraint(ALLOC_IN_RC(int_flags));
  match(RegFlags);
  interface(REG_INTER);
%}

operand rFlagsRegUCF()%{
  constraint(ALLOC_IN_RC(int_flags));
  match(RegFlags);
  predicate(false);

  interface(REG_INTER);
%}

// Float register operands
operand regF()%{
  constraint(ALLOC_IN_RC(float_reg));
  match(RegF);
  interface(REG_INTER);
%}

// Double register operands
operand regD()%{
  constraint(ALLOC_IN_RC(double_reg));
  match(RegD);
match(f15_RegD);
  interface(REG_INTER);
%}

operand f15_RegD()%{
constraint(ALLOC_IN_RC(fp_f15_reg));
match(RegD);
match(regD);
  interface(REG_INTER);
%}



//----------Memory Operands----------------------------------------------------
// Direct Memory Operand
// operand direct(immP addr)
// %{
//   match(addr);

//   interface(MEMORY_INTER) %{
//     base(0xFFFFFFFF);
//     index(0x4);
//     scale(0x0);
//     disp($addr);
//   %}
// %}

// Indirect Memory Operand
operand indirect(any_RegP reg)%{
  constraint(ALLOC_IN_RC(ptr_reg));
  match(reg);
  interface(MEMORY_INTER) %{
    base($reg);
index(0xFFFFFFFF);
    scale(0x0);
    disp(0x0);
  %}
%}

// Indirect Memory Plus Short Offset Operand
operand indOffset8(any_RegP reg,immL8 off)%{
  constraint(ALLOC_IN_RC(ptr_reg));
  match(AddP reg off);
  interface(MEMORY_INTER) %{
    base($reg);
index(0xFFFFFFFF);
    scale(0x0);
    disp($off);
  %}
%}

// Indirect Memory Plus Long Offset Operand
operand indOffset32(any_RegP reg,immL32 off)%{
  constraint(ALLOC_IN_RC(ptr_reg));
  match(AddP reg off);
  interface(MEMORY_INTER) %{
    base($reg);
index(0xFFFFFFFF);
    scale(0x0);
    disp($off);
  %}
%}

// Indirect Memory Plus Index Register Plus Offset Operand
operand indIndexOffset(any_RegP reg,rRegL lreg,immL32 off)%{
  constraint(ALLOC_IN_RC(ptr_reg));
  match(AddP (AddP reg lreg) off);
  op_cost(10);
  interface(MEMORY_INTER) %{
    base($reg);
    index($lreg);
    scale(0x0);
    disp($off);
  %}
%}

// Indirect Memory Plus Index Register Plus Offset Operand
operand indIndex(any_RegP reg,rRegL lreg)%{
  constraint(ALLOC_IN_RC(ptr_reg));
  match(AddP reg lreg);
  op_cost(10);
  interface(MEMORY_INTER) %{
    base($reg);
    index($lreg);
    scale(0x0);
    disp(0x0);
  %}
%}

// Indirect Memory Times Scale Plus Index Register
operand indIndexScale(any_RegP reg,rRegL lreg,immI2 scale)%{
  constraint(ALLOC_IN_RC(ptr_reg));
  match(AddP reg (LShiftL lreg scale));
  op_cost(10);
  interface(MEMORY_INTER) %{
    base($reg);
    index($lreg);
    scale($scale);
    disp(0x0);
  %}
%}

// Indirect Memory Times Scale Plus Index Register Plus Offset Operand
operand indIndexScaleOffset(any_RegP reg,immL32 off,rRegL lreg,immI2 scale)%{
  constraint(ALLOC_IN_RC(ptr_reg));
  match(AddP (AddP reg (LShiftL lreg scale)) off);
  op_cost(10);
  interface(MEMORY_INTER) %{
    base($reg);
    index($lreg);
    scale($scale);
    disp($off);
  %}
%}

// Indirect Memory Times Scale Plus Positive Index Register Plus Offset Operand
operand indPosIndexScaleOffset(any_RegP reg,immL32 off,rRegI idx,immI2 scale)%{
  constraint(ALLOC_IN_RC(ptr_reg));
  predicate(n->in(2)->in(3)->in(1)->as_Type()->type()->is_long()->_lo >= 0);
  match(AddP (AddP reg (LShiftL (ConvI2L idx) scale)) off);
  op_cost(10);
  interface(MEMORY_INTER) %{
    base($reg);
    index($idx);
    scale($scale);
    disp($off);
  %}
%}

operand directAddr( immP31 adr ) %{
match(adr);
  // This puts a pointer directly in the code.  The pointer had better NOT be an 
  // oop because GC will not be adjusting any code.
  interface(MEMORY_INTER) %{
    base(0xFFFFFFFF);
index(0xFFFFFFFF);
    scale(0x0);
disp($adr);
  %}
%}


//----------Special Memory Operands--------------------------------------------
// Stack Slot Operand - This operand is used for loading and storing temporary
//                      values on the stack where a match requires a value to
//                      flow through memory.
operand stackSlotP(sRegP reg)
%{
  constraint(ALLOC_IN_RC(stack_slots));
  // No match rule because this operand is only generated in matching

  interface(MEMORY_INTER) %{
    base(0x4);   // RSP
index(0xFFFFFFFF);//No Index
    scale(0x0);  // No Scale
    disp($reg);  // Stack Offset
  %}
%}

operand stackSlotI(sRegI reg)
%{
  constraint(ALLOC_IN_RC(stack_slots));
  // No match rule because this operand is only generated in matching

  interface(MEMORY_INTER) %{
    base(0x4);   // RSP
index(0xFFFFFFFF);//No Index
    scale(0x0);  // No Scale
    disp($reg);  // Stack Offset
  %}
%}

operand stackSlotF(sRegF reg)
%{
  constraint(ALLOC_IN_RC(stack_slots));
  // No match rule because this operand is only generated in matching

  interface(MEMORY_INTER) %{
    base(0x4);   // RSP
index(0xFFFFFFFF);//No Index
    scale(0x0);  // No Scale
    disp($reg);  // Stack Offset
  %}
%}

operand stackSlotD(sRegD reg) %{
  constraint(ALLOC_IN_RC(stack_slots));
  // No match rule because this operand is only generated in matching
  interface(MEMORY_INTER) %{
    base(0x4);   // RSP
index(0xFFFFFFFF);//No Index
    scale(0x0);  // No Scale
    disp($reg);  // Stack Offset
  %}
%}
operand stackSlotL(sRegL reg)%{
  constraint(ALLOC_IN_RC(stack_slots));
  // No match rule because this operand is only generated in matching
  interface(MEMORY_INTER) %{
    base(0x4);   // RSP
index(0xFFFFFFFF);//No Index
    scale(0x0);  // No Scale
    disp($reg);  // Stack Offset
  %}
%}

//----------Conditional Branch Operands----------------------------------------
// Comparison Op  - This is the operation of the comparison, and is limited to
//                  the following set of codes:
//                  L (<), LE (<=), G (>), GE (>=), E (==), NE (!=)
//
// Other attributes of the comparison, such as unsignedness, are specified
// by the comparison instruction that sets a condition code flags register.
// That result is represented by a flags operand whose subtype is appropriate
// to the unsignedness (etc.) of the comparison.
//
// Later, the instruction which matches both the Comparison Op (a Bool) and
// the flags (produced by the Cmp) specifies the coding of the comparison op
// by matching a specific subtype of Bool operand below, such as cmpOpU.

// Comparision Code
operand cmpOp()%{
  match(Bool);
  interface(COND_INTER) %{
equal(0x4,"eq");
not_equal(0x5,"ne");
less(0xC,"lt");
greater_equal(0xD,"ge");
less_equal(0xE,"le");
greater(0xF,"gt");
  %}
%}

// Comparison Code, unsigned compare.  Used by FP also, with
// C2 (unordered) turned into GT or LT already.  The other bits
// C0 and C3 are turned into Carry & Zero flags.
operand cmpOpU()%{
  match(Bool);
  interface(COND_INTER) %{
equal(0x4,"eq");
not_equal(0x5,"ne");
less(0x2,"bl");
greater_equal(0x3,"ae");
less_equal(0x6,"be");
greater(0x7,"ab");
  %}
%}


// Comparision Code: equality tests only.
operand cmpOpEQ()%{
  match(Bool);
  predicate(n->as_Bool()->_test._test == BoolTest::eq ||
            n->as_Bool()->_test._test == BoolTest::ne);
  interface(COND_INTER) %{
    equal        (0x4 , "eq");
    not_equal    (0x5 , "ne");
    less         (0xFF, "--");
    greater_equal(0xFF, "--");
    less_equal   (0xFF, "--");
    greater      (0xFF, "--");
  %}
%}

// Floating comparisons that don't require any fixup for the unordered case
operand cmpOpUCF()%{
  match(Bool);
  predicate(n->as_Bool()->_test._test == BoolTest::lt ||
            n->as_Bool()->_test._test == BoolTest::ge ||
            n->as_Bool()->_test._test == BoolTest::le ||
            n->as_Bool()->_test._test == BoolTest::gt);
  interface(COND_INTER) %{
    equal(0x4, "e");
    not_equal(0x5, "ne");
    less(0x2, "b");
    greater_equal(0x3, "nb");
    less_equal(0x6, "be");
    greater(0x7, "nbe");
  %}
%}


// Floating comparisons that can be fixed up with extra conditional jumps
operand cmpOpUCF2()%{
  match(Bool);
  predicate(n->as_Bool()->_test._test == BoolTest::ne ||
            n->as_Bool()->_test._test == BoolTest::eq);
  interface(COND_INTER) %{
    equal(0x4, "e");
    not_equal(0x5, "ne");
    less(0x2, "b");
    greater_equal(0x3, "nb");
    less_equal(0x6, "be");
    greater(0x7, "nbe");
  %}
%}


//----------OPERAND CLASSES----------------------------------------------------
// Operand Classes are groups of operands that are used as to simplify
// instruction definitions by not requiring the AD writer to specify separate
// instructions for every form of operand when the instruction accepts
// multiple operand types with the same basic encoding and format.  The classic
// case of this is memory operands.

opclass memory(indirect, indOffset8, indOffset32, indIndexOffset, indIndex,
indIndexScale,indIndexScaleOffset,indPosIndexScaleOffset,directAddr);

//----------PIPELINE-----------------------------------------------------------
// Rules which define the behavior of the target architectures pipeline.
pipeline %{

//----------ATTRIBUTES---------------------------------------------------------
attributes %{
  variable_size_instructions;        // Fixed size instructions
  max_instructions_per_bundle = 3;   // Up to 3 instructions per bundle
  instruction_unit_size = 1;         // An instruction is 1 bytes long
  instruction_fetch_unit_size = 16;  // The processor fetches one line
  instruction_fetch_units = 1;       // of 16 bytes

  // List of nop instructions
  nops( MachNop );
%}

//----------RESOURCES----------------------------------------------------------
// Resources are the functional units available to the machine

// Generic P2/P3 pipeline
// 3 decoders, only D0 handles big operands; a "bundle" is the limit of
// 3 instructions decoded per cycle.
// 2 load/store ops per cycle, 1 branch, 1 FPU,
// 3 ALU op, only ALU0 handles mul instructions.
resources( D0, D1, D2, DECODE = D0 | D1 | D2,
           MS0, MS1, MS2, MEM = MS0 | MS1 | MS2,
           BR, FPU,
           ALU0, ALU1, ALU2, ALU = ALU0 | ALU1 | ALU2);

//----------PIPELINE DESCRIPTION-----------------------------------------------
// Pipeline Description specifies the stages in the machine's pipeline

// Generic P2/P3 pipeline
pipe_desc(S0, S1, S2, S3, S4, S5);

//----------PIPELINE CLASSES---------------------------------------------------
// Pipeline Classes describe the stages in which input and output are
// referenced by the hardware pipeline.

// Naming convention: ialu or fpu
// Then: _reg
// Then: _reg if there is a 2nd register
// Then: _long if it's a pair of instructions implementing a long
// Then: _fat if it requires the big decoder
//   Or: _mem if it requires the big decoder and a memory unit.

// Integer ALU reg operation
pipe_class ialu_reg(rRegI dst)
%{
    single_instruction;
    dst    : S4(write);
    dst    : S3(read);
    DECODE : S0;        // any decoder
    ALU    : S3;        // any alu
%}

// Long ALU reg operation
pipe_class ialu_reg_long(rRegL dst)
%{
    instruction_count(2);
    dst    : S4(write);
    dst    : S3(read);
    DECODE : S0(2);     // any 2 decoders
    ALU    : S3(2);     // both alus
%}

// Integer ALU reg operation using big decoder
pipe_class ialu_reg_fat(rRegI dst)
%{
    single_instruction;
    dst    : S4(write);
    dst    : S3(read);
    D0     : S0;        // big decoder only
    ALU    : S3;        // any alu
%}

// Long ALU reg operation using big decoder
pipe_class ialu_reg_long_fat(rRegL dst)
%{
    instruction_count(2);
    dst    : S4(write);
    dst    : S3(read);
    D0     : S0(2);     // big decoder only; twice
    ALU    : S3(2);     // any 2 alus
%}

// Integer ALU reg-reg operation
pipe_class ialu_reg_reg(rRegI dst, rRegI src)
%{
    single_instruction;
    dst    : S4(write);
    src    : S3(read);
    DECODE : S0;        // any decoder
    ALU    : S3;        // any alu
%}

// Long ALU reg-reg operation
pipe_class ialu_reg_reg_long(rRegL dst, rRegL src)
%{
    instruction_count(2);
    dst    : S4(write);
    src    : S3(read);
    DECODE : S0(2);     // any 2 decoders
    ALU    : S3(2);     // both alus
%}

// Integer ALU reg-reg operation
pipe_class ialu_reg_reg_fat(rRegI dst, memory src)
%{
    single_instruction;
    dst    : S4(write);
    src    : S3(read);
    D0     : S0;        // big decoder only
    ALU    : S3;        // any alu
%}

// Long ALU reg-reg operation
pipe_class ialu_reg_reg_long_fat(rRegL dst, rRegL src)
%{
    instruction_count(2);
    dst    : S4(write);
    src    : S3(read);
    D0     : S0(2);     // big decoder only; twice
    ALU    : S3(2);     // both alus
%}

// Integer ALU reg-mem operation
pipe_class ialu_reg_mem(rRegI dst, memory mem)
%{
    single_instruction;
    dst    : S5(write);
    mem    : S3(read);
    D0     : S0;        // big decoder only
    ALU    : S4;        // any alu
    MEM    : S3;        // any mem
%}

// Integer mem operation (prefetch)
pipe_class ialu_mem(memory mem)
%{
    single_instruction;
    mem    : S3(read);
    D0     : S0;        // big decoder only
    MEM    : S3;        // any mem
%}

// Integer Store to Memory
pipe_class ialu_mem_reg(memory mem, rRegI src)
%{
    single_instruction;
    mem    : S3(read);
    src    : S5(read);
    D0     : S0;        // big decoder only
    ALU    : S4;        // any alu
    MEM    : S3;
%}

// // Long Store to Memory
// pipe_class ialu_mem_long_reg(memory mem, rRegL src)
// %{
//     instruction_count(2);
//     mem    : S3(read);
//     src    : S5(read);
//     D0     : S0(2);          // big decoder only; twice
//     ALU    : S4(2);     // any 2 alus
//     MEM    : S3(2);  // Both mems
// %}

// Integer Store to Memory
pipe_class ialu_mem_imm(memory mem)
%{
    single_instruction;
    mem    : S3(read);
    D0     : S0;        // big decoder only
    ALU    : S4;        // any alu
    MEM    : S3;
%}

// Integer ALU0 reg-reg operation
pipe_class ialu_reg_reg_alu0(rRegI dst, rRegI src)
%{
    single_instruction;
    dst    : S4(write);
    src    : S3(read);
    D0     : S0;        // Big decoder only
    ALU0   : S3;        // only alu0
%}

// Integer ALU0 reg-mem operation
pipe_class ialu_reg_mem_alu0(rRegI dst, memory mem)
%{
    single_instruction;
    dst    : S5(write);
    mem    : S3(read);
    D0     : S0;        // big decoder only
    ALU0   : S4;        // ALU0 only
    MEM    : S3;        // any mem
%}

// Integer ALU reg-reg operation
pipe_class ialu_cr_reg_reg(rFlagsReg cr, rRegI src1, rRegI src2)
%{
    single_instruction;
    cr     : S4(write);
    src1   : S3(read);
    src2   : S3(read);
    DECODE : S0;        // any decoder
    ALU    : S3;        // any alu
%}

// Integer ALU reg-imm operation
pipe_class ialu_cr_reg_imm(rFlagsReg cr, rRegI src1)
%{
    single_instruction;
    cr     : S4(write);
    src1   : S3(read);
    DECODE : S0;        // any decoder
    ALU    : S3;        // any alu
%}

// Integer ALU reg-mem operation
pipe_class ialu_cr_reg_mem(rFlagsReg cr, rRegI src1, memory src2)
%{
    single_instruction;
    cr     : S4(write);
    src1   : S3(read);
    src2   : S3(read);
    D0     : S0;        // big decoder only
    ALU    : S4;        // any alu
    MEM    : S3;
%}

// Integer ALU reg-mem operation
pipe_class ialu_cr_mem_imm(rFlagsReg cr,memory src1)
%{
    single_instruction;
    cr     : S4(write);
    src1   : S3(read);
    D0     : S0;        // big decoder only
    ALU    : S4;        // any alu
    MEM    : S3;
%}

// Conditional move reg-reg
pipe_class pipe_cmplt( rRegI p, rRegI q, rRegI y)
%{
    instruction_count(4);
    y      : S4(read);
    q      : S3(read);
    p      : S3(read);
    DECODE : S0(4);     // any decoder
%}

// Conditional move reg-reg
pipe_class pipe_cmov_reg( rRegI dst, rRegI src, rFlagsReg cr)
%{
    single_instruction;
    dst    : S4(write);
    src    : S3(read);
    cr     : S3(read);
    DECODE : S0;        // any decoder
%}

// Conditional move reg-mem
pipe_class pipe_cmov_mem( rFlagsReg cr, rRegI dst, memory src)
%{
    single_instruction;
    dst    : S4(write);
    src    : S3(read);
    cr     : S3(read);
    DECODE : S0;        // any decoder
    MEM    : S3;
%}

// Conditional move reg-reg long
pipe_class pipe_cmov_reg_long( rFlagsReg cr, rRegL dst, rRegL src)
%{
    single_instruction;
    dst    : S4(write);
    src    : S3(read);
    cr     : S3(read);
    DECODE : S0(2);     // any 2 decoders
%}

// XXX
// // Conditional move double reg-reg
// pipe_class pipe_cmovD_reg( rFlagsReg cr, regDPR1 dst, regD src)
// %{
//     single_instruction;
//     dst    : S4(write);
//     src    : S3(read);
//     cr     : S3(read);
//     DECODE : S0;     // any decoder
// %}

// Float reg-reg operation
pipe_class fpu_reg(regD dst)%{
    instruction_count(2);
    dst    : S3(read);
    DECODE : S0(2);     // any 2 decoders
    FPU    : S3;
%}

// Float reg-reg operation
pipe_class fpu_reg_reg(regD dst,regD src)%{
    instruction_count(2);
    dst    : S4(write);
    src    : S3(read);
    DECODE : S0(2);     // any 2 decoders
    FPU    : S3;
%}

// Float reg-reg operation
pipe_class fpu_reg_reg_reg(regD dst, regD src1, regD src2)
%{
    instruction_count(3);
    dst    : S4(write);
    src1   : S3(read);
    src2   : S3(read);
    DECODE : S0(3);     // any 3 decoders
    FPU    : S3(2);
%}

// Float reg-reg operation
pipe_class fpu_reg_reg_reg_reg(regD dst, regD src1, regD src2, regD src3)
%{
    instruction_count(4);
    dst    : S4(write);
    src1   : S3(read);
    src2   : S3(read);
    src3   : S3(read);
    DECODE : S0(4);     // any 3 decoders
    FPU    : S3(2);
%}

// Float reg-reg operation
pipe_class fpu_reg_mem_reg_reg(regD dst, memory src1, regD src2, regD src3)
%{
    instruction_count(4);
    dst    : S4(write);
    src1   : S3(read);
    src2   : S3(read);
    src3   : S3(read);
    DECODE : S1(3);     // any 3 decoders
    D0     : S0;        // Big decoder only
    FPU    : S3(2);
    MEM    : S3;
%}

// Float reg-mem operation
pipe_class fpu_reg_mem(regD dst, memory mem)
%{
    instruction_count(2);
    dst    : S5(write);
    mem    : S3(read);
    D0     : S0;        // big decoder only
    DECODE : S1;        // any decoder for FPU POP
    FPU    : S4;
    MEM    : S3;        // any mem
%}

// Float reg-mem operation
pipe_class fpu_reg_reg_mem(regD dst, regD src1, memory mem)
%{
    instruction_count(3);
    dst    : S5(write);
    src1   : S3(read);
    mem    : S3(read);
    D0     : S0;        // big decoder only
    DECODE : S1(2);     // any decoder for FPU POP
    FPU    : S4;
    MEM    : S3;        // any mem
%}

// Float mem-reg operation
pipe_class fpu_mem_reg(memory mem, regD src)
%{
    instruction_count(2);
    src    : S5(read);
    mem    : S3(read);
    DECODE : S0;        // any decoder for FPU PUSH
    D0     : S1;        // big decoder only
    FPU    : S4;
    MEM    : S3;        // any mem
%}

pipe_class fpu_mem_reg_reg(memory mem, regD src1, regD src2)
%{
    instruction_count(3);
    src1   : S3(read);
    src2   : S3(read);
    mem    : S3(read);
    DECODE : S0(2);     // any decoder for FPU PUSH
    D0     : S1;        // big decoder only
    FPU    : S4;
    MEM    : S3;        // any mem
%}

pipe_class fpu_mem_reg_mem(memory mem, regD src1, memory src2)
%{
    instruction_count(3);
    src1   : S3(read);
    src2   : S3(read);
    mem    : S4(read);
    DECODE : S0;        // any decoder for FPU PUSH
    D0     : S0(2);     // big decoder only
    FPU    : S4;
    MEM    : S3(2);     // any mem
%}

pipe_class fpu_mem_mem(memory dst, memory src1)
%{
    instruction_count(2);
    src1   : S3(read);
    dst    : S4(read);
    D0     : S0(2);     // big decoder only
    MEM    : S3(2);     // any mem
%}

pipe_class fpu_mem_mem_mem(memory dst, memory src1, memory src2)
%{
    instruction_count(3);
    src1   : S3(read);
    src2   : S3(read);
    dst    : S4(read);
    D0     : S0(3);     // big decoder only
    FPU    : S4;
    MEM    : S3(3);     // any mem
%}

pipe_class fpu_mem_reg_con(memory mem, regD src1)
%{
    instruction_count(3);
    src1   : S4(read);
    mem    : S4(read);
    DECODE : S0;        // any decoder for FPU PUSH
    D0     : S0(2);     // big decoder only
    FPU    : S4;
    MEM    : S3(2);     // any mem
%}

// Float load constant
pipe_class fpu_reg_con(regD dst)
%{
    instruction_count(2);
    dst    : S5(write);
    D0     : S0;        // big decoder only for the load
    DECODE : S1;        // any decoder for FPU POP
    FPU    : S4;
    MEM    : S3;        // any mem
%}

// Float load constant
pipe_class fpu_reg_reg_con(regD dst, regD src)
%{
    instruction_count(3);
    dst    : S5(write);
    src    : S3(read);
    D0     : S0;        // big decoder only for the load
    DECODE : S1(2);     // any decoder for FPU POP
    FPU    : S4;
    MEM    : S3;        // any mem
%}

// UnConditional branch
pipe_class pipe_jmp(label labl)
%{
    single_instruction;
    BR   : S3;
%}

// Conditional branch
pipe_class pipe_jcc(cmpOp cmp, rFlagsReg cr, label labl)
%{
    single_instruction;
    cr    : S1(read);
    BR    : S3;
%}

// Allocation idiom
pipe_class pipe_cmpxchg(rRegP dst, rRegP heap_ptr)
%{
    instruction_count(1); force_serialization;
    fixed_latency(6);
    heap_ptr : S3(read);
    DECODE   : S0(3);
    D0       : S2;
    MEM      : S3;
    ALU      : S3(2);
    dst      : S5(write);
    BR       : S5;
%}

// Generic big/slow expanded idiom
pipe_class pipe_slow()%{
    instruction_count(10); multiple_bundles; force_serialization;
    fixed_latency(100);
    D0  : S0(2);
    MEM : S3(2);
%}

// The real do-nothing guy
pipe_class empty()%{
    instruction_count(0);
%}

// Define the class for the Nop node
define
%{
   MachNop = empty;
%}

%}

//----------INSTRUCTIONS-------------------------------------------------------
//
// match      -- States which machine-independent subtree may be replaced
//               by this instruction.
// ins_cost   -- The estimated cost of this instruction is used by instruction
//               selection to identify a minimum cost tree of machine
//               instructions that matches a tree of machine-independent
//               instructions.

//----------Load/Store/Move Instructions---------------------------------------
//----------Load Instructions--------------------------------------------------

// Load Byte (8 bit signed)
instruct loadB(rRegI dst,memory mem)%{
  match(Set dst (LoadB mem));
  ins_cost(125);
  emit %{  __ lds1($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

// Load Byte (8 bit signed) into Long Register
instruct loadB2L(rRegL dst,memory mem)%{
match(Set dst(ConvI2L(LoadB mem)));
  ins_cost(125);
  emit %{  __ lds1($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

// Load Short (16 bit signed)
instruct loadS(rRegI dst,memory mem)%{
  match(Set dst (LoadS mem));
  ins_cost(125);
  emit %{  __ lds2($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

// Load Short (16 bit signed) to Byte (8 bit signed)
instruct loadS2B(rRegI dst,memory mem,immI_24 twentyfour)%{
  match(Set dst (RShiftI (LShiftI (LoadS mem) twentyfour) twentyfour));
  ins_cost(125);
  emit %{  __ lds1($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

// Load Short (16 bit signed) into Long Register
instruct loadS2L(rRegL dst,memory mem)%{
match(Set dst(ConvI2L(LoadS mem)));
  ins_cost(125);
  emit %{  __ lds2($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

// Load Char (16 bit UNsigned)
instruct loadC(rRegI dst,memory mem)%{
  match(Set dst (LoadC mem));
  ins_cost(125);
  emit %{  __ ldz2($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

// Load Integer
instruct loadI(rRegI dst,memory mem)%{
  match(Set dst (LoadI mem));
  ins_cost(125);
  emit %{  __ ldz4($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

// Load Integer (32 bit signed) to Byte (8 bit signed)
instruct loadI2B(rRegI dst,memory mem,immI_24 twentyfour)%{
  match(Set dst (RShiftI (LShiftI (LoadI mem) twentyfour) twentyfour));
  ins_cost(125);
  emit %{  __ lds1($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

// Load Integer (32 bit signed) to Unsigned Byte (8 bit UNsigned)
instruct loadI2UB(rRegI dst,memory mem,immI_255 mask)%{
match(Set dst(AndI(LoadI mem)mask));
  ins_cost(125);
  emit %{ __ ldz1($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale); %}
  ins_pipe(ialu_reg_mem);
%}

// Load Integer (32 bit signed) to Short (16 bit signed)
instruct loadI2S(rRegI dst,memory mem,immI_16 sixteen)%{
  match(Set dst (RShiftI (LShiftI (LoadI mem) sixteen) sixteen));
  ins_cost(125);
  emit %{  __ lds2($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

// Load Integer (32 bit signed) to Unsigned Short/Char (16 bit UNsigned)
instruct loadI2US(rRegI dst,memory mem,immI_65535 mask)%{
match(Set dst(AndI(LoadI mem)mask));
  ins_cost(125);
  emit %{  __ ldz2($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

// Load Integer into Long Register
instruct loadI2L(rRegL dst,memory mem)%{
match(Set dst(ConvI2L(LoadI mem)));
  ins_cost(125);
  emit %{  __ lds4($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

// Load Integer with mask 0xFF into Long Register
instruct loadI2L_immI_255(rRegL dst,memory mem,immI_255 mask)%{
  match(Set dst (ConvI2L (AndI (LoadI mem) mask)));
  emit %{ __ ldz1($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale ); %}
  ins_pipe(ialu_reg_mem);
%}

// Load Integer with mask 0xFFFF into Long Register
instruct loadI2L_immI_65535(rRegL dst,memory mem,immI_65535 mask)%{
  match(Set dst (ConvI2L (AndI (LoadI mem) mask)));
  emit %{ __ ldz2($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale ); %}
  ins_pipe(ialu_reg_mem);
%}

// Load Integer with a 32-bit mask into Long Register
instruct loadI2L_immI(rRegL dst, memory mem, immI mask, rFlagsReg cr) %{
  match(Set dst (ConvI2L (AndI (LoadI mem) mask)));
  effect(KILL cr);
  emit %{
    __ ldz4($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);
    __ and8i($dst$,$mask$);
  %}
  ins_pipe(ialu_reg_mem);
%}

// Load Long
instruct loadL(rRegL dst,memory mem)%{
  match(Set dst (LoadL mem));
  ins_cost(125);
  emit %{  __ ld8($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem); 
%}

// Load Range
instruct loadRange(rRegI dst,memory mem)%{
  match(Set dst (LoadRange mem));
  ins_cost(125);
  emit %{  __ ldz4($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

instruct loadRange_convI2L(rRegI dst,memory mem)%{
match(Set dst(ConvI2L(LoadRange mem)));
  predicate( n->in(1)->bottom_type()->is_int()->_lo >= 0 );
  ins_cost(125);
  emit %{ __ ldz4($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

// Load Pointer
instruct loadP(rRegP dst,memory mem)%{
  match(Set dst (LoadP mem));
  ins_cost(125);
  emit %{  __ ld8($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

// Load Klass Pointer
instruct loadKlass(rRegP dst,memory mem)%{
  match(Set dst (LoadKlass mem));
  ins_cost(150);
  emit %{  
    if( bottom_type()->is_klassptr()->_is_kid ) {
      // Loading a KID actually, not a klass pointer - and not from an object header.
      // Use GetKID on object headers.
      __ ldz4($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  
    } else
      __ ld8($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  
  %}
ins_pipe(ialu_reg_mem);
%}


// Load KID and cast
instruct loadKlass_castP2X(rRegL dst,memory mem)%{
match(Set dst(CastP2X(LoadKlass mem)));
  predicate( n->in(1)->bottom_type()->is_klassptr()->_is_kid );
  ins_cost(150);
  emit %{ __ ldz4($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

instruct kid2klass(rRegP dst, rRegP kid) %{
match(Set dst(KID2Klass kid));
  ins_cost(125); 
  emit %{  __ ld8($dst$, noreg, (intptr_t)KlassTable::getKlassTableBase(), $kid$, 3); %}
  ins_pipe(ialu_reg_mem); 
%}

// Load Float
instruct loadF(regF dst,memory mem)%{
  match(Set dst (LoadF mem));
  ins_cost(145); 
  emit %{  __ ld4((FRegister)$dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
ins_pipe(fpu_reg_mem);
%}

instruct loadD(regD dst,memory mem)%{
  match(Set dst (LoadD mem));
  ins_cost(145);
  emit %{  __ ld8((FRegister)$dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
ins_pipe(fpu_reg_mem);
%}

// Load Aligned Packed Byte to XMM register
instruct loadA8B(regD dst, memory mem) %{
  match(Set dst (Load8B mem));
  ins_cost(125);

  //emit( movq_ld(dst, mem));
  ins_pipe( pipe_slow );
%}

// Load Aligned Packed Short to XMM register
instruct loadA4S(regD dst, memory mem) %{
  match(Set dst (Load4S mem));
  ins_cost(125);

  //emit( movq_ld(dst, mem));
  ins_pipe( pipe_slow );
%}

// Load Aligned Packed Char to XMM register
instruct loadA4C(regD dst, memory mem) %{
  match(Set dst (Load4C mem));
  ins_cost(125);

  //emit( movq_ld(dst, mem));
  ins_pipe( pipe_slow );
%}

// Load Aligned Packed Integer to XMM register
instruct load2IU(regD dst, memory mem) %{
  match(Set dst (Load2I mem));
  ins_cost(125);

  //emit( movq_ld(dst, mem));
  ins_pipe( pipe_slow );
%}

// Load Aligned Packed Single to XMM
instruct loadA2F(regD dst, memory mem) %{
  match(Set dst (Load2F mem));
  ins_cost(145);

  //emit( movq_ld(dst, mem));
  ins_pipe( pipe_slow );
%}

// Load Effective Address
instruct leaP8(rRegP dst,indOffset8 mem)%{
  match(Set dst mem);
  ins_cost(110); 
  emit %{  __ lea($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_reg_fat);
%}

instruct leaP32(rRegP dst,indOffset32 mem)%{
  match(Set dst mem);
  ins_cost(110);
  emit %{  __ lea($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_reg_fat);
%}

instruct leaPIdx(rRegP dst,indIndex mem)%{
  match(Set dst mem);
  ins_cost(110);
  emit %{  __ lea($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_reg_fat);
%}

instruct leaPIdxOff(rRegP dst,indIndexOffset mem)%{
  match(Set dst mem);
  ins_cost(110);
  emit %{  __ lea($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_reg_fat);
%}

instruct leaPIdxScale(rRegP dst,indIndexScale mem)%{
  match(Set dst mem);
  ins_cost(110);
  emit %{  __ lea($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_reg_fat);
%}

instruct leaPIdxScaleOff(rRegP dst,indIndexScaleOffset mem)%{
match(Set dst mem);
ins_cost(110);
  emit %{  __ lea($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_reg_fat);
%}

instruct leaPPosIdxScaleOff(rRegP dst,indPosIndexScaleOffset mem)%{
match(Set dst mem);
ins_cost(110);
  emit %{  __ lea($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_reg_fat);
%}

instruct leaLIdxScaleOff(rRegL dst, immL32 off, rRegL index, immI2 scale) %{
  match(Set dst (AddL (LShiftL index scale) off));
  ins_cost(110);
  emit %{  __ lea($dst$, noreg, $off$, $index$, $scale$);  %}
  ins_pipe(ialu_reg_reg_fat);
%}

instruct leaLIdxIScale(rRegL dst, rRegI index, immI2 scale) %{
match(Set dst(LShiftL(ConvI2L index)scale));
  predicate( n->in(1)->in(1)->bottom_type()->is_int()->_lo >= 0 );
  emit %{ __ lea($dst$,noreg,0,$index$,$scale$); %}
  ins_pipe(ialu_reg_reg);
%}

instruct leaLIdxIScaleOff(rRegL dst, immL32 off, rRegI index, immI2 scale) %{
  match(Set dst (AddL (LShiftL (ConvI2L index) scale) off));
  predicate( n->in(1)->in(1)->in(1)->bottom_type()->is_int()->_lo >= 0 );
  emit %{ __ lea($dst$,noreg,$off$,$index$,$scale$); %}
  ins_pipe(ialu_reg_reg);
%}


instruct loadConI(rRegI dst,immI src)%{
  match(Set dst src);
  emit %{ __ mov8u($dst$,(uint32_t)($src$),false); %}
ins_pipe(ialu_reg_fat);
%}

instruct loadConI0(rRegI dst,immI0 src,rFlagsReg cr)%{
  match(Set dst src);
  effect(KILL cr);
  ins_cost(50);
  emit %{ __ mov8u($dst$,0,true); %}
  ins_pipe(ialu_reg);
%}

instruct loadConI0_expand(rRegI dst,rFlagsRegU cr)%{
effect(DEF dst,KILL cr);
  emit %{ __ mov8u($dst$,0,true); %}
  ins_pipe(ialu_reg);
%}

instruct loadConL(rRegL dst,immL src)%{
  match(Set dst src);
  ins_cost(150);
  emit %{ __ mov8i( $dst$, $src$, false); %}
  ins_pipe(ialu_reg);
%}

instruct loadConL0(rRegL dst,immL0 src,rFlagsReg cr)%{
  match(Set dst src);
  effect(KILL cr);
  emit %{ __ mov8i( $dst$, 0, true/*can blow flags*/); %}
  ins_cost(50);
  ins_pipe(ialu_reg); // XXX
%}

instruct loadConUL32(rRegL dst,immUL32 src)%{
  match(Set dst src);
  ins_cost(60);
  emit %{ __ mov8u($dst$,$src$,false/*cannot blow flags*/); %}
  ins_pipe(ialu_reg);
%}

instruct loadConL32(rRegL dst,immL32 src)%{
  match(Set dst src);
  ins_cost(70);
  emit %{ __ mov8i( $dst$, $src$, false/*cannot blow flags*/); %}
  ins_pipe(ialu_reg);
%}

instruct loadConP0(rRegP dst,immP0 src,rFlagsReg cr)%{
  match(Set dst src);
  effect(KILL cr);
  ins_cost(50);
  emit %{ __ mov8u($dst$,0,true); %}
  ins_pipe(ialu_reg);
%}

instruct loadConP(rRegP dst,immP src)%{
  match(Set dst src);
  emit %{  
    const TypeKlassPtr *k1 = bottom_type()->isa_klassptr();
    if( k1 && k1->_is_kid ) {
      const int idx = ((ciKlass*)k1->const_oop())->klassId();
      __ mov8i($dst$,(int32_t)idx,false);
      __ record_constant_oop(idx);
    } else if( bottom_type()->isa_rawptr() ) {
      __ mov8i($dst$,bottom_type()->is_rawptr()->get_con(),false);
    } else if( bottom_type()->isa_oopptr() ) {
      const TypeOopPtr *to = bottom_type()->is_oopptr();
ciObject*cio=to->const_oop();
      const int idx = cio->is_klass() ? ((ciKlass*)cio)->klassId() : ciEnv::get_OopTable_index(cio->encoding());
      __ ld8($dst$, (address)KlassTable::getKlassTableBase()+(idx<<3));  
      __ record_constant_oop(idx);
    } else {
      assert0( bottom_type()->isa_ptr() );
      __ mov8i($dst$,bottom_type()->is_ptr()->get_con(),false);
    }
  %}
  ins_pipe(ialu_reg_mem);
%}

instruct loadConF(regF dst,immF src,rRegI tmp)%{
  match(Set dst src);
  effect(TEMP tmp);
  ins_cost(125);
  emit %{ __ float_constant((FRegister)$dst$,$src$,$tmp$); %}
  ins_pipe(pipe_slow);
%}

instruct loadConF0(regF dst,immF0 src)%{
  match(Set dst src);
  ins_cost(100);
  emit %{ __ xorf((FRegister)$dst$,(FRegister)$dst$); %}
ins_pipe(fpu_reg_reg);
%}

instruct loadConDgpr(rRegL gpr,immD src)%{
effect(DEF gpr,USE src);
  emit %{ 
    double d = $src$;
    __ mov8i($gpr$,*(int64*)&d, false /*cannot blow flags*/);
  %}
ins_pipe(ialu_reg);
%}

instruct MoveL2D_reg_reg(regD dst, rRegL src) %{
  match(Set dst (MoveL2D src));
  effect(DEF dst, USE src);
  ins_cost(300);
  emit %{ __ mov8((FRegister)$dst$,$src$); %}
  ins_pipe( pipe_slow );
%}

instruct loadConD(regD dst,immD src)%{
  match(Set dst src);
  effect( DEF dst, USE src );
  ins_cost(125);
  expand %{
rRegL tmp;
loadConDgpr(tmp,src);
MoveL2D_reg_reg(dst,tmp);
  %}
%}

instruct loadConD_mem(regD dst,immD_mem src)%{
  match(Set dst src);
  ins_cost(100);
  emit %{ __ double_constant((FRegister)$dst$,$src$,RAX/*unused*/); %}
  ins_pipe(fpu_reg_reg);
%}

instruct loadConD0(regD dst,immD0 src)%{
  match(Set dst src);
  ins_cost(100);
  emit %{ __ xord((FRegister)$dst$,(FRegister)$dst$); %}
  ins_pipe(fpu_reg_reg);
%}

instruct loadSSI(rRegI dst, stackSlotI src)
%{
  match(Set dst src);

  ins_cost(125);

  //  emit(REX_reg_mem(dst, src), OpcP, reg_mem(dst, src));
  ins_pipe(ialu_reg_mem);
%}

instruct loadSSL(rRegL dst, stackSlotL src)
%{
  match(Set dst src);

  ins_cost(125);

  //  emit(REX_reg_mem_wide(dst, src), OpcP, reg_mem(dst, src));
  ins_pipe(ialu_reg_mem);
%}

instruct loadSSP(rRegP dst, stackSlotP src)
%{
  match(Set dst src);

  ins_cost(125);

  //  emit(REX_reg_mem_wide(dst, src), OpcP, reg_mem(dst, src));
  ins_pipe(ialu_reg_mem);
%}

instruct loadSSF(regF dst, stackSlotF src)
%{
  match(Set dst src);

  ins_cost(125);

//  emit(OpcP, REX_reg_mem(dst, src), OpcS, OpcT, reg_mem(dst, src));
  ins_pipe(pipe_slow); // XXX
%}



// Prefetch instructions.
// Must be safe to execute with invalid address (cannot fault).
instruct prefetchr( memory mem ) %{
  match(PrefetchRead mem);
  ins_cost(125);
  emit %{ 
    if( $mem$$index != noreg )
      __ prefetch0($mem$$base,$mem$$disp, $mem$$index, $mem$$scale);
    else
      __ prefetch0($mem$$base,$mem$$disp); 
  %}
  ins_pipe(ialu_mem);
%}

instruct prefetchwT0( memory mem ) %{
  match(PrefetchWrite mem);
  ins_cost(125);
  emit %{ 
    if( $mem$$index != noreg ) 
      __ prefetchnta($mem$$base,$mem$$disp, $mem$$index, $mem$$scale);
    else
      __ prefetchnta($mem$$base,$mem$$disp); 
  %}
  ins_pipe(ialu_mem);
%}

//----------Store Instructions-------------------------------------------------

// Store Byte
instruct storeB(memory mem,rRegI src)%{
  match(Set mem (StoreB mem src));
  ins_cost(125);
  emit %{  __ st1($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,$src$);  %}
  ins_pipe(ialu_mem_reg);
%}

// Store Char/Short
instruct storeC(memory mem,rRegI src)%{
  match(Set mem (StoreC mem src));
  ins_cost(125);
  emit %{  __ st2($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,$src$);  %}
  ins_pipe(ialu_mem_reg);
%}

// Store Integer
instruct storeI(memory mem,rRegI src)%{
  match(Set mem (StoreI mem src));
  ins_cost(125);
  emit %{  __ st4($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,$src$);  %}
  ins_pipe(ialu_mem_reg);
%}

// Store Long
instruct storeL(memory mem,rRegL src)%{
  match(Set mem (StoreL mem src));
  emit %{  __ st8($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,$src$);  %}
ins_cost(125);
ins_pipe(ialu_mem_reg);
%}

// Store Pointer- oop into the heap
instruct store_oop_into_heap(memory mem, any_RegP src, rRegP tmp1, rRegP tmp2, rFlagsReg cr) %{
  predicate( n->in(MemNode::Address)->bottom_type()->isa_oopptr() != NULL );
  match(Set mem (StoreP mem src));
  effect( KILL cr, TEMP tmp1, TEMP tmp2 );
ins_cost(500);
  emit %{
    if( UseSBA ) Unimplemented();
Label do_store;
    __ pre_write_barrier( RInOuts::a, $tmp1$, $tmp2$, 
                          RKeepIns::a, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale,$src$,
                          do_store );
__ bind(do_store);
    if ( RefPoisoning ) {
      __ move8($tmp1$,$src$);
      __ poison($tmp1$);            
      __ st8($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,$tmp1$);
    } else {
      __ st8($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,$src$);
    }
  %}
  ins_pipe(ialu_mem_reg);
%}

// Store Pointer- oop into the non-heap
instruct store_oop_into_other(memory mem,any_RegP src)%{
  predicate( n->in(MemNode::Address)->bottom_type()->isa_oopptr() == NULL );
match(Set mem(StoreP mem src));
ins_cost(125);
  emit %{
    __ st8 ($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,$src$);
  %}
  ins_pipe(ialu_mem_reg);
%}

// Store NULL Pointer, mark word, or other simple pointer constant.
instruct storeImmP(memory mem,immP31 src)%{
  match(Set mem (StoreP mem src));
  ins_cost(150);
  emit %{  __ st8i($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,$src$);  %}
  ins_pipe(ialu_mem_imm);
%}

instruct storeImmL(memory mem,immL32 src)%{
match(Set mem(StoreL mem src));
  ins_cost(150);
  emit %{  __ st8i($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,$src$);  %}
  ins_pipe(ialu_mem_imm);
%}

instruct storeImmI(memory mem,immI src)%{
match(Set mem(StoreI mem src));
  ins_cost(150);
  emit %{  __ st4i($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,$src$);  %}
  ins_pipe(ialu_mem_imm);
%}

instruct storeImmI16(memory mem,immI16 src)%{
  match(Set mem (StoreC mem src));
  ins_cost(150);
  emit %{  __ st2i($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,$src$);  %}
  ins_pipe(ialu_mem_imm);
%}

instruct storeImmB(memory mem,immI8 src)%{
  match(Set mem (StoreB mem src));
  ins_cost(150);
  emit %{  __ st1i($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,$src$);  %}
  ins_pipe(ialu_mem_imm);
%}

// Store Aligned Packed Byte XMM register to memory
instruct storeA8B(memory mem, regD src) %{
  match(Set mem (Store8B mem src));
  ins_cost(145);

//  emit( movq_st(mem, src));
  ins_pipe( pipe_slow );
%}

// Store Aligned Packed Char/Short XMM register to memory
instruct storeA4C(memory mem, regD src) %{
  match(Set mem (Store4C mem src));
  ins_cost(145);

//  emit( movq_st(mem, src));
  ins_pipe( pipe_slow );
%}

// Store Aligned Packed Integer XMM register to memory
instruct storeA2I(memory mem, regD src) %{
  match(Set mem (Store2I mem src));
  ins_cost(145);

//  emit( movq_st(mem, src));
  ins_pipe( pipe_slow );
%}

// Store Aligned Packed Single Float XMM register to memory
instruct storeA2F(memory mem, regD src) %{
  match(Set mem (Store2F mem src));
  ins_cost(145);

//  emit( movq_st(mem, src));
  ins_pipe( pipe_slow );
%}

// Store Float
instruct storeF(memory mem,regF src)%{
  match(Set mem (StoreF mem src));
ins_cost(95);
  emit %{  __ st4($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,(FRegister)$src$);  %}
  ins_pipe(ialu_mem_reg);
%}


instruct storeF_imm(memory mem,immF src)%{
  match(Set mem (StoreF mem src));
  ins_cost(50);
  emit %{  
    float f = $src$;
    __ st4i($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,*(int*)&f);
  %}
  ins_pipe(ialu_mem_imm);
%}

// Store Double
instruct storeD(memory mem,regD src)%{
  match(Set mem (StoreD mem src));
  emit %{  __ st8($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,(FRegister)$src$);  %}
ins_pipe(fpu_mem_reg);
%}

instruct storeD_imm0(memory mem,immD0 src)%{
  match(Set mem (StoreD mem src));
  ins_cost(50);
  emit %{  __ st8i($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,0);  %}
  ins_pipe(ialu_mem_imm);
%}

instruct storeSSI(stackSlotI dst,rRegI src)%{
  match(Set dst src);
  ins_cost(100);
  emit %{ __ st4($dst$$base,$dst$$disp,$src$); %}
  ins_pipe( ialu_mem_reg );
%}

instruct storeSSL(stackSlotL dst,rRegL src)%{
  match(Set dst src);
  ins_cost(100);
  emit %{ __ st8($dst$$base,$dst$$disp,$src$); %}
  ins_pipe(ialu_mem_reg);
%}

instruct storeSSP(stackSlotP dst, rRegP src)
%{
  match(Set dst src);

  ins_cost(100);

//  emit(REX_reg_mem_wide(src, dst), OpcP, reg_mem(src, dst));
  ins_pipe(ialu_mem_reg);
%}

instruct storeSSF(stackSlotF dst, regF src)
%{
  match(Set dst src);

  ins_cost(95); // XXX

//  emit(OpcP, REX_reg_mem(src, dst), OpcS, OpcT, reg_mem(src, dst));
  ins_pipe(pipe_slow); // XXX
%}

instruct storeSSD(stackSlotD dst, regD src)
%{
  match(Set dst src);

  ins_cost(95); // XXX

//  emit(OpcP, REX_reg_mem(src, dst), OpcS, OpcT, reg_mem(src, dst));
  ins_pipe(pipe_slow); // XXX
%}

//----------BSWAP Instructions-------------------------------------------------
instruct bytes_reverse_int(rRegI dst) %{
  match(Set dst (ReverseBytesI dst));
  emit %{ __ bswap4($dst$); %}
  ins_pipe( ialu_reg );
%}

instruct bytes_reverse_long(rRegL dst) %{
  match(Set dst (ReverseBytesL dst));
  emit %{ __ bswap8($dst$); %}
  ins_pipe( ialu_reg);
%}

// instruct loadI_reversed(rRegI dst, memory src) %{
//   match(Set dst (ReverseBytesI (LoadI src)));
// 
// 
// //  emit(REX_reg_mem(dst, src), OpcP, reg_mem(dst, src), REX_reg(dst), OpcS, opc3_reg(dst));
//   ins_pipe( ialu_reg_mem );
// %}
// 
// instruct loadL_reversed(rRegL dst, memory src) %{
//   match(Set dst (ReverseBytesL (LoadL src)));
// 
// 
// //  emit(REX_reg_mem_wide(dst, src), OpcP, reg_mem(dst, src), REX_reg_wide(dst), OpcS, opc3_reg(dst));
//   ins_pipe( ialu_reg_mem );
// %}
// 
// instruct storeI_reversed(memory dst, rRegI src) %{
//   match(Set dst (StoreI dst (ReverseBytesI  src)));
// 
// 
// //  emit( REX_reg(src), OpcP, opc2_reg(src), REX_reg_mem(src, dst), OpcT, reg_mem(src, dst) );
//   ins_pipe( ialu_mem_reg );
// %}
// 
// instruct storeL_reversed(memory dst, rRegL src) %{
//   match(Set dst (StoreL dst (ReverseBytesL  src)));
// 
// 
// //  emit( REX_reg_wide(src), OpcP, opc2_reg(src), REX_reg_mem_wide(src, dst), OpcT, reg_mem(src, dst) );
//   ins_pipe( ialu_mem_reg );
// %}


//---------- Zeros Count Instructions ------------------------------------------

instruct countLeadingZerosI(rRegI dst,rRegI src,rFlagsReg cr)%{
match(Set dst(CountLeadingZerosI src));
  effect(KILL cr);


  emit %{
    Unimplemented();
    //__ lzcntl($dst$, $src$);
  %}
  ins_pipe(ialu_reg);
%}

instruct countLeadingZerosL(rRegI dst,rRegL src,rFlagsReg cr)%{
match(Set dst(CountLeadingZerosL src));
  effect(KILL cr);


  emit %{
    Unimplemented();
    //    __ lzcntq($dst$, $src$);
  %}
  ins_pipe(ialu_reg);
%}

instruct countTrailingZerosI(rRegI dst,rRegI src,rFlagsReg cr)%{
match(Set dst(CountTrailingZerosI src));
  effect(KILL cr);


  emit %{
    Register Rdst = $dst$;
Label done;
    Unimplemented();
//    __ bsfl(Rdst, $src$);
//    __ jccb(Assembler::notZero, done);
//    __ movl(Rdst, BitsPerInt);
//    __ bind(done);
  %}
  ins_pipe(ialu_reg);
%}

instruct countTrailingZerosL(rRegI dst,rRegL src,rFlagsReg cr)%{
match(Set dst(CountTrailingZerosL src));
  effect(KILL cr);


  emit %{
    Register Rdst = $dst$;
Label done;
    Unimplemented();
//    __ bsfq(Rdst, $src$);
//    __ jccb(Assembler::notZero, done);
//    __ movl(Rdst, BitsPerLong);
//    __ bind(done);
  %}
  ins_pipe(ialu_reg);
%}


//---------- Population Count Instructions -------------------------------------

instruct popCountI(rRegI dst,rRegI src)%{
match(Set dst(PopCountI src));


  emit %{
    Unimplemented();
    //    __ popcntl($dst$, $src$);
  %}
  ins_pipe(ialu_reg);
%}

instruct popCountI_mem(rRegI dst,memory mem)%{
match(Set dst(PopCountI(LoadI mem)));


  emit %{
    Unimplemented();
  %}
  ins_pipe(ialu_reg);
%}

// Note: Long.bitCount(long) returns an int.
instruct popCountL(rRegI dst,rRegL src)%{
match(Set dst(PopCountL src));


  emit %{
    Unimplemented();
    //    __ popcntq($dst$, $src$);
  %}
  ins_pipe(ialu_reg);
%}

// Note: Long.bitCount(long) returns an int.
instruct popCountL_mem(rRegI dst,memory mem)%{
match(Set dst(PopCountL(LoadL mem)));


  emit %{
    Unimplemented();
  %}
  ins_pipe(ialu_reg);
%}


//----------MemBar Instructions-----------------------------------------------
// Memory barrier flavors

// On X86, strong memory ordering means this is a nop
instruct membar_acquire() %{
  match(MemBarAcquire);
  ins_cost(0);
  emit %{ ; %}
  ins_pipe(empty);
%}

// On X86, strong memory ordering means this is a nop
instruct membar_release() %{
  match(MemBarRelease);
  ins_cost(0);
  emit %{ ; %}
  ins_pipe(empty);
%}

instruct membar_volatile(rFlagsReg cr)%{
  match(MemBarVolatile);
  effect(KILL cr);
  ins_cost(400);
  emit %{ __ mfence(); // StoreLoad %}
  ins_pipe(pipe_slow);
%}

instruct membar_cpuorder()%{
match(MemBarCPUOrder);
ins_cost(0);
  emit %{ ; %}
  ins_pipe(empty);
%}

instruct unnecessary_membar_volatile() %{
  match(MemBarVolatile);
  predicate(Matcher::post_store_load_barrier(n));
  ins_cost(0);
  emit %{ ; %}
  ins_pipe(empty);
%}

//----------Move Instructions--------------------------------------------------
instruct castL2P(rRegP dst,rRegL src)%{
  match(Set dst (CastX2P src));
emit%{__ move8($dst$,$src$);%}
ins_pipe(ialu_reg_reg);
%}

instruct castP2L(rRegL dst,rRegP src)%{
  match(Set dst (CastP2X src));
  emit %{ __ move8($dst$,$src$); %}
  ins_pipe(ialu_reg_reg);
%}

instruct castKID2L(rRegL dst,rRegP kid)%{
match(Set dst(CastP2X kid));
  predicate( n->in(1)->bottom_type()->isa_klassptr() &&
             n->in(1)->bottom_type()-> is_klassptr()->_is_kid );
  emit %{ __ move4($dst$,$kid$); %}
  ins_pipe(ialu_reg_reg);
%}


//----------Conditional Move---------------------------------------------------
// Jump Table.  The table follows in icache memory.
instruct jumpXtnd(rRegI switch_val,label table_label)%{
  match(Jump switch_val);
effect(USE table_label);
  ins_cost(350);
  emit %{  __ jmp8(noreg, $table_label$, $switch_val$, 3);  %}
  ins_pipe(pipe_jmp);
%}

// Conditional move
instruct cmovI_reg(cmpOp cop,rFlagsReg cr,rRegI dst,rRegI src)%{
  match(Set dst (CMoveI (Binary cop cr) (Binary dst src)));
  ins_cost(200); 
  emit %{ 
    switch( $cop$ ) {
    case BoolTest::eq:  __ cmov4eq($dst$,$src$);  break;
    case BoolTest::ne:  __ cmov4ne($dst$,$src$);  break;
    case BoolTest::lt:  __ cmov4lt($dst$,$src$);  break;
    case BoolTest::gt:  __ cmov4gt($dst$,$src$);  break;
    case BoolTest::le:  __ cmov4le($dst$,$src$);  break;
    case BoolTest::ge:  __ cmov4ge($dst$,$src$);  break;
    default: ShouldNotReachHere();
    }
  %}
  ins_pipe(pipe_cmov_reg);
%}

instruct cmovI_regU(cmpOpU cop,rFlagsRegU cr,rRegI dst,rRegI src)%{
  match(Set dst (CMoveI (Binary cop cr) (Binary dst src)));
  ins_cost(200);
  emit %{ 
    switch( $cop$ ) {
    case BoolTest::eq:  __ cmov4eq($dst$,$src$);  break;
    case BoolTest::ne:  __ cmov4ne($dst$,$src$);  break;
    case BoolTest::lt:  __ cmov4bl($dst$,$src$);  break;
    case BoolTest::gt:  __ cmov4ab($dst$,$src$);  break;
    case BoolTest::le:  __ cmov4be($dst$,$src$);  break;
    case BoolTest::ge:  __ cmov4ae($dst$,$src$);  break;
    default: ShouldNotReachHere();
    }
  %}
  ins_pipe(pipe_cmov_reg);
%}

instruct cmovI_regUCF(cmpOpUCF cop,rFlagsRegUCF cr,rRegI dst,rRegI src)%{
  match(Set dst (CMoveI (Binary cop cr) (Binary dst src)));
  ins_cost(200);
  expand %{
    cmovI_regU(cop, cr, dst, src);
  %}
%}

// Conditional move
instruct cmovI_mem(cmpOp cop,rFlagsReg cr,rRegI dst,memory src)%{
  match(Set dst (CMoveI (Binary cop cr) (Binary dst (LoadI src))));
ins_cost(250);
  emit %{ 
    switch( $cop$ ) {
    case BoolTest::eq:  __ cmov4eq($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    case BoolTest::ne:  __ cmov4ne($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    case BoolTest::lt:  __ cmov4lt($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    case BoolTest::gt:  __ cmov4gt($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    case BoolTest::le:  __ cmov4le($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    case BoolTest::ge:  __ cmov4ge($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    default: ShouldNotReachHere();
    }
  %}
  ins_pipe(pipe_cmov_mem);
%}

// Conditional move
instruct cmovI_memU(cmpOpU cop, rFlagsRegU cr, rRegI dst, memory src)
%{
  match(Set dst (CMoveI (Binary cop cr) (Binary dst (LoadI src))));
ins_cost(250);
  emit %{ 
    switch( $cop$ ) {
    case BoolTest::eq:  __ cmov4eq($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    case BoolTest::ne:  __ cmov4ne($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    case BoolTest::lt:  __ cmov4bl($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    case BoolTest::gt:  __ cmov4ab($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    case BoolTest::le:  __ cmov4be($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    case BoolTest::ge:  __ cmov4ae($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    default: ShouldNotReachHere();
    }
  %}
  ins_pipe(pipe_cmov_mem);
%}

instruct cmovI_memUCF(cmpOpUCF cop,rFlagsRegUCF cr,rRegI dst,memory src)%{
  match(Set dst (CMoveI (Binary cop cr) (Binary dst (LoadI src))));
ins_cost(250);
  expand %{
    cmovI_memU(cop, cr, dst, src);
  %}
%}

// Conditional move
instruct cmovP_reg(rRegP dst,rRegP src,rFlagsReg cr,cmpOp cop)%{
  match(Set dst (CMoveP (Binary cop cr) (Binary dst src)));
  ins_cost(200);
  emit %{
    switch( $cop$ ) {
    case BoolTest::eq:  __ cmov8eq($dst$,$src$);  break;
    case BoolTest::ne:  __ cmov8ne($dst$,$src$);  break;
    case BoolTest::lt:  __ cmov8lt($dst$,$src$);  break;
    case BoolTest::gt:  __ cmov8gt($dst$,$src$);  break;
    case BoolTest::le:  __ cmov8le($dst$,$src$);  break;
    case BoolTest::ge:  __ cmov8ge($dst$,$src$);  break;
    default: ShouldNotReachHere();
    }
  %}
  ins_pipe(pipe_cmov_reg);
%}

// Conditional move
instruct cmovP_regU(rRegP dst,rRegP src,rFlagsRegU cr,cmpOpU cop)%{
  match(Set dst (CMoveP (Binary cop cr) (Binary dst src)));
  ins_cost(200);
  emit %{
    switch( $cop$ ) {
    case BoolTest::eq:  __ cmov8eq($dst$,$src$);  break;
    case BoolTest::ne:  __ cmov8ne($dst$,$src$);  break;
    case BoolTest::lt:  __ cmov8bl($dst$,$src$);  break;
    case BoolTest::gt:  __ cmov8ab($dst$,$src$);  break;
    case BoolTest::le:  __ cmov8be($dst$,$src$);  break;
    case BoolTest::ge:  __ cmov8ae($dst$,$src$);  break;
    default: ShouldNotReachHere();
    }
  %}
  ins_pipe(pipe_cmov_reg);
%}

instruct cmovP_regUCF(cmpOpUCF cop,rFlagsRegUCF cr,rRegP dst,rRegP src)%{
  match(Set dst (CMoveP (Binary cop cr) (Binary dst src)));
  ins_cost(200);
  expand %{
    cmovP_regU(cop, cr, dst, src);
  %}
%}

// DISABLED: Requires the ADLC to emit a bottom_type call that
// correctly meets the two pointer arguments; one is an incoming
// register but the other is a memory operand.  ALSO appears to
// be buggy with implicit null checks.
//
//// Conditional move
//instruct cmovP_mem(cmpOp cop, rFlagsReg cr, rRegP dst, memory src)
//%{
//  match(Set dst (CMoveP (Binary cop cr) (Binary dst (LoadP src))));
//  ins_cost(250);

////  emit( enc_cmov(cop), reg_mem( dst, src ) );
//  ins_pipe( pipe_cmov_mem );
//%}
//
//// Conditional move
//instruct cmovP_memU(cmpOpU cop, rFlagsRegU cr, rRegP dst, memory src)
//%{
//  match(Set dst (CMoveP (Binary cop cr) (Binary dst (LoadP src))));
//  ins_cost(250);

////  emit( enc_cmov(cop), reg_mem( dst, src ) );
//  ins_pipe( pipe_cmov_mem );
//%}

instruct cmovL_reg(cmpOp cop,rFlagsReg cr,rRegL dst,rRegL src)%{
  match(Set dst (CMoveL (Binary cop cr) (Binary dst src)));
ins_cost(250);
  emit %{
    switch( $cop$ ) {
    case BoolTest::eq:  __ cmov8eq($dst$,$src$);  break;
    case BoolTest::ne:  __ cmov8ne($dst$,$src$);  break;
    case BoolTest::lt:  __ cmov8lt($dst$,$src$);  break;
    case BoolTest::gt:  __ cmov8gt($dst$,$src$);  break;
    case BoolTest::le:  __ cmov8le($dst$,$src$);  break;
    case BoolTest::ge:  __ cmov8ge($dst$,$src$);  break;
    default: ShouldNotReachHere();
    }
  %}
  ins_pipe(pipe_cmov_reg);
%}

instruct cmovL_mem(cmpOp cop,rFlagsReg cr,rRegL dst,memory src)%{
  match(Set dst (CMoveL (Binary cop cr) (Binary dst (LoadL src))));
ins_cost(250);
  emit %{ 
    switch( $cop$ ) {
    case BoolTest::eq:  __ cmov8eq($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    case BoolTest::ne:  __ cmov8ne($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    case BoolTest::lt:  __ cmov8lt($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    case BoolTest::gt:  __ cmov8gt($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    case BoolTest::le:  __ cmov8le($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    case BoolTest::ge:  __ cmov8ge($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    default: ShouldNotReachHere();
    }
  %}
  ins_pipe(pipe_cmov_mem);
%}

instruct cmovL_regU(cmpOpU cop,rFlagsRegU cr,rRegL dst,rRegL src)%{
  match(Set dst (CMoveL (Binary cop cr) (Binary dst src)));
ins_cost(250);
  emit %{
    switch( $cop$ ) {
    case BoolTest::eq:  __ cmov8eq($dst$,$src$);  break;
    case BoolTest::ne:  __ cmov8ne($dst$,$src$);  break;
    case BoolTest::lt:  __ cmov8bl($dst$,$src$);  break;
    case BoolTest::gt:  __ cmov8ab($dst$,$src$);  break;
    case BoolTest::le:  __ cmov8be($dst$,$src$);  break;
    case BoolTest::ge:  __ cmov8ae($dst$,$src$);  break;
    default: ShouldNotReachHere();
    }
  %}
  ins_pipe(pipe_cmov_reg);
%}

instruct cmovL_regUCF(cmpOpUCF cop,rFlagsRegUCF cr,rRegL dst,rRegL src)%{
  match(Set dst (CMoveL (Binary cop cr) (Binary dst src)));
  ins_cost(200);
  expand %{
    cmovL_regU(cop, cr, dst, src);
  %}
%}

instruct cmovL_memU(cmpOpU cop,rFlagsRegU cr,rRegL dst,memory src)%{
  match(Set dst (CMoveL (Binary cop cr) (Binary dst (LoadL src))));
ins_cost(250);
  emit %{ 
    switch( $cop$ ) {
    case BoolTest::eq:  __ cmov8eq($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    case BoolTest::ne:  __ cmov8ne($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    case BoolTest::lt:  __ cmov8bl($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    case BoolTest::gt:  __ cmov8ab($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    case BoolTest::le:  __ cmov8be($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    case BoolTest::ge:  __ cmov8ae($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  break;
    default: ShouldNotReachHere();
    }
  %}
  ins_pipe(pipe_cmov_mem);
%}

instruct cmovL_memUCF(cmpOpUCF cop,rFlagsRegUCF cr,rRegL dst,memory src)%{
  match(Set dst (CMoveL (Binary cop cr) (Binary dst (LoadL src))));
  ins_cost(200);
  expand %{
    cmovL_memU(cop, cr, dst, src);
  %}
%}

instruct cmovF_reg(cmpOp cop,rFlagsReg cr,regF dst,regF src)%{
  match(Set dst (CMoveF (Binary cop cr) (Binary dst src)));
  ins_cost(200);
  emit %{
Label done;
    switch( $cop$ ) {
    case BoolTest::eq:  __ jne(done);  break;
    case BoolTest::ne:  __ jeq(done);  break;
    case BoolTest::lt:  __ jge(done);  break;
    case BoolTest::gt:  __ jle(done);  break;
    case BoolTest::le:  __ jgt(done);  break;
    case BoolTest::ge:  __ jlt(done);  break;
    default: ShouldNotReachHere();
    }
    __ mov4((FRegister)$dst$,(FRegister)$src$);
__ bind(done);
  %}
  ins_pipe(pipe_slow);
%}

// instruct cmovF_mem(cmpOp cop, rFlagsReg cr, regF dst, memory src)
// %{
//   match(Set dst (CMoveF (Binary cop cr) (Binary dst (LoadL src))));

//   ins_cost(200); // XXX
//  emit(enc_cmovf_mem_branch(cop, dst, src));
//   ins_pipe(pipe_slow);
// %}

instruct cmovF_regU(cmpOpU cop,rFlagsRegU cr,regF dst,regF src)%{
  match(Set dst (CMoveF (Binary cop cr) (Binary dst src)));
  ins_cost(200);
  emit %{
Label done;
    switch( $cop$ ) {
    case BoolTest::eq:  __ jne(done);  break;
    case BoolTest::ne:  __ jeq(done);  break;
    case BoolTest::lt:  __ jae(done);  break;
    case BoolTest::gt:  __ jbe(done);  break;
    case BoolTest::le:  __ jab(done);  break;
    case BoolTest::ge:  __ jbl(done);  break;
    default: ShouldNotReachHere();
    }
    __ mov4((FRegister)$dst$,(FRegister)$src$);
__ bind(done);
  %}
  ins_pipe(pipe_slow);
%}

instruct cmovF_regUCF(cmpOpUCF cop,rFlagsRegUCF cr,regF dst,regF src)%{
match(Set dst(CMoveF(Binary cop cr)(Binary dst src)));
ins_cost(200);
  expand %{
    cmovF_regU(cop, cr, dst, src);
  %}
%}

instruct cmovD_reg(cmpOp cop,rFlagsReg cr,regD dst,regD src)%{
  match(Set dst (CMoveD (Binary cop cr) (Binary dst src)));
  ins_cost(200);
  emit %{
Label done;
    switch( $cop$ ) {
    case BoolTest::eq:  __ jne(done);  break;
    case BoolTest::ne:  __ jeq(done);  break;
    case BoolTest::lt:  __ jge(done);  break;
    case BoolTest::gt:  __ jle(done);  break;
    case BoolTest::le:  __ jgt(done);  break;
    case BoolTest::ge:  __ jlt(done);  break;
    default: ShouldNotReachHere();
    }
    __ mov8((FRegister)$dst$,(FRegister)$src$);
__ bind(done);
  %}
  ins_pipe(pipe_slow);
%}

instruct cmovD_regU(cmpOpU cop,rFlagsRegU cr,regD dst,regD src)%{
  match(Set dst (CMoveD (Binary cop cr) (Binary dst src)));
  ins_cost(200);
  emit %{
Label done;
    switch( $cop$ ) {
    case BoolTest::eq:  __ jne(done);  break;
    case BoolTest::ne:  __ jeq(done);  break;
    case BoolTest::lt:  __ jae(done);  break;
    case BoolTest::gt:  __ jbe(done);  break;
    case BoolTest::le:  __ jab(done);  break;
    case BoolTest::ge:  __ jbl(done);  break;
    default: ShouldNotReachHere();
    }
    __ mov8((FRegister)$dst$,(FRegister)$src$);
__ bind(done);
  %}
  ins_pipe(pipe_slow);
%}

instruct cmovD_regUCF(cmpOpUCF cop,rFlagsRegUCF cr,regD dst,regD src)%{
  match(Set dst (CMoveD (Binary cop cr) (Binary dst src)));
  ins_cost(200);
  expand %{
    cmovD_regU(cop, cr, dst, src);
  %}
%}

//----------Arithmetic Instructions--------------------------------------------
//----------Addition Instructions----------------------------------------------

instruct addI_rReg(rRegI dst,rRegI src,rFlagsReg cr)%{
  match(Set dst (AddI dst src));
  effect(KILL cr);
  emit %{ __ add4($dst$,$src$);  %}
  ins_pipe(ialu_reg_reg);
%}

instruct addI_rReg_imm(rRegI dst,immI src,rFlagsReg cr)%{
  match(Set dst (AddI dst src));
  effect(KILL cr);
  emit %{ __ add4i($dst$,$src$);  %}
  ins_pipe( ialu_reg );
%}

instruct addI_rReg_mem(rRegI dst,memory mem,rFlagsReg cr)%{
match(Set dst(AddI dst(LoadI mem)));
  effect(KILL cr);
  ins_cost(125);
  emit %{ __ add4($dst$,$mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

instruct addI_mem_rReg(memory mem,rRegI src,rFlagsReg cr)%{
match(Set mem(StoreI mem(AddI(LoadI mem)src)));
  effect(KILL cr);
  ins_cost(150);
  emit %{ __ add4($mem$$base,$mem$$disp,$mem$$index,$mem$$scale, $src$);  %}
  ins_pipe(ialu_mem_reg);
%}

instruct addI_mem_imm(memory mem,immI src,rFlagsReg cr)%{
match(Set mem(StoreI mem(AddI(LoadI mem)src)));
  effect(KILL cr);
  ins_cost(125);
  emit %{  __ add4i($mem$$base,$mem$$disp,$mem$$index,$mem$$scale, $src$);  %}
  ins_pipe(ialu_mem_imm);
%}

instruct leaI_rReg_immI(rRegI dst, rRegI src0, immI src1)
%{
  match(Set dst (AddI src0 src1));

  ins_cost(110);

//  emit(Opcode(0x67), REX_reg_reg(dst, src0), OpcP, reg_lea(dst, src0, src1)); // XXX
  ins_pipe(ialu_reg_reg);
%}

instruct addL_rReg(rRegL dst,rRegL src,rFlagsReg cr)%{
  match(Set dst (AddL dst src));
  effect(KILL cr);
  emit %{ __ add8($dst$,$src$);  %}
  ins_pipe(ialu_reg_reg);
%}

instruct addL_rReg_imm(rRegL dst,immL32 src,rFlagsReg cr)%{
  match(Set dst (AddL dst src));
  effect(KILL cr);
  emit %{ __ add8i($dst$,$src$);  %}
  ins_pipe( ialu_reg );
%}

instruct addL_rReg_mem(rRegL dst,memory mem,rFlagsReg cr)%{
match(Set dst(AddL dst(LoadL mem)));
  effect(KILL cr);
  ins_cost(125); 
  emit %{ __ add8($dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

instruct addL_mem_rReg(memory mem,rRegL src,rFlagsReg cr)%{
match(Set mem(StoreL mem(AddL(LoadL mem)src)));
  effect(KILL cr);
  ins_cost(150);
  emit %{ __ add8($mem$$base,$mem$$disp,$mem$$index,$mem$$scale, $src$);  %}
  ins_pipe(ialu_mem_reg);
%}

instruct addL_mem_imm(memory mem,immL32 src,rFlagsReg cr)%{
match(Set mem(StoreL mem(AddL(LoadL mem)src)));
  effect(KILL cr);
  ins_cost(125);
  emit %{  __ add8i($mem$$base,$mem$$disp,$mem$$index,$mem$$scale, $src$);  %}
  ins_pipe(ialu_mem_imm);
%}

instruct leaL_rReg_immL(rRegL dst, rRegL src0, immL32 src1)
%{
  match(Set dst (AddL src0 src1));

  ins_cost(110);

//  emit(REX_reg_reg_wide(dst, src0), OpcP, reg_lea(dst, src0, src1)); // XXX
  ins_pipe(ialu_reg_reg);
%}

instruct addP_rReg(rRegP dst,rRegL src,rFlagsReg cr)%{
  match(Set dst (AddP dst src));
  effect(KILL cr);
  emit %{ __ add8($dst$,$src$);  %}
  ins_pipe(ialu_reg_reg);
%}

instruct addP_rReg_imm(rRegP dst,immL32 src,rFlagsReg cr)%{
  match(Set dst (AddP dst src));
  effect(KILL cr);
  emit %{ __ add8i($dst$,$src$);  %}
  ins_pipe( ialu_reg );
%}

instruct leaP_rReg_imm(rRegP dst, rRegP src0, immL32 src1)
%{
  match(Set dst (AddP src0 src1));

  ins_cost(110);

//  emit(REX_reg_reg_wide(dst, src0), OpcP, reg_lea(dst, src0, src1));// XXX
  ins_pipe(ialu_reg_reg);
%}

instruct checkCastPP(rRegP dst)%{
  match(Set dst (CheckCastPP dst));
  emit %{ ; %}
  ins_pipe(empty);
%}

instruct castPP(rRegP dst)
%{
  match(Set dst (CastPP dst));


//  emit(/* empty encoding */);
  ins_pipe(empty);
%}

instruct castII(rRegI dst)
%{
  match(Set dst (CastII dst));


//  emit(/* empty encoding */);
  ins_cost(0);
  ins_pipe(empty);
%}

// LoadP-locked same as a regular LoadP when used with compare-swap
instruct loadPLocked(rRegP dst, memory mem)
%{
  match(Set dst (LoadPLocked mem));

  ins_cost(125); // XXX

//  emit(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));
  ins_pipe(ialu_reg_mem); // XXX
%}

instruct compareAndSwapP(rFlagsReg cr, memory mem, rax_RegP oldval, rRegP newval, rRegP tmp1, rRegP tmp2) %{
match(Set cr(CompareAndSwapP mem(Binary oldval newval)));
  effect(DEF cr, KILL oldval, TEMP tmp1, TEMP tmp2);
ins_cost(500);
  emit %{
    if( UseSBA ) Unimplemented();
Label do_store;
    __ pre_write_barrier( RInOuts::a, $tmp1$, $tmp2$, 
                          RKeepIns::a, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale,$newval$,
                          do_store );
__ bind(do_store);
    if ( RefPoisoning ) {
      __ move8($tmp1$,$newval$);
      __ poison($tmp1$);
      __ poison($oldval$);
      __ locked()->cas8($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,$tmp1$  ); // implicitly oldval in RAX
__ pushf();
      __ unpoison($oldval$);
__ popf();
    } else {
      __ locked()->cas8($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,$newval$); // implicitly oldval in RAX
    }
  %}
  ins_pipe( pipe_cmpxchg );
%}

instruct compareAndSwapL(rFlagsReg cr, memory mem, rax_RegL oldval, rRegL newval) %{
match(Set cr(CompareAndSwapL mem(Binary oldval newval)));
effect(DEF cr,KILL oldval);
  emit %{
    __ locked()->cas8($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,$newval$); // implicitly oldval in RAX
  %}
  ins_pipe( pipe_cmpxchg );
%}

instruct compareAndSwapI(rFlagsReg cr, memory mem, rax_RegI oldval, rRegI newval) %{
match(Set cr(CompareAndSwapI mem(Binary oldval newval)));
effect(DEF cr,KILL oldval);
  emit %{
    __ locked()->cas4($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,$newval$); // implicitly oldval in RAX
  %}
  ins_pipe( pipe_cmpxchg );
%}


instruct ticks( rax_RegL rax_dst, rdx_RegL rdx, rFlagsReg cr ) %{
match(Set rax_dst(Ticks));
  effect( DEF rax_dst, KILL rdx, KILL cr );
  emit %{ 
__ rdtsc();
    __ shl8i(RDX,32); // high 32 bits of timestamp
    __ or_8 (RAX,RDX);
  %}
  ins_pipe( ialu_reg );
%}


//----------Subtraction Instructions-------------------------------------------

// Integer Subtraction Instructions
instruct subI_rReg(rRegI dst,rRegI src,rFlagsReg cr)%{
  match(Set dst (SubI dst src));
  effect(KILL cr);
  emit %{ __ sub4($dst$,$src$);  %}
  ins_pipe(ialu_reg_reg);
%}

instruct subI_rReg_imm(rRegI dst,immI src,rFlagsReg cr)%{
  match(Set dst (SubI dst src));
  effect(KILL cr);
  emit %{ __ sub4i($dst$,$src$);  %}
  ins_pipe(ialu_reg);
%}

instruct subI_rReg_mem(rRegI dst,memory mem,rFlagsReg cr)%{
match(Set dst(SubI dst(LoadI mem)));
  effect(KILL cr);
  ins_cost(125);
  emit %{ __ sub4($dst$,$mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

instruct subI_mem_rReg(memory mem,rRegI src,rFlagsReg cr)%{
match(Set mem(StoreI mem(SubI(LoadI mem)src)));
  effect(KILL cr);
  ins_cost(150);
  emit %{ __ sub4($mem$$base,$mem$$disp,$mem$$index,$mem$$scale, $src$);  %}
  ins_pipe(ialu_mem_reg);
%}

instruct subI_mem_imm(memory mem,immI src,rFlagsReg cr)%{
match(Set mem(StoreI mem(SubI(LoadI mem)src)));
  effect(KILL cr);
  ins_cost(125);
  emit %{ __ sub4i($mem$$base,$mem$$disp,$mem$$index,$mem$$scale, $src$);  %}
  ins_pipe(ialu_mem_imm);
%}

instruct subL_rReg(rRegL dst,rRegL src,rFlagsReg cr)%{
  match(Set dst (SubL dst src));
  effect(KILL cr);
  emit %{ __ sub8($dst$,$src$);  %}
  ins_pipe(ialu_reg_reg);
%}

instruct subL_rReg_imm(rRegI dst, immL32 src, rFlagsReg cr)
%{
  match(Set dst (SubL dst src));
  effect(KILL cr);


//  emit(OpcSErm_wide(dst, src), Con8or32(src));
  ins_pipe(ialu_reg);
%}

instruct subL_rReg_mem(rRegL dst,memory mem,rFlagsReg cr)%{
match(Set dst(SubL dst(LoadL mem)));
  effect(KILL cr);
  ins_cost(125);
  emit %{ __ sub8($dst$,$mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

instruct subL_mem_rReg(memory dst, rRegL src, rFlagsReg cr)
%{
  match(Set dst (StoreL dst (SubL (LoadL dst) src)));
  effect(KILL cr);
  ins_cost(150);
  emit %{ __ sub8($dst$$base,$dst$$disp, $dst$$index, $dst$$scale, $src$); %}
  ins_pipe(ialu_mem_reg);
%}

instruct subL_mem_imm(memory dst, immL32 src, rFlagsReg cr)
%{
  match(Set dst (StoreL dst (SubL (LoadL dst) src)));
  effect(KILL cr);

  ins_cost(125); // XXX

//  emit(REX_mem_wide(dst),
//             OpcSE(src), RM_opc_mem(0x05, dst), Con8or32(src));
  ins_pipe(ialu_mem_imm);
%}

// Subtract from a pointer
instruct subP_rReg(rRegP dst, rRegI src, immI0 zero, rFlagsReg cr)
%{
  match(Set dst (AddP dst (SubI zero src)));
  effect(KILL cr);


//  emit(REX_reg_reg_wide(dst, src), OpcP, reg_reg(dst, src));
  ins_pipe(ialu_reg_reg);
%}

instruct negI_rReg(rRegI dst,immI0 zero,rFlagsReg cr)%{
  match(Set dst (SubI zero dst));
  effect(KILL cr);
  emit %{ __ neg4($dst$); %}
  ins_pipe(ialu_reg);
%}

instruct negI_mem(memory dst, immI0 zero, rFlagsReg cr)
%{
  match(Set dst (StoreI dst (SubI zero (LoadI dst))));
  effect(KILL cr);
  emit %{ __ neg4($dst$$base,$dst$$disp,$dst$$index,$dst$$scale); %}
  ins_pipe(ialu_reg);
%}

instruct negL_rReg(rRegL dst, immL0 zero, rFlagsReg cr)
%{
  match(Set dst (SubL zero dst));
  effect(KILL cr);
  emit %{ __ neg8($dst$); %}
  ins_pipe(ialu_reg);
%}

instruct negL_mem(memory dst, immL0 zero, rFlagsReg cr)
%{
  match(Set dst (StoreL dst (SubL zero (LoadL dst))));
  effect(KILL cr);
  emit %{ __ neg8($dst$$base,$dst$$disp,$dst$$index,$dst$$scale); %}
  ins_pipe(ialu_reg);
%}


//----------Multiplication/Division Instructions-------------------------------
// Integer Multiplication Instructions
// Multiply Register

instruct mulI_rReg(rRegI dst,rRegI src,rFlagsReg cr)%{
  match(Set dst (MulI dst src));
  effect(KILL cr);
  ins_cost(300);
  emit %{ __ mul4($dst$,$src$);  %}
  ins_pipe(ialu_reg_reg_alu0);
%}

instruct mulI_rReg_imm(rRegI dst, rRegI src, immI imm, rFlagsReg cr) %{
  match(Set dst (MulI src imm));
  effect(KILL cr);
  ins_cost(300);
  emit %{ __ mul4i($dst$,$src$,$imm$);  %}
  ins_pipe(ialu_reg_reg_alu0);
%}

instruct mulI_mem(rRegI dst,memory src,rFlagsReg cr)%{
  match(Set dst (MulI dst (LoadI src)));
  effect(KILL cr);
  ins_cost(350);
  emit %{ __ mul4($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  %}
  ins_pipe(ialu_reg_mem_alu0);
%}

instruct mulI_mem_imm(rRegI dst, memory src, immI imm, rFlagsReg cr) %{
  match(Set dst (MulI (LoadI src) imm));
  effect(KILL cr);
  ins_cost(300);
  emit %{ __ mul4i($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale,$imm$);  %}
  ins_pipe(ialu_reg_mem_alu0);
%}

instruct mulL_rReg(rRegL dst,rRegL src,rFlagsReg cr)%{
  match(Set dst (MulL dst src));
  effect(KILL cr);
  ins_cost(300);
  emit %{ __ mul8($dst$,$src$);  %}
  ins_pipe(ialu_reg_reg_alu0);
%}

instruct mulL_rReg_imm(rRegL dst, rRegL src, immL32 imm, rFlagsReg cr) %{
  match(Set dst (MulL src imm));
  effect(KILL cr);
  ins_cost(300);
  emit %{ __ mul8i($dst$,$src$,$imm$);  %}
  ins_pipe(ialu_reg_reg_alu0);
%}

instruct mulL_mem(rRegL dst,memory src,rFlagsReg cr)%{
  match(Set dst (MulL dst (LoadL src)));
  effect(KILL cr);
  ins_cost(350);
  emit %{ __ mul8($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale); %}
  ins_pipe(ialu_reg_mem_alu0);
%}

instruct mulL_mem_imm(rRegL dst, memory src, immL32 imm, rFlagsReg cr) %{
  match(Set dst (MulL (LoadL src) imm));
  effect(KILL cr);
  ins_cost(300);
  emit %{ __ mul8i($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale,$imm$); %}
  ins_pipe(ialu_reg_mem_alu0);
%}

instruct mulHiL_rReg(rdx_RegL dst, no_rax_RegL src, rax_RegL rax, rFlagsReg cr) %{
match(Set dst(MulHiL src rax));
effect(USE_KILL rax,KILL cr);
  ins_cost(300);
  emit %{ __ mul8($src$); // RAX is implicitly the other source  %}
  ins_pipe(ialu_reg_reg_alu0);
%}

instruct divI_rReg(rax_RegI rax,rdx_RegI rdx,no_rax_rdx_RegI div,rFlagsReg cr)%{
  match(Set rax (DivI rax div));
  effect(KILL rdx, KILL cr);
ins_cost(30*100+10*100);
  emit %{ __ cdq4(); __ div4($div$); %}
  ins_pipe(ialu_reg_reg_alu0);
%}

instruct divL_rReg(rax_RegL rax,rdx_RegL rdx,no_rax_rdx_RegL div,rFlagsReg cr)%{
  match(Set rax (DivL rax div));
  effect(KILL rdx, KILL cr);
ins_cost(30*100+10*100);
  emit %{ __ cdq8(); __ div8($div$); %}
  ins_pipe(ialu_reg_reg_alu0);
%}

// Integer DIVMOD with Register, both quotient and mod results
instruct divModI_rReg_divmod(rax_RegI rax,rdx_RegI rdx,no_rax_rdx_RegI div,rFlagsReg cr)%{
  match(DivModI rax div);
  effect(KILL cr);
ins_cost(30*100+10*100);
  emit %{ __ cdq4(); __ div4($div$); %}
  ins_pipe(pipe_slow);
%}

// Long DIVMOD with Register, both quotient and mod results
instruct divModL_rReg_divmod(rax_RegL rax,rdx_RegL rdx,no_rax_rdx_RegL div,rFlagsReg cr)%{
  match(DivModL rax div);
  effect(KILL cr);
ins_cost(30*100+10*100);
  emit %{ __ cdq8(); __ div8($div$); %}
  ins_pipe(pipe_slow);
%}

//----------- DivL-By-Constant-Expansions--------------------------------------
// DivI cases are handled by the compiler

// Magic constant, reciprocal of 10
instruct loadConL_0x6666666666666667(rRegL dst)
%{
  effect(DEF dst);


//  emit(load_immL(dst, 0x6666666666666667));
  ins_pipe(ialu_reg);
%}

instruct mul_hi(rdx_RegL dst, no_rax_RegL src, rax_RegL rax, rFlagsReg cr)
%{
  effect(DEF dst, USE src, USE_KILL rax, KILL cr);


//  emit(REX_reg_wide(src), OpcP, reg_opc(src));
  ins_pipe(ialu_reg_reg_alu0);
%}

instruct sarL_rReg_63(rRegL dst, rFlagsReg cr)
%{
  effect(USE_DEF dst, KILL cr);


//  emit(reg_opc_imm_wide(dst, 0x3F));
  ins_pipe(ialu_reg);
%}

instruct sarL_rReg_2(rRegL dst, rFlagsReg cr)
%{
  effect(USE_DEF dst, KILL cr);


//  emit(reg_opc_imm_wide(dst, 0x2));
  ins_pipe(ialu_reg);
%}

instruct divL_10(rdx_RegL dst, no_rax_RegL src, immL10 div)
%{
  match(Set dst (DivL src div));

  ins_cost((5+8)*100);
  expand %{
    rax_RegL rax;                     // Killed temp
    rFlagsReg cr;                     // Killed
    loadConL_0x6666666666666667(rax); // movq  rax, 0x6666666666666667
    mul_hi(dst, src, rax, cr);        // mulq  rdx:rax <= rax * $src
    sarL_rReg_63(src, cr);            // sarq  src, 63
    sarL_rReg_2(dst, cr);             // sarq  rdx, 2
    subL_rReg(dst, src, cr);          // subl  rdx, src
  %}
%}

//-----------------------------------------------------------------------------

instruct modI_rReg(rdx_RegI rdx, rax_RegI rax, no_rax_rdx_RegI div, rFlagsReg cr) %{
  match(Set rdx (ModI rax div));
  effect(KILL rax, KILL cr);
  ins_cost(300); 
  emit %{ __ cdq4(); __ div4($div$); %}
  ins_pipe(ialu_reg_reg_alu0);
%}

instruct modL_rReg(rdx_RegL rdx, rax_RegL rax, no_rax_rdx_RegL div, rFlagsReg cr) %{
  match(Set rdx (ModL rax div));
  effect(KILL rax, KILL cr);
  ins_cost(300);
  emit %{ __ cdq8(); __ div8($div$); %}
  ins_pipe(ialu_reg_reg_alu0);
%}

// Integer Shift Instructions
// Shift Left by one
instruct salI_mem_1(memory dst, immI1 shift, rFlagsReg cr)
%{
  match(Set dst (StoreI dst (LShiftI (LoadI dst) shift)));
  effect(KILL cr);
  emit %{ __ shl4i($dst$$base,$dst$$disp,$dst$$index,$dst$$scale,$shift$); %}
  ins_pipe(ialu_mem_imm);
%}

// Shift Left by 8-bit immediate
instruct salI_rReg_imm(rRegI dst,immI8 shift,rFlagsReg cr)%{
  match(Set dst (LShiftI dst shift));
  effect(KILL cr);
  emit %{ __ shl4i($dst$,$shift$); %}
  ins_pipe(ialu_reg);
%}

// Shift Left by 8-bit immediate
instruct salI_mem_imm(memory dst,immI8 shift,rFlagsReg cr)%{
  match(Set dst (StoreI dst (LShiftI (LoadI dst) shift)));
  effect(KILL cr);
  emit %{ __ untested("test __ salI_mem_imm"); __ shl4i($dst$$base,$dst$$disp,$dst$$index,$dst$$scale,$shift$); %}
  ins_pipe(ialu_mem_imm);
%}

// Shift Left by variable
instruct salI_rReg_CL(rRegI dst,rcx_RegI shift,rFlagsReg cr)%{
  match(Set dst (LShiftI dst shift));
  effect(KILL cr);
  emit %{ __ shl4($dst$,RCX); %}
  ins_pipe(ialu_reg_reg);
%}

// Shift Left by variable
instruct salI_mem_CL(memory dst,rcx_RegI shift,rFlagsReg cr)%{
  match(Set dst (StoreI dst (LShiftI (LoadI dst) shift)));
  effect(KILL cr);
  emit %{ __ shl4($dst$$base,$dst$$disp,$dst$$index,$dst$$scale,RCX); %}
  ins_pipe(ialu_mem_reg);
%}

// Arithmetic shift right by one
instruct sarI_mem_1(memory dst,immI1 shift,rFlagsReg cr)%{
  match(Set dst (StoreI dst (RShiftI (LoadI dst) shift)));
  effect(KILL cr);
  emit %{ __ untested("test __ sarI_mem_1"); __ sar4i($dst$$base,$dst$$disp,$dst$$index,$dst$$scale,$shift$); %}
  ins_pipe(ialu_mem_imm);
%}

// Arithmetic Shift Right by 8-bit immediate
instruct sarI_rReg_imm(rRegI dst,immI8 shift,rFlagsReg cr)%{
  match(Set dst (RShiftI dst shift));
  effect(KILL cr);
  emit %{ __ sar4i($dst$,$shift$); %}
  ins_pipe(ialu_mem_imm);
%}

// Arithmetic Shift Right by 8-bit immediate
instruct sarI_mem_imm(memory dst, immI8 shift, rFlagsReg cr)
%{
  match(Set dst (StoreI dst (RShiftI (LoadI dst) shift)));
  effect(KILL cr);
  emit %{ __ untested("test __ sarI_mem_imm"); __ sar4i($dst$$base,$dst$$disp,$dst$$index,$dst$$scale,$shift$); %}
  ins_pipe(ialu_mem_imm);
%}

// Arithmetic Shift Right by variable
instruct sarI_rReg_CL(rRegI dst,rcx_RegI shift,rFlagsReg cr)%{
  match(Set dst (RShiftI dst shift));
  effect(KILL cr);
  emit %{ __ sar4($dst$,RCX); %}
  ins_pipe(ialu_reg_reg);
%}

// Arithmetic Shift Right by variable
instruct sarI_mem_CL(memory dst,rcx_RegI shift,rFlagsReg cr)%{
  match(Set dst (StoreI dst (RShiftI (LoadI dst) shift)));
  effect(KILL cr);
  emit %{ __ untested("test __ sarI_mem_CL"); __ sar4($dst$$base,$dst$$disp,$dst$$index,$dst$$scale,RCX); %}
  ins_pipe(ialu_mem_reg);
%}

// Logical shift right by one
instruct shrI_mem_1(memory dst, immI1 shift, rFlagsReg cr)
%{
  match(Set dst (StoreI dst (URShiftI (LoadI dst) shift)));
  effect(KILL cr);


//  emit(REX_mem(dst), OpcP, RM_opc_mem(secondary, dst));
  ins_pipe(ialu_mem_imm);
%}

// Logical Shift Right by 8-bit immediate
instruct shrI_rReg_imm(rRegI dst,immI8 shift,rFlagsReg cr)%{
  match(Set dst (URShiftI dst shift));
  effect(KILL cr);
  emit %{ __ shr4i($dst$,$shift$); %}
  ins_pipe(ialu_reg);
%}

// Logical Shift Right by 8-bit immediate
instruct shrI_mem_imm(memory dst,immI8 shift,rFlagsReg cr)%{
  match(Set dst (StoreI dst (URShiftI (LoadI dst) shift)));
  effect(KILL cr);
  emit %{ __ untested("test __ shrI_mem_imm"); __ shr4i($dst$$base,$dst$$disp,$dst$$index,$dst$$scale,$shift$); %}
  ins_pipe(ialu_mem_imm);
%}

// Logical Shift Right by variable
instruct shrI_rReg_CL(rRegI dst,rcx_RegI shift,rFlagsReg cr)%{
  match(Set dst (URShiftI dst shift));
  effect(KILL cr);
  emit %{ __ shr4($dst$,RCX); %}
  ins_pipe(ialu_reg_reg);
%}

// Logical Shift Right by variable
instruct shrI_mem_CL(memory dst,rcx_RegI shift,rFlagsReg cr)%{
  match(Set dst (StoreI dst (URShiftI (LoadI dst) shift)));
  effect(KILL cr);
  emit %{ __ shr4($dst$$base,$dst$$disp,$dst$$index,$dst$$scale,RCX); %}
  ins_pipe(ialu_mem_reg);
%}

// Long Shift Instructions
// Shift Left by one
instruct salL_mem_1(memory dst,immI1 shift,rFlagsReg cr)%{
  match(Set dst (StoreL dst (LShiftL (LoadL dst) shift)));
  effect(KILL cr);
  emit %{ __ untested("test __ salL_mem_1"); __ shl8i($dst$$base,$dst$$disp,$dst$$index,$dst$$scale,$shift$); %}
  ins_pipe(ialu_mem_imm);
%}

// Shift Left by 8-bit immediate
instruct salL_rReg_imm(rRegL dst,immI8 shift,rFlagsReg cr)%{
  match(Set dst (LShiftL dst shift));
  effect(KILL cr);
  emit %{ __ shl8i($dst$,$shift$); %}
  ins_pipe(ialu_reg);
%}

// Shift Left by 8-bit immediate
instruct salL_mem_imm(memory dst,immI8 shift,rFlagsReg cr)%{
  match(Set dst (StoreL dst (LShiftL (LoadL dst) shift)));
  effect(KILL cr);
  emit %{ __ untested("test __ salL_mem_imm"); __ shl8i($dst$$base,$dst$$disp,$dst$$index,$dst$$scale,$shift$); %}
  ins_pipe(ialu_mem_imm);
%}

// Shift Left by variable
instruct salL_rReg_CL(rRegL dst,rcx_RegI shift,rFlagsReg cr)%{
  match(Set dst (LShiftL dst shift));
  effect(KILL cr);
  emit %{ __ shl8($dst$,$shift$); %}
  ins_pipe(ialu_reg_reg);
%}


// Shift Left by variable
instruct salL_mem_CL(memory dst,rcx_RegI shift,rFlagsReg cr)%{
  match(Set dst (StoreL dst (LShiftL (LoadL dst) shift)));
  effect(KILL cr);
  emit %{ __ untested("test __ salL_mem_CL"); __ shl8($dst$$base,$dst$$disp,$dst$$index,$dst$$scale,RCX); %}
  ins_pipe(ialu_mem_reg);
%}


// Arithmetic shift right by one
instruct sarL_mem_1(memory dst,immI1 shift,rFlagsReg cr)%{
  match(Set dst (StoreL dst (RShiftL (LoadL dst) shift)));
  effect(KILL cr);
  emit %{ __ untested("test __ sarL_mem_1"); __ sar8i($dst$$base,$dst$$disp,$dst$$index,$dst$$scale,$shift$); %}
  ins_pipe(ialu_mem_imm);
%}

// Arithmetic Shift Right by 8-bit immediate
instruct sarL_rReg_imm(rRegL dst,immI8 shift,rFlagsReg cr)%{
  match(Set dst (RShiftL dst shift));
  effect(KILL cr);
  emit %{ __ sar8i($dst$,$shift$); %}
  ins_pipe(ialu_reg);
%}

// Arithmetic Shift Right by 8-bit immediate
instruct sarL_mem_imm(memory dst,immI8 shift,rFlagsReg cr)%{
  match(Set dst (StoreL dst (RShiftL (LoadL dst) shift)));
  effect(KILL cr);
  emit %{ __ untested("test __ sarL_mem_imm"); __ sar8i($dst$$base,$dst$$disp,$dst$$index,$dst$$scale,$shift$); %}
  ins_pipe(ialu_mem_imm);
%}

// Arithmetic Shift Right by variable
instruct sarL_rReg_CL(rRegL dst,rcx_RegI shift,rFlagsReg cr)%{
  match(Set dst (RShiftL dst shift));
  effect(KILL cr);
  emit %{ __ sar8($dst$,RCX); %}
  ins_pipe(ialu_reg_reg);
%}

// Arithmetic Shift Right by variable
instruct sarL_mem_CL(memory dst,rcx_RegI shift,rFlagsReg cr)%{
  match(Set dst (StoreL dst (RShiftL (LoadL dst) shift)));
  effect(KILL cr);
  emit %{ __ untested("test __ sarL_mem_CL"); __ sar8($dst$$base,$dst$$disp,$dst$$index,$dst$$scale,RCX); %}
  ins_pipe(ialu_mem_reg);
%}

// Logical shift right by one
instruct shrL_mem_1(memory dst,immI1 shift,rFlagsReg cr)%{
  match(Set dst (StoreL dst (URShiftL (LoadL dst) shift)));
  effect(KILL cr);
  emit %{ __ untested("test __ shrL_mem_1"); __ shr8i($dst$$base,$dst$$disp,$dst$$index,$dst$$scale,$shift$); %}
  ins_pipe(ialu_mem_imm);
%}

// Logical Shift Right by 8-bit immediate
instruct shrL_rReg_imm(rRegL dst,immI8 shift,rFlagsReg cr)%{
  match(Set dst (URShiftL dst shift));
  effect(KILL cr);
  emit %{ __ shr8i($dst$,$shift$); %}
  ins_pipe(ialu_reg);
%}


// Logical Shift Right by 8-bit immediate
instruct shrL_mem_imm(memory dst,immI8 shift,rFlagsReg cr)%{
  match(Set dst (StoreL dst (URShiftL (LoadL dst) shift)));
  effect(KILL cr);
  emit %{ __ untested("test __ shrL_mem_imm"); __ shr8i($dst$$base,$dst$$disp,$dst$$index,$dst$$scale,$shift$); %}
  ins_pipe(ialu_mem_imm);
%}

// Logical Shift Right by variable
instruct shrL_rReg_CL(rRegL dst,rcx_RegI shift,rFlagsReg cr)%{
  match(Set dst (URShiftL dst shift));
  effect(KILL cr);
  emit %{ __ shr8($dst$,$shift$); %}
  ins_pipe(ialu_reg_reg);
%}

// Logical Shift Right by variable
instruct shrL_mem_CL(memory dst,rcx_RegI shift,rFlagsReg cr)%{
  match(Set dst (StoreL dst (URShiftL (LoadL dst) shift)));
  effect(KILL cr);
  emit %{ __ untested("test __ shrL_mem_CL"); __ shr8($dst$$base,$dst$$disp,$dst$$index,$dst$$scale,RCX); %}
  ins_pipe(ialu_mem_reg);
%}

// Logical Shift Right by 24, followed by Arithmetic Shift Left by 24.
// This idiom is used by the compiler for the i2b bytecode.
instruct i2b(rRegI dst,rRegI src,immI_24 twentyfour)%{
  match(Set dst (RShiftI (LShiftI src twentyfour) twentyfour));
  emit %{ __ movsx41($dst$,$src$); %}
  ins_pipe(ialu_reg_reg);
%}

// Logical Shift Right by 16, followed by Arithmetic Shift Left by 16.
// This idiom is used by the compiler the i2s bytecode.
instruct i2s(rRegI dst,rRegI src,immI_16 sixteen)%{
  match(Set dst (RShiftI (LShiftI src sixteen) sixteen));
  emit %{ __ movsx42($dst$,$src$); %}
  ins_pipe(ialu_reg_reg);
%}

// ROL/ROR instructions

// ROL expand
instruct rolI_rReg_imm1(rRegI dst, rFlagsReg cr) %{
  effect(KILL cr, USE_DEF dst);
  
  
//  emit(REX_reg(dst), OpcP, reg_opc(dst));
  ins_pipe(ialu_reg);
%}

instruct rolI_rReg_imm8(rRegI dst, immI8 shift, rFlagsReg cr) %{
  effect(USE_DEF dst, USE shift, KILL cr);
  emit %{ __ rol4i($dst$,$shift$); %}
  ins_pipe(ialu_reg);
%}

instruct rolI_rReg_CL(no_rcx_RegI dst,rcx_RegI shift,rFlagsReg cr)%{
  effect(USE_DEF dst, USE shift, KILL cr);
  emit %{ __ rol4($dst$,$shift$); %}
  ins_pipe(ialu_reg_reg);
%}
// end of ROL expand

// Rotate Left by one
instruct rolI_rReg_i1(rRegI dst,immI1 lshift,immI_M1 rshift,rFlagsReg cr)%{
  match(Set dst (OrI (LShiftI dst lshift) (URShiftI dst rshift)));
  expand %{
    rolI_rReg_imm1(dst, cr);
  %}
%}

// Rotate Left by 8-bit immediate
instruct rolI_rReg_i8(rRegI dst,immI8 lshift,immI8 rshift,rFlagsReg cr)%{
  predicate(0 == ((n->in(1)->in(2)->get_int() + n->in(2)->in(2)->get_int()) & 0x1f));
  match(Set dst (OrI (LShiftI dst lshift) (URShiftI dst rshift)));
  expand %{
    rolI_rReg_imm8(dst, lshift, cr);
  %}
%}

// Rotate Left by variable
instruct rolI_rReg_Var_C0(no_rcx_RegI dst,rcx_RegI shift,immI0 zero,rFlagsReg cr)%{
  match(Set dst (OrI (LShiftI dst shift) (URShiftI dst (SubI zero shift))));
  expand %{
    rolI_rReg_CL(dst, shift, cr);
  %}
%}

// Rotate Left by variable
instruct rolI_rReg_Var_C32(no_rcx_RegI dst,rcx_RegI shift,immI_32 c32,rFlagsReg cr)%{
  match(Set dst (OrI (LShiftI dst shift) (URShiftI dst (SubI c32 shift))));
  expand %{
    rolI_rReg_CL(dst, shift, cr);
  %}
%}

// ROR expand
instruct rorI_rReg_imm1(rRegI dst, rFlagsReg cr)
%{
  effect(USE_DEF dst, KILL cr);


//  emit(REX_reg(dst), OpcP, reg_opc(dst));
  ins_pipe(ialu_reg);
%}

instruct rorI_rReg_imm8(rRegI dst,immI8 shift,rFlagsReg cr)%{
  effect(USE_DEF dst, USE shift, KILL cr);
  emit %{ __ untested("test rorI_rReg_imm8"); __ ror4i($dst$,$shift$); %}
  ins_pipe(ialu_reg);
%}

instruct rorI_rReg_CL(no_rcx_RegI dst,rcx_RegI shift,rFlagsReg cr)%{
  effect(USE_DEF dst, USE shift, KILL cr);
  emit %{ __ ror4($dst$,$shift$); %}
  ins_pipe(ialu_reg_reg);
%}
// end of ROR expand

// Rotate Right by one
instruct rorI_rReg_i1(rRegI dst,immI1 rshift,immI_M1 lshift,rFlagsReg cr)%{
  match(Set dst (OrI (URShiftI dst rshift) (LShiftI dst lshift)));
  expand %{
    rorI_rReg_imm1(dst, cr);
  %}
%}

// Rotate Right by 8-bit immediate
instruct rorI_rReg_i8(rRegI dst,immI8 rshift,immI8 lshift,rFlagsReg cr)%{
  predicate(0 == ((n->in(1)->in(2)->get_int() + n->in(2)->in(2)->get_int()) & 0x1f));
  match(Set dst (OrI (URShiftI dst rshift) (LShiftI dst lshift)));
  expand %{
    rorI_rReg_imm8(dst, rshift, cr);
  %}
%}

// Rotate Right by variable
instruct rorI_rReg_Var_C0(no_rcx_RegI dst,rcx_RegI shift,immI0 zero,rFlagsReg cr)%{
  match(Set dst (OrI (URShiftI dst shift) (LShiftI dst (SubI zero shift))));
  expand %{
    rorI_rReg_CL(dst, shift, cr);
  %}
%}

// Rotate Right by variable
instruct rorI_rReg_Var_C32(no_rcx_RegI dst,rcx_RegI shift,immI_32 c32,rFlagsReg cr)%{
  match(Set dst (OrI (URShiftI dst shift) (LShiftI dst (SubI c32 shift))));
  expand %{
    rorI_rReg_CL(dst, shift, cr);
  %}
%}

// for long rotate
// ROL expand
instruct rolL_rReg_imm1(rRegL dst, rFlagsReg cr) %{
  effect(USE_DEF dst, KILL cr);


//  emit(REX_reg_wide(dst), OpcP, reg_opc(dst));
  ins_pipe(ialu_reg);
%}

instruct rolL_rReg_imm8(rRegL dst, immI8 shift, rFlagsReg cr) %{
  effect(USE_DEF dst, USE shift, KILL cr);
  emit %{ __ rol8i($dst$,$shift$); %}
  ins_pipe(ialu_reg);
%}

instruct rolL_rReg_CL(no_rcx_RegL dst,rcx_RegI shift,rFlagsReg cr)%{
  effect(USE_DEF dst, USE shift, KILL cr);
  emit %{ __ rol8($dst$,$shift$); %}
  ins_pipe(ialu_reg_reg);
%}
// end of ROL expand

// Rotate Left by one
instruct rolL_rReg_i1(rRegL dst,immI1 lshift,immI_M1 rshift,rFlagsReg cr)%{
  match(Set dst (OrL (LShiftL dst lshift) (URShiftL dst rshift)));
  expand %{
    rolL_rReg_imm1(dst, cr);
  %}
%}

// Rotate Left by 8-bit immediate
instruct rolL_rReg_i8(rRegL dst,immI8 lshift,immI8 rshift,rFlagsReg cr)%{
  predicate(0 == ((n->in(1)->in(2)->get_int() + n->in(2)->in(2)->get_int()) & 0x3f));
  match(Set dst (OrL (LShiftL dst lshift) (URShiftL dst rshift)));
  expand %{
    rolL_rReg_imm8(dst, lshift, cr);
  %}
%}

// Rotate Left by variable
instruct rolL_rReg_Var_C0(no_rcx_RegL dst,rcx_RegI shift,immI0 zero,rFlagsReg cr)%{
  match(Set dst (OrL (LShiftL dst shift) (URShiftL dst (SubI zero shift))));
  expand %{
    rolL_rReg_CL(dst, shift, cr);
  %}
%}

// Rotate Left by variable
instruct rolL_rReg_Var_C64(no_rcx_RegL dst,rcx_RegI shift,immI_64 c64,rFlagsReg cr)%{
  match(Set dst (OrL (LShiftL dst shift) (URShiftL dst (SubI c64 shift))));
  expand %{
    rolL_rReg_CL(dst, shift, cr);
  %}
%}

// ROR expand
instruct rorL_rReg_imm1(rRegL dst, rFlagsReg cr)
%{
  effect(USE_DEF dst, KILL cr);


//  emit(REX_reg_wide(dst), OpcP, reg_opc(dst));
  ins_pipe(ialu_reg);
%}

instruct rorL_rReg_imm8(rRegL dst,immI8 shift,rFlagsReg cr)%{
  effect(USE_DEF dst, USE shift, KILL cr);
  emit %{ __ untested("test rorL_rReg_imm8"); __ ror8i($dst$,$shift$); %}
  ins_pipe(ialu_reg);
%}

instruct rorL_rReg_CL(no_rcx_RegL dst, rcx_RegI shift, rFlagsReg cr)
%{
  effect(USE_DEF dst, USE shift, KILL cr);
  emit %{ __ ror8($dst$,$shift$); %}
  ins_pipe(ialu_reg_reg);
%}
// end of ROR expand

// Rotate Right by one
instruct rorL_rReg_i1(rRegL dst,immI1 rshift,immI_M1 lshift,rFlagsReg cr)%{
  match(Set dst (OrL (URShiftL dst rshift) (LShiftL dst lshift)));
  expand %{
    rorL_rReg_imm1(dst, cr);
  %}
%}

// Rotate Right by 8-bit immediate
instruct rorL_rReg_i8(rRegL dst,immI8 rshift,immI8 lshift,rFlagsReg cr)%{
  predicate(0 == ((n->in(1)->in(2)->get_int() + n->in(2)->in(2)->get_int()) & 0x3f));
  match(Set dst (OrL (URShiftL dst rshift) (LShiftL dst lshift)));
  expand %{
    rorL_rReg_imm8(dst, rshift, cr);
  %}
%}

// Rotate Right by variable
instruct rorL_rReg_Var_C0(no_rcx_RegL dst,rcx_RegI shift,immI0 zero,rFlagsReg cr)%{
  match(Set dst (OrL (URShiftL dst shift) (LShiftL dst (SubI zero shift))));
  expand %{
    rorL_rReg_CL(dst, shift, cr);
  %}
%}

// Rotate Right by variable
instruct rorL_rReg_Var_C64(no_rcx_RegL dst,rcx_RegI shift,immI_64 c64,rFlagsReg cr)%{
  match(Set dst (OrL (URShiftL dst shift) (LShiftL dst (SubI c64 shift))));
  expand %{
    rorL_rReg_CL(dst, shift, cr);
  %}
%}

// Logical Instructions

// Integer Logical Instructions

// And Instructions
// And Register with Register
instruct andI_rReg(rRegI dst,rRegI src,rFlagsReg cr)%{
  match(Set dst (AndI dst src));
  effect(KILL cr);
  emit %{ __ and4($dst$,$src$); %}
  ins_pipe(ialu_reg_reg);
%}

// And Register with Immediate 255 and promote to long
instruct andI2L_rReg_imm255(rRegL dst,rRegI src,immI_255 mask)%{
  match(Set dst (ConvI2L (AndI src mask)));
  emit %{ __ movzx81($dst$,$src$); %}
  ins_pipe(ialu_reg);
%}

// And Register with Immediate 65535 and promote to long
instruct andI2L_rReg_imm65535(rRegL dst,rRegI src,immI_65535 mask)%{
  match(Set dst (ConvI2L (AndI src mask)));
  emit %{ __ movzx82($dst$,$src$); %}
  ins_pipe(ialu_reg);
%}

// And Register with Immediate
instruct andI_rReg_imm(rRegI dst,immI src,rFlagsReg cr)%{
  match(Set dst (AndI dst src));
  effect(KILL cr);
  emit %{ __ and4i($dst$,$src$); %}
  ins_pipe(ialu_reg);
%}

// And Register with Memory
instruct andI_rReg_mem(rRegI dst,memory mem,rFlagsReg cr)%{
match(Set dst(AndI dst(LoadI mem)));
  effect(KILL cr);
  ins_cost(125);
  emit %{ __ and4($dst$,$mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

// And Memory with Register
instruct andI_mem_rReg(memory dst,rRegI src,rFlagsReg cr)%{
  match(Set dst (StoreI dst (AndI (LoadI dst) src)));
  effect(KILL cr);
  ins_cost(150);
  emit %{ __ and4($dst$$base,$dst$$disp,$dst$$index,$dst$$scale, $src$);  %}
  ins_pipe(ialu_mem_reg);
%}

// And Memory with Immediate
instruct andI_mem_imm(memory mem,immI src,rFlagsReg cr)%{
match(Set mem(StoreI mem(AndI(LoadI mem)src)));
  effect(KILL cr);
  ins_cost(125);
  emit %{  __ and4i($mem$$base,$mem$$disp,$mem$$index,$mem$$scale, $src$);  %}
  ins_pipe(ialu_mem_imm);
%}

// Or Instructions
// Or Register with Register
instruct orI_rReg(rRegI dst,rRegI src,rFlagsReg cr)%{
  match(Set dst (OrI dst src));
  effect(KILL cr);
  emit %{ __ or_4($dst$,$src$); %}
  ins_pipe(ialu_reg_reg);
%}

// Or Register with Immediate
instruct orI_rReg_imm(rRegI dst,immI src,rFlagsReg cr)%{
  match(Set dst (OrI dst src));
  effect(KILL cr);
  emit %{ __ or_4i($dst$,$src$); %}
  ins_pipe(ialu_reg);
%}

// Or Register with Memory
instruct orI_rReg_mem(rRegI dst,memory src,rFlagsReg cr)%{
  match(Set dst (OrI dst (LoadI src)));
  effect(KILL cr);
  ins_cost(125);
  emit %{ __ or_4($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

// Or Memory with Register
instruct orI_mem_rReg(memory dst,rRegI src,rFlagsReg cr)%{
  match(Set dst (StoreI dst (OrI (LoadI dst) src)));
  effect(KILL cr);
  ins_cost(150);
  emit %{ __ or_4($dst$$base,$dst$$disp, $dst$$index, $dst$$scale, $src$); %}
  ins_pipe(ialu_mem_reg);
%}

// Or Memory with Immediate
instruct orI_mem_imm(memory mem,immI src,rFlagsReg cr)%{
match(Set mem(StoreI mem(OrI(LoadI mem)src)));
  effect(KILL cr);
  ins_cost(125);
  emit %{  __ or_4i($mem$$base,$mem$$disp,$mem$$index,$mem$$scale, $src$);  %}
  ins_pipe(ialu_mem_imm);
%}

// Xor Instructions
// Xor Register with Register
instruct xorI_rReg(rRegI dst,rRegI src,rFlagsReg cr)%{
  match(Set dst (XorI dst src));
  effect(KILL cr);
  emit %{ __ xor4($dst$,$src$); %}
  ins_pipe(ialu_reg_reg);
%}

// Xor Register with Immediate
instruct xorI_rReg_imm(rRegI dst,immI src,rFlagsReg cr)%{
  match(Set dst (XorI dst src));
  effect(KILL cr);
  emit %{ __ xor4i($dst$,$src$); %}
  ins_pipe(ialu_reg);
%}

// Xor Register with Memory
instruct xorI_rReg_mem(rRegI dst,memory src,rFlagsReg cr)%{
  match(Set dst (XorI dst (LoadI src)));
  effect(KILL cr);
  ins_cost(125);
  emit %{ __ xor4($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

// Xor Memory with Register
instruct xorI_mem_rReg(memory dst,rRegI src,rFlagsReg cr)%{
  match(Set dst (StoreI dst (XorI (LoadI dst) src)));
  effect(KILL cr);
  ins_cost(150);
  emit %{ __ xor4($dst$$base,$dst$$disp, $dst$$index, $dst$$scale, $src$); %}
  ins_pipe(ialu_mem_reg);
%}

// Xor Memory with Immediate
instruct xorI_mem_imm(memory dst, immI src, rFlagsReg cr)
%{
  match(Set dst (StoreI dst (XorI (LoadI dst) src)));
  effect(KILL cr);
  ins_cost(125);
  emit %{ __ xor4i($dst$$base,$dst$$disp, $dst$$index, $dst$$scale, $src$); %}
  ins_pipe(ialu_mem_imm);
%}


// Long Logical Instructions

// And Instructions
// And Register with Register
instruct andL_rReg(rRegL dst,rRegL src,rFlagsReg cr)%{
  match(Set dst (AndL dst src));
  effect(KILL cr);
  emit %{ __ and8($dst$,$src$); %}
  ins_pipe(ialu_reg_reg);
%}

// And Register with Immediate 65535
instruct andL_rReg_imm65535(rRegL dst,immL_65535 src)%{
  match(Set dst (AndL dst src));
  emit %{ __ movzx82($dst$,$dst$); %}
  ins_pipe(ialu_reg);
%}

// And Register with Immediate
instruct andL_rReg_imm(rRegL dst,immL32 src,rFlagsReg cr)%{
  match(Set dst (AndL dst src));
  effect(KILL cr);
  emit %{ __ and8i($dst$,$src$);  %}
  ins_pipe(ialu_reg);
%}

// And Register with Memory
instruct andL_rReg_mem(rRegL dst,memory mem,rFlagsReg cr)%{
match(Set dst(AndL dst(LoadL mem)));
  effect(KILL cr);
  ins_cost(125);
  emit %{ __ and8($dst$,$mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

// And Memory with Register
instruct andL_mem_rReg(memory dst,rRegL src,rFlagsReg cr)%{
  match(Set dst (StoreL dst (AndL (LoadL dst) src)));
  effect(KILL cr);
  ins_cost(150);
  emit %{ __ and8($dst$$base,$dst$$disp, $dst$$index, $dst$$scale, $src$); %}
  ins_pipe(ialu_mem_reg);
%}

// And Memory with Immediate
instruct andL_mem_imm(memory dst,immL32 src,rFlagsReg cr)%{
  match(Set dst (StoreL dst (AndL (LoadL dst) src)));
  effect(KILL cr);
  ins_cost(125);
  emit %{ __ and8i($dst$$base,$dst$$disp, $dst$$index, $dst$$scale, $src$); %}
  ins_pipe(ialu_mem_imm);
%}

// Or Instructions
// Or Register with Register
instruct orL_rReg(rRegL dst,rRegL src,rFlagsReg cr)%{
  match(Set dst (OrL dst src));
  effect(KILL cr);
  emit %{ __ or_8($dst$,$src$); %}
  ins_pipe(ialu_reg_reg);
%}

instruct orL_rRegI(rRegL dst,rRegI src,rFlagsReg cr)%{
match(Set dst(OrL dst(ConvI2L src)));
  predicate( (n->in(1)->Opcode() == Op_ConvI2L && n->in(1)->in(1)->bottom_type()->is_int()->_lo >= 0) ||
             (n->in(2)->Opcode() == Op_ConvI2L && n->in(2)->in(1)->bottom_type()->is_int()->_lo >= 0) );
  emit %{ __ or_8($dst$,$src$); %}
  ins_pipe(ialu_reg_reg);
%}

// Or Register with Immediate
instruct orL_rReg_imm(rRegL dst,immL32 src,rFlagsReg cr)%{
  match(Set dst (OrL dst src));
  effect(KILL cr);
  emit %{ __ or_8i($dst$,$src$);  %}
  ins_pipe(ialu_reg);
%}

// Or Register with Memory
instruct orL_rReg_mem(rRegL dst,memory mem,rFlagsReg cr)%{
match(Set dst(OrL dst(LoadL mem)));
  effect(KILL cr);
  ins_cost(125);
  emit %{ __ or_8($dst$,$mem$$base,$mem$$disp, $mem$$index, $mem$$scale); %}
  ins_pipe(ialu_reg_mem);
%}

// Or Memory with Register
instruct orL_mem_rReg(memory dst,rRegL src,rFlagsReg cr)%{
  match(Set dst (StoreL dst (OrL (LoadL dst) src)));
  effect(KILL cr);
  ins_cost(150);
  emit %{ __ or_8($dst$$base,$dst$$disp, $dst$$index, $dst$$scale, $src$); %}
  ins_pipe(ialu_mem_reg);
%}

// Or Memory with Immediate
instruct orL_mem_imm(memory dst, immL32 src, rFlagsReg cr)
%{
  match(Set dst (StoreL dst (OrL (LoadL dst) src)));
  effect(KILL cr);
  ins_cost(125);
  emit %{ __ or_8i($dst$$base,$dst$$disp, $dst$$index, $dst$$scale, $src$); %}
  ins_pipe(ialu_mem_imm);
%}

// Xor Instructions
// Xor Register with Register
instruct xorL_rReg(rRegL dst,rRegL src,rFlagsReg cr)%{
  match(Set dst (XorL dst src));
  effect(KILL cr);
  emit %{ __ xor8($dst$,$src$); %}
  ins_pipe(ialu_reg_reg);
%}

// Xor Register with Immediate -1
instruct xorL_rReg_im1(rRegL dst,immL_M1 imm)%{
match(Set dst(XorL dst imm));
  emit %{ __ not8($dst$); %}
  ins_pipe(ialu_reg);
%}

// Xor Register with Immediate
instruct xorL_rReg_imm(rRegL dst, immL32 src, rFlagsReg cr)
%{
  match(Set dst (XorL dst src));
  effect(KILL cr);


//  emit(OpcSErm_wide(dst, src), Con8or32(src));
  ins_pipe(ialu_reg);
%}

// Xor Register with Memory
instruct xorL_rReg_mem(rRegL dst,memory src,rFlagsReg cr)%{
  match(Set dst (XorL dst (LoadL src)));
  effect(KILL cr);
  ins_cost(125);
  emit %{ __ xor8($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  %}
  ins_pipe(ialu_reg_mem);
%}

// Xor Memory with Register
instruct xorL_mem_rReg(memory dst,rRegL src,rFlagsReg cr)%{
  match(Set dst (StoreL dst (XorL (LoadL dst) src)));
  effect(KILL cr);
  ins_cost(150);
  emit %{ __ xor8($dst$$base,$dst$$disp, $dst$$index, $dst$$scale, $src$); %}
  ins_pipe(ialu_mem_reg);
%}

// Xor Memory with Immediate
instruct xorL_mem_imm(memory dst, immL32 src, rFlagsReg cr)
%{
  match(Set dst (StoreL dst (XorL (LoadL dst) src)));
  effect(KILL cr);
  ins_cost(125);
  emit %{ __ xor8i($dst$$base,$dst$$disp, $dst$$index, $dst$$scale, $src$); %}
  ins_pipe(ialu_mem_imm);
%}

// Convert Int to Boolean
instruct convI2B(rRegI dst,rRegI src,rFlagsReg cr)%{
  match(Set dst (Conv2B src));
  effect(KILL cr);
  emit %{
    __ test4($src$,$src$);
    __ setnz($dst$);
    __ movzx41($dst$,$dst$);
  %}
  ins_pipe(ialu_reg_reg);
%}

instruct cmpLTMask(rRegI dst,rRegI p,rRegI q,rFlagsReg cr)%{
  match(Set dst (CmpLTMask p q));
  effect(KILL cr);
  ins_cost(400);
  emit %{
    __ test4($p$,$q$);
    __ setlt($dst$);
    __ movzx41($dst$,$dst$);
    __ neg4($dst$);
  %}    
  ins_pipe(pipe_slow);
%}

instruct cmpLTMask0(rRegI dst,immI0 zero,rFlagsReg cr)%{
  match(Set dst (CmpLTMask dst zero));
  effect(KILL cr);
  ins_cost(100);
  emit %{ __ sar4i($dst$,31); // convert sign bit into a mask %}
  ins_pipe(ialu_reg);
%}

instruct cadd_cmpLTMask(rRegI p, rRegI q, rRegI y,
rRegI tmp,rFlagsReg cr)%{
  match(Set p (AddI (AndI (CmpLTMask p q) y) (SubI p q)));
  effect(TEMP tmp, KILL cr);
  ins_cost(400);
  emit %{
    __ sub4($p$,$q$);
    __ sbb4($tmp$,$tmp$);
    __ and4($tmp$,$y$);
    __ add4($p$,$tmp$);
  %}
  ins_pipe(pipe_cmplt);
%}

/* If I enable this, I encourage spilling in the inner loop of compress.
instruct cadd_cmpLTMask_mem( rRegI p, rRegI q, memory y, rRegI tmp, rFlagsReg cr )
%{
  match(Set p (AddI (AndI (CmpLTMask p q) (LoadI y)) (SubI p q)));
  effect( TEMP tmp, KILL cr );
  ins_cost(400);


//  emit( enc_cmpLTP_mem(p,q,y,tmp) );
%}
*/

//---------- FP Instructions------------------------------------------------

instruct cmpF_cc_reg(rFlagsRegU cr,regF src1,regF src2)%{
  match(Set cr (CmpF src1 src2));
  ins_cost(300);
  emit %{ 
Label done;
    __ cmp4((FRegister)$src1$,(FRegister)$src2$);
    __ jpo  (done);
__ pushf();
    __ and8i(RSP,0,(int)0xffffff2b);
__ popf();
__ bind(done);
    __ nop(); // avoid branch to branch
  %}
  ins_pipe(pipe_slow);
%}

// No cleanup of carry flag in the case of a NaN
instruct cmpF_cc_reg_CF(rFlagsRegUCF cr,regF src1,regF src2)%{
match(Set cr(CmpF src1 src2));
  ins_cost(100);
  emit %{ __ cmp4((FRegister)$src1$,(FRegister)$src2$); %}
  ins_pipe(pipe_slow);
%}

instruct cmpF_cc_mem(rFlagsRegU cr,regF src1,memory src2)%{
  match(Set cr (CmpF src1 (LoadF src2)));
  ins_cost(145);
  emit %{ 
Label done;
    __ cmp4((FRegister)$src1$,$src2$$base,$src2$$disp,$src2$$index,$src2$$scale);
    __ jpo  (done);
__ pushf();
    __ and8i(RSP,0,(int)0xffffff2b);
__ popf();
__ bind(done);
    __ nop(); // avoid branch to branch
  %}
  ins_pipe(pipe_slow);
%}

instruct cmpF_cc_memCF(rFlagsRegUCF cr,regF src1,memory src2)%{
  match(Set cr (CmpF src1 (LoadF src2)));
  ins_cost(100);
  emit %{ __ cmp4((FRegister)$src1$,$src2$$base,$src2$$disp,$src2$$index,$src2$$scale); %}
  ins_pipe(pipe_slow);
%}

// instruct cmpF_cc_imm(rFlagsRegU cr, regF src1, immF src2)
// %{
//   match(Set cr (CmpF src1 src2));
// 
//   ins_cost(145);
// 
// //  emit(REX_reg_mem(src1, src2), OpcP, OpcS, load_immF(src1, src2),
// //             cmpfp_fixup);
//   ins_pipe(pipe_slow);
// %}

// instruct cmpF_cc_immCF(rFlagsRegUCF cr, regF src1, immF src2) %{
//   match(Set cr (CmpF src1 src2));
//   ins_cost(125);
//   emit %{ 
//     unsigned char *addr = __ float_constant($src2$); 
//     if (addr == NULL) Unimplemented();
//     __ cmp4((FRegister)$src1$, addr);
//   %}
//   ins_pipe(pipe_slow);
// %}

instruct cmpD_cc_reg(rFlagsRegU cr,regD src1,regD src2)%{
  match(Set cr (CmpD src1 src2));
  ins_cost(145);
  emit %{ 
Label done;
    __ cmp8 ((FRegister)$src1$,(FRegister)$src2$);
    __ jpo  (done);
__ pushf();
    __ and8i(RSP,0,(int)0xffffff2b);
__ popf();
__ bind(done);
    __ nop(); // avoid branch to branch
  %}
  ins_pipe(pipe_slow);
%}

instruct cmpD_cc_reg_CF(rFlagsRegUCF cr,regD src1,regD src2)%{
match(Set cr(CmpD src1 src2));
  ins_cost(100);
  emit %{ __ cmp8 ((FRegister)$src1$,(FRegister)$src2$); %}
  ins_pipe(pipe_slow);
%}

instruct cmpD_cc_mem(rFlagsRegU cr, regD src1, memory src2) %{
  match(Set cr (CmpD src1 (LoadD src2)));
  ins_cost(145);
  emit %{ 
Label done;
    __ cmp8((FRegister)$src1$,$src2$$base,$src2$$disp,$src2$$index,$src2$$scale);
    __ jpo  (done);
__ pushf();
    __ and8i(RSP,0,(int)0xffffff2b);
__ popf();
__ bind(done);
    __ nop(); // avoid branch to branch
  %}
  emit %{ 
  ins_pipe(pipe_slow);
%}

instruct cmpD_cc_memCF(rFlagsRegUCF cr, regD src1, memory src2) %{
  match(Set cr (CmpD src1 (LoadD src2)));
  ins_cost(100);
  emit %{ __ cmp8((FRegister)$src1$,$src2$$base,$src2$$disp,$src2$$index,$src2$$scale); %}
  ins_pipe(pipe_slow);
%}

// instruct cmpD_cc_imm(rFlagsRegU cr, regD src1, immD src2)
// %{
//   match(Set cr (CmpD src1 src2));
// 
//   ins_cost(145);
// 
// //  emit(OpcP, REX_reg_mem(src1, src2), OpcS, OpcT, load_immD(src1, src2),
// //             cmpfp_fixup);
//   ins_pipe(pipe_slow);
// %}

//instruct cmpD_cc_immCF(rFlagsRegUCF cr, regD src1, immD src2) %{
//  match(Set cr (CmpD src1 src2));
//
//  ins_cost(100);
//
////  emit(OpcP, REX_reg_mem(src1, src2), OpcS, OpcT, load_immD(src1, src2));
//  ins_pipe(pipe_slow);
//%}

// Compare into -1,0,1
instruct cmpF_reg(rRegI dst,regF src1,regF src2,rFlagsReg cr)%{
  match(Set dst (CmpF3 src1 src2));
  effect(KILL cr);
  ins_cost(275);
  emit %{ __ fcmp($dst$,(FRegister)$src1$,(FRegister)$src2$,-1/*unordered returns -1*/); %}
  ins_pipe(pipe_slow);
%}

// Compare into -1,0,1
instruct cmpF_mem(rRegI dst,regF src1,memory src2,rFlagsReg cr)%{
  match(Set dst (CmpF3 src1 (LoadF src2)));
  effect(KILL cr);
  ins_cost(275);
  emit %{ __ fcmp($dst$,(FRegister)$src1$,$src2$$base,$src2$$disp,$src2$$index,$src2$$scale,-1);  %}  
  ins_pipe(pipe_slow);
%}

// // Compare into -1,0,1
// instruct cmpF_imm(rRegI dst, regF src1, immF src2, rFlagsReg cr)
// %{
//   match(Set dst (CmpF3 src1 src2));
//   effect(KILL cr);
// 
//   ins_cost(275);
// 
// 
// //  emit(REX_reg_mem(src1, src2), OpcP, OpcS, load_immF(src1, src2),
// //             cmpfp3(dst));
//   ins_pipe(pipe_slow);
// %}

// Compare into -1,0,1
instruct cmpD_reg(rRegI dst,regD src1,regD src2,rFlagsReg cr)%{
  match(Set dst (CmpD3 src1 src2));
  effect(KILL cr);
  ins_cost(275);
  emit %{ __ dcmp($dst$,(FRegister)$src1$,(FRegister)$src2$,-1);  %}
  ins_pipe(pipe_slow);
%}

// Compare into -1,0,1
instruct cmpD_mem(rRegI dst,regD src1,memory src2,rFlagsReg cr)%{
  match(Set dst (CmpD3 src1 (LoadD src2)));
  effect(KILL cr);
  ins_cost(275);
  emit %{ __ dcmp($dst$,(FRegister)$src1$,$src2$$base,$src2$$disp,$src2$$index,$src2$$scale,-1);  %}
  ins_pipe(pipe_slow);
%}

// Compare into -1,0,1
// instruct cmpD_imm(rRegI dst, regD src1, immD src2, rFlagsReg cr)
// %{
//   match(Set dst (CmpD3 src1 src2));
//   effect(KILL cr);
// 
//   ins_cost(275);
// 
// 
// //  emit(OpcP, REX_reg_mem(src1, src2), OpcS, OpcT, load_immD(src1, src2),
// //             cmpfp3(dst));
//   ins_pipe(pipe_slow);
// %}

instruct addF_reg(regF dst,regF src)%{
  match(Set dst (AddF dst src));
  ins_cost(150);
  emit %{ __ addf((FRegister)$dst$,(FRegister)$src$); %}
  ins_pipe(pipe_slow);
%}

instruct addF_mem(regF dst,memory src)%{
  match(Set dst (AddF dst (LoadF src)));
  ins_cost(150);
  emit %{ __ addf((FRegister)$dst$,$src$$base,$src$$disp,$src$$index,$src$$scale); %}
  ins_pipe(pipe_slow);
%}

// instruct addF_imm(regF dst, immF src)
// %{
//   match(Set dst (AddF dst src));
// 
// 
//   ins_cost(150); // XXX
//  emit(OpcP, REX_reg_mem(dst, src), OpcS, OpcT, load_immF(dst, src));
//   ins_pipe(pipe_slow);
// %}

instruct addD_reg(regD dst,regD src)%{
  match(Set dst (AddD dst src));
  ins_cost(150);
  emit %{ __ addd((FRegister)$dst$,(FRegister)$src$); %}
  ins_pipe(fpu_reg_reg);
%}

instruct addD_mem(regD dst,memory mem)%{
match(Set dst(AddD dst(LoadD mem)));
  ins_cost(150);
  emit %{  __ addd((FRegister)$dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
ins_pipe(fpu_reg_mem);
%}

instruct addD_imm(regD dst,immD_mem src)%{
  match(Set dst (AddD dst src));
  ins_cost(150); 
  emit %{ __ addd((FRegister)$dst$, noreg, (intptr_t)__ double_constant($src$)); %}
ins_pipe(fpu_reg_mem);
%}

instruct subF_reg(regF dst,regF src)%{
  match(Set dst (SubF dst src));
  ins_cost(150);
  emit %{ __ subf((FRegister)$dst$,(FRegister)$src$); %}
  ins_pipe(pipe_slow);
%}

instruct subF_mem(regF dst,memory src)%{
  match(Set dst (SubF dst (LoadF src)));
  ins_cost(150);
  emit %{ __ subf((FRegister)$dst$,$src$$base,$src$$disp,$src$$index,$src$$scale); %}  
  ins_pipe(pipe_slow);
%}

// instruct subF_imm(regF dst, immF src)
// %{
//   match(Set dst (SubF dst src));
// 
// 
//   ins_cost(150); // XXX
// //  emit(OpcP, REX_reg_mem(dst, src), OpcS, OpcT, load_immF(dst, src));
//   ins_pipe(pipe_slow);
// %}

instruct subD_reg(regD dst,regD src)%{
  match(Set dst (SubD dst src));
  ins_cost(150);
  emit %{ __ subd((FRegister)$dst$,(FRegister)$src$); %}
  ins_pipe(pipe_slow);
%}

instruct subD_mem(regD dst,memory mem)%{
match(Set dst(SubD dst(LoadD mem)));
  ins_cost(150);
  emit %{  __ subd((FRegister)$dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
ins_pipe(fpu_reg_mem);
%}

instruct subD_imm(regD dst,immD_mem src)%{
  match(Set dst (SubD dst src));
  ins_cost(150); 
  emit %{ __ subd((FRegister)$dst$, noreg, (intptr_t)__ double_constant($src$)); %}
ins_pipe(fpu_reg_mem);
%}

instruct mulF_reg(regF dst,regF src)%{
  match(Set dst (MulF dst src));
  ins_cost(150);
  emit %{ __ mulf((FRegister)$dst$,(FRegister)$src$); %}
  ins_pipe(pipe_slow);
%}

instruct mulF_mem(regF dst,memory mem)%{
match(Set dst(MulF dst(LoadF mem)));
  ins_cost(150); 
  emit %{ __ mulf((FRegister)$dst$,$mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(pipe_slow);
%}

// instruct mulF_imm(regF dst, immF src) %{
//   match(Set dst (MulF dst src));
//   ins_cost(150);
//   emit %{ 
//     unsigned char *addr = __ float_constant($src$); 
//     if (addr == NULL) Unimplemented();
//     __ mulf((FRegister)$src$, addr);
//   %}
//   ins_pipe(fpu_reg_reg);
// %}

instruct mulD_reg(regD dst,regD src)%{
  match(Set dst (MulD dst src));
  ins_cost(150);
  emit %{ __ muld((FRegister)$dst$,(FRegister)$src$); %}
  ins_pipe(fpu_reg_reg);
%}

instruct mulD_mem(regD dst,memory mem)%{
match(Set dst(MulD dst(LoadD mem)));
  ins_cost(150);
  emit %{  __ muld((FRegister)$dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
ins_pipe(fpu_reg_mem);
%}

instruct mulD_imm(regD dst,immD_mem src)%{
  match(Set dst (MulD dst src));
  ins_cost(150); 
  emit %{ __ muld((FRegister)$dst$, noreg, (intptr_t)__ double_constant($src$)); %}
ins_pipe(fpu_reg_mem);
%}

instruct divF_reg(regF dst,regF src)%{
  match(Set dst (DivF dst src));
  ins_cost(150);
  emit %{ __ divf((FRegister)$dst$,(FRegister)$src$); %}
  ins_pipe(pipe_slow);
%}

instruct divF_mem(regF dst,memory src)%{
  match(Set dst (DivF dst (LoadF src)));
  ins_cost(150);
  emit %{ __ divf((FRegister)$dst$,$src$$base,$src$$disp,$src$$index,$src$$scale); %}  
  ins_pipe(pipe_slow);
%}

// instruct divF_imm(regF dst, immF src)
// %{
//   match(Set dst (DivF dst src));
// 
// 
//   ins_cost(150); // XXX
//  emit(OpcP, REX_reg_mem(dst, src), OpcS, OpcT, load_immF(dst, src));
//   ins_pipe(pipe_slow);
// %}

instruct divD_reg(regD dst,regD src)%{
  match(Set dst (DivD dst src));
  ins_cost(150);
  emit %{ __ divd((FRegister)$dst$,(FRegister)$src$); %}
  ins_pipe(fpu_reg_reg);
%}

instruct divD_mem(regD dst,memory src)%{
  match(Set dst (DivD dst (LoadD src)));
  ins_cost(150);
  emit %{ __ divd((FRegister)$dst$,$src$$base,$src$$disp,$src$$index,$src$$scale); %}
  ins_pipe(pipe_slow);
%}

instruct sqrtF_reg_opt(regF dst,regF src)%{
  match(Set dst (ConvD2F (SqrtD (ConvF2D src))));
  ins_cost(150);
  emit %{ __ sqrts((FRegister)$dst$,(FRegister)$src$); %}
  ins_pipe(pipe_slow);
%}

instruct sqrtF_reg(regF dst,regF src)%{
match(Set dst(SqrtF src));
  ins_cost(150);
  emit %{ __ sqrts((FRegister)$dst$,(FRegister)$src$); %}
  ins_pipe(pipe_slow);
%}

instruct sqrtF_mem(regF dst,memory src)%{
  match(Set dst (ConvD2F (SqrtD (ConvF2D (LoadF src)))));
  ins_cost(150);
  emit %{ __ sqrts((FRegister)$dst$,$src$$base,$src$$disp,$src$$index,$src$$scale); %}
  ins_pipe(pipe_slow);
%}

// instruct sqrtF_imm(regF dst, immF src)
// %{
//   match(Set dst (ConvD2F (SqrtD (ConvF2D src))));
// 
// 
//   ins_cost(150); // XXX
// //  emit(OpcP, REX_reg_mem(dst, src), OpcS, OpcT, load_immF(dst, src));
//   ins_pipe(pipe_slow);
// %}

instruct sqrtD_reg(regD dst,regD src)%{
  match(Set dst (SqrtD src));
  ins_cost(150);
  emit %{ __ sqrtd((FRegister)$dst$,(FRegister)$src$); %}
  ins_pipe(pipe_slow);
%}

instruct sqrtD_mem(regD dst,memory src)%{
  match(Set dst (SqrtD (LoadD src)));
  ins_cost(150);
  emit %{ __ sqrtd((FRegister)$dst$,$src$$base,$src$$disp,$src$$index,$src$$scale); %}
  ins_pipe(pipe_slow);
%}

// instruct sqrtD_imm(regD dst, immD src)
// %{
//   match(Set dst (SqrtD src));
// 
// 
//   ins_cost(150); // XXX
// //  emit(OpcP, REX_reg_mem(dst, src), OpcS, OpcT, load_immD(dst, src));
//   ins_pipe(pipe_slow);
// %}

instruct absF_reg(regF dst)%{
  match(Set dst (AbsF dst));
  emit %{ __ absf((FRegister)$dst$); %}
  ins_pipe(pipe_slow);
%}

instruct absD_reg(regD dst)%{
  match(Set dst (AbsD dst));
  emit %{ __ absd((FRegister)$dst$); %}
  ins_pipe(fpu_reg_reg);
%}

instruct negF_reg(regF dst)%{
  match(Set dst (NegF dst));
  emit %{ __ negf((FRegister)$dst$); %}
  ins_pipe(fpu_reg_reg);
%}

instruct negD_reg(regD dst)%{
  match(Set dst (NegD dst));
  emit %{ __ negd((FRegister)$dst$); %}
  ins_pipe(fpu_reg_reg);
%}

// -----------Trig and Trancendental Instructions------------------------------
instruct cosD_reg(regD dst,regD src,rFlagsReg cr)%{
match(Set dst(CosD src));
  effect( KILL cr );
  emit %{ 
    __ sub8i(RSP,8);
    __ st8  (RSP,0,(FRegister)$src$);
    __ x87_ld8 (RSP,0);
    __ emit2(0xFFD9); // x87_cos
    __ x87_st8p(RSP,0);
    __ ld8  ((FRegister)$dst$,RSP,0);
    __ add8i(RSP,8);
  %}
  ins_pipe( pipe_slow );
%}

instruct sinD_reg(regD dst,regD src,rFlagsReg cr)%{
match(Set dst(SinD src));
  effect( KILL cr );
  emit %{ 
    __ sub8i(RSP,8);
    __ st8  (RSP,0,(FRegister)$src$);
    __ x87_ld8 (RSP,0);
    __ emit2(0xFED9); // x87_sin
    __ x87_st8p(RSP,0);
    __ ld8  ((FRegister)$dst$,RSP,0);
    __ add8i(RSP,8);
  %}
  ins_pipe( pipe_slow );
%}

instruct tanD_reg(regD dst,regD src,rFlagsReg cr)%{
match(Set dst(TanD src));
  effect( KILL cr );
  emit %{ 
    __ sub8i(RSP,8);
    __ st8  (RSP,0,(FRegister)$src$);
    __ x87_ld8 (RSP,0);
    __ emit2(0xF2D9); // x87_tan; sets TAN to ST(0) and then pushes 1.0
    __ emit2(0xD8DD); // x87 pop the 1.0
    __ x87_st8p(RSP,0);
    __ ld8  ((FRegister)$dst$,RSP,0);
    __ add8i(RSP,8);
  %}
  ins_pipe( pipe_slow );
%}

instruct log10D_reg(regD dst) %{
  // The source and result Double operands in XMM registers
  match(Set dst (Log10D dst));
  // fldlg2       ; push log_10(2) on the FPU stack; full 80-bit number
  // fyl2x        ; compute log_10(2) * log_2(x)

//              Push_SrcXD(dst),
//              Push_ResultXD(dst));

  ins_pipe( pipe_slow );
%}

instruct logD_reg(regD dst,regD src)%{
  // The source and result Double operands in XMM registers
match(Set dst(LogD src));
  emit %{ __ flog ((FRegister)$dst$, (FRegister)$src$); %}
  ins_pipe( pipe_slow );
%}



//----------Arithmetic Conversion Instructions---------------------------------

instruct roundFloat_nop(regF dst)
%{
  match(Set dst (RoundFloat dst));

  ins_cost(0);
//  emit();
  ins_pipe(empty);
%}

instruct roundDouble_nop(regD dst)
%{
  match(Set dst (RoundDouble dst));

  ins_cost(0);
//  emit();
  ins_pipe(empty);
%}

instruct convF2D_reg_reg(regD dst,regF src)%{
  match(Set dst (ConvF2D src));
  emit %{ __ cvt_f2d((FRegister)$dst$,(FRegister)$src$);  %}
  ins_pipe(fpu_reg_reg); 
%}

instruct convF2D_reg_mem(regD dst,memory src)%{
  match(Set dst (ConvF2D (LoadF src)));
  ins_cost(125);
  emit %{ __ cvt_f2d((FRegister)$dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  %}
  ins_pipe(fpu_reg_reg);
%}

instruct convD2F_reg_reg(regF dst,regD src)%{
  match(Set dst (ConvD2F src));
  emit %{ __ cvt_d2f((FRegister)$dst$,(FRegister)$src$);  %}
  ins_pipe(fpu_reg_reg);
%}

instruct convD2F_reg_mem(regF dst,memory src)%{
  match(Set dst (ConvD2F (LoadD src)));
  emit %{ __ cvt_d2f((FRegister)$dst$,$src$$base,$src$$disp,$src$$index,$src$$scale);  %}
  ins_pipe(pipe_slow);
%}

instruct convF2I_reg_reg(no_rcx_RegI dst, regF src, rcx_RegI tmp, rFlagsReg cr) %{
  match(Set dst (ConvF2I src));
effect(KILL cr,TEMP tmp);
  emit %{ __ corrected_f2i($dst$,(FRegister)$src$,$tmp$); %}
  ins_pipe(pipe_slow);
%}

instruct convF2L_reg_reg(no_rcx_RegL dst, regF src, rcx_RegI tmp, rFlagsReg cr) %{
  match(Set dst (ConvF2L src));
effect(KILL cr,TEMP tmp);
  emit %{ __ corrected_f2l($dst$,(FRegister)$src$,$tmp$); %}
  ins_pipe(pipe_slow);
%}

instruct convD2I_reg_reg(no_rcx_RegI dst, regD src, rcx_RegL tmp, rFlagsReg cr) %{
  match(Set dst (ConvD2I src));
effect(KILL cr,TEMP tmp);
  emit %{ __ corrected_d2i($dst$,(FRegister)$src$,$tmp$); %}
  ins_pipe(pipe_slow);
%}

instruct convD2L_reg_reg(no_rcx_RegL dst, regD src, rcx_RegL tmp, rFlagsReg cr) %{
  match(Set dst (ConvD2L src));
effect(KILL cr,TEMP tmp);
  emit %{ __ corrected_d2l($dst$,(FRegister)$src$,$tmp$); %}
  ins_pipe(pipe_slow);
%}

instruct convI2F_reg_mem(regF dst,memory mem)%{
match(Set dst(ConvI2F(LoadI mem)));
  emit %{ __ cvt_i2f((FRegister)$dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(pipe_slow);
%}

instruct convI2D_reg_mem(regD dst,memory mem)%{
match(Set dst(ConvI2D(LoadI mem)));
  emit %{ __ cvt_i2d((FRegister)$dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(pipe_slow);
%}

instruct convXI2F_reg(regF dst,rRegI src)%{
match(Set dst(ConvI2F src));
  emit %{ __ cvt_i2f((FRegister)$dst$,$src$);  %}
  ins_pipe(fpu_reg_reg);
%}

instruct convXI2D_reg(regD dst,rRegI src)%{
match(Set dst(ConvI2D src));
  emit %{ __ cvt_i2d((FRegister)$dst$,$src$);  %}
  ins_pipe(fpu_reg_reg);
%}

instruct convL2F_reg_reg(regF dst,rRegL src)%{
  match(Set dst (ConvL2F src));
  emit %{ __ cvt_l2f((FRegister)$dst$,$src$);  %}
  ins_pipe(pipe_slow);
%}

instruct convL2F_reg_mem(regF dst,memory mem)%{
match(Set dst(ConvL2F(LoadL mem)));
  emit %{ __ cvt_l2f((FRegister)$dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(pipe_slow);
%}

instruct convL2D_reg_reg(regD dst,rRegL src)%{
  match(Set dst (ConvL2D src));
  emit %{ __ cvt_l2d((FRegister)$dst$,$src$);  %}
  ins_pipe(pipe_slow);
%}

instruct convL2D_reg_mem(regD dst,memory mem)%{
match(Set dst(ConvL2D(LoadL mem)));
  emit %{ __ cvt_l2d((FRegister)$dst$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(pipe_slow);
%}

instruct convI2L_reg_reg(rRegL dst,rRegI src)%{
  match(Set dst (ConvI2L src));
  ins_cost(125);
  emit %{ __ movsx84($dst$,$src$); %}
  ins_pipe(ialu_reg_reg);
%}

instruct convI2L_reg_reg_pos(rRegL dst,rRegI src)%{
match(Set dst(ConvI2L src));
  predicate(_kids[0]->_leaf->as_Type()->type()->is_int()->_lo >= 0 &&
            _kids[0]->_leaf->as_Type()->type()->is_int()->_hi >= 0);
  predicate(((const TypeNode*) n)->type()->is_long()->_hi ==
            (unsigned int) ((const TypeNode*) n)->type()->is_long()->_hi &&
            ((const TypeNode*) n)->type()->is_long()->_lo ==
            (unsigned int) ((const TypeNode*) n)->type()->is_long()->_lo);
  emit %{ __ mov4($dst$,$src$); %}
  ins_pipe(ialu_reg_reg);
%}

// Zero-extend convert int to long
instruct convI2L_reg_reg_zex(rRegL dst,rRegI src,immL_32bits mask)%{
  match(Set dst (AndL (ConvI2L src) mask));
  emit %{ __ mov4($dst$,$src$); %}
  ins_pipe(ialu_reg_reg);
%}

// Zero-extend convert int to long
instruct convI2L_reg_mem_zex(rRegL dst,memory src,immL_32bits mask)%{
  match(Set dst (AndL (ConvI2L (LoadI src)) mask));
  emit %{ __ ld4($dst$,$src$$base,$src$$disp,$src$$index,$src$$scale); %}
  ins_pipe(ialu_reg_mem);
%}

instruct zerox_long_reg_reg(rRegL dst, rRegL src, immL_32bits mask)
%{
  match(Set dst (AndL src mask));
  emit %{ __ mov4($dst$,$src$); %}
  ins_pipe(ialu_reg_reg);
%}

instruct convL2I_reg_reg(rRegI dst,rRegL src)%{
  match(Set dst (ConvL2I src));
  emit %{ __ move4($dst$,$src$); /*may not copy so high bits may not be sign-ext */ %}
  ins_pipe(ialu_reg_reg);
%}


instruct MoveF2I_stack_reg(rRegI dst, stackSlotF src) %{
  match(Set dst (MoveF2I src));
  effect(DEF dst, USE src);
  ins_cost(125);
  emit %{ __ ld4((Register)$dst$,$src$$base,$src$$disp); %}
  ins_pipe(ialu_reg_mem);
%}

instruct MoveI2F_stack_reg(regF dst, stackSlotI src) %{
  match(Set dst (MoveI2F src));
  effect(DEF dst, USE src);
  ins_cost(125);
  emit %{ __ ld4((FRegister)$dst$,$src$$base,$src$$disp); %}
  ins_pipe(pipe_slow);
%}

instruct MoveD2L_stack_reg(rRegL dst, stackSlotD src) %{
  match(Set dst (MoveD2L src));
  effect(DEF dst, USE src);
  ins_cost(125);
  emit %{ __ ld8((Register)$dst$,$src$$base,$src$$disp); %}
  ins_pipe(ialu_reg_mem);
%}

instruct MoveL2D_stack_reg(regD dst, stackSlotL src) %{
  match(Set dst (MoveL2D src));
  effect(DEF dst, USE src);
  ins_cost(125);
  emit %{ __ ld8((FRegister)$dst$,$src$$base,$src$$disp); %}
  ins_pipe(pipe_slow);
%}

instruct MoveF2I_reg_stack(stackSlotI dst, regF src) %{
  match(Set dst (MoveF2I src));
  effect(DEF dst, USE src);
  ins_cost(125);
  emit %{ __ st4($dst$$base,$dst$$disp,(FRegister)$src$); %}
  ins_pipe(pipe_slow);
%}

instruct MoveI2F_reg_stack(stackSlotF dst, rRegI src) %{
  match(Set dst (MoveI2F src));
  effect(DEF dst, USE src);
  ins_cost(125);
  emit %{ __ st4($dst$$base,$dst$$disp,(Register)$src$); %}
  ins_pipe( ialu_mem_reg );
%}

instruct MoveD2L_reg_stack(stackSlotL dst, regD src) %{
  match(Set dst (MoveD2L src));
  effect(DEF dst, USE src);
  ins_cost(125);
  emit %{ __ st8($dst$$base,$dst$$disp,(FRegister)$src$); %}
  ins_pipe(pipe_slow);
%}

instruct MoveL2D_reg_stack(stackSlotD dst, rRegL src) %{
  match(Set dst (MoveL2D src));
  effect(DEF dst, USE src);
  ins_cost(100);
  emit %{ __ st8($dst$$base,$dst$$disp,(Register)$src$); %}
  ins_pipe(ialu_mem_reg);
%}

instruct MoveF2I_reg_reg(rRegI dst, regF src) %{
  match(Set dst (MoveF2I src));
  effect(DEF dst, USE src);
  ins_cost(85);
  emit %{ __ mov4($dst$,(FRegister)$src$); %}
  ins_pipe( pipe_slow );
%}

instruct MoveD2L_reg_reg(rRegL dst, regD src) %{
  match(Set dst (MoveD2L src));
  effect(DEF dst, USE src);
  ins_cost(85);
  emit %{ __ mov8($dst$,(FRegister)$src$); %}
  ins_pipe( pipe_slow );
%}

// The next instructions have long latency and use Int unit. Set high cost.
instruct MoveI2F_reg_reg(regF dst, rRegI src) %{
  match(Set dst (MoveI2F src));
  effect(DEF dst, USE src);
  ins_cost(300);
  emit %{ __ mov4((FRegister)$dst$,$src$); %}
  ins_pipe( pipe_slow );
%}

// Replicate scalar to packed byte (1 byte) values in xmm
instruct Repl8B_reg(regD dst, regD src) %{
  match(Set dst (Replicate8B src));

//  emit( pshufd_8x8(dst, src));
  ins_pipe( pipe_slow );
%}

// Replicate scalar to packed byte (1 byte) values in xmm
instruct Repl8B_rRegI(regD dst, rRegI src) %{
  match(Set dst (Replicate8B src));

//  emit( mov_i2x(dst, src), pshufd_8x8(dst, dst));
  ins_pipe( pipe_slow );
%}

// Replicate scalar zero to packed byte (1 byte) values in xmm
instruct Repl8B_immI0(regD dst, immI0 zero) %{
  match(Set dst (Replicate8B zero));

//  emit( pxor(dst, dst));
  ins_pipe( fpu_reg_reg );
%}

// Replicate scalar to packed shore (2 byte) values in xmm
instruct Repl4S_reg(regD dst, regD src) %{
  match(Set dst (Replicate4S src));

//  emit( pshufd_4x16(dst, src));
  ins_pipe( fpu_reg_reg );
%}

// Replicate scalar to packed shore (2 byte) values in xmm
instruct Repl4S_rRegI(regD dst, rRegI src) %{
  match(Set dst (Replicate4S src));

//  emit( mov_i2x(dst, src), pshufd_4x16(dst, dst));
  ins_pipe( fpu_reg_reg );
%}

// Replicate scalar zero to packed short (2 byte) values in xmm
instruct Repl4S_immI0(regD dst, immI0 zero) %{
  match(Set dst (Replicate4S zero));

//  emit( pxor(dst, dst));
  ins_pipe( fpu_reg_reg );
%}

// Replicate scalar to packed char (2 byte) values in xmm
instruct Repl4C_reg(regD dst, regD src) %{
  match(Set dst (Replicate4C src));

//  emit( pshufd_4x16(dst, src));
  ins_pipe( fpu_reg_reg );
%}

// Replicate scalar to packed char (2 byte) values in xmm
instruct Repl4C_rRegI(regD dst, rRegI src) %{
  match(Set dst (Replicate4C src));

//  emit( mov_i2x(dst, src), pshufd_4x16(dst, dst));
  ins_pipe( fpu_reg_reg );
%}

// Replicate scalar zero to packed char (2 byte) values in xmm
instruct Repl4C_immI0(regD dst, immI0 zero) %{
  match(Set dst (Replicate4C zero));

//  emit( pxor(dst, dst));
  ins_pipe( fpu_reg_reg );
%}

// Replicate scalar to packed integer (4 byte) values in xmm
instruct Repl2I_reg(regD dst, regD src) %{
  match(Set dst (Replicate2I src));

//  emit( pshufd(dst, src, 0x00));
  ins_pipe( fpu_reg_reg );
%}

// Replicate scalar to packed integer (4 byte) values in xmm
instruct Repl2I_rRegI(regD dst, rRegI src) %{
  match(Set dst (Replicate2I src));

//  emit( mov_i2x(dst, src), pshufd(dst, dst, 0x00));
  ins_pipe( fpu_reg_reg );
%}

// Replicate scalar zero to packed integer (2 byte) values in xmm
instruct Repl2I_immI0(regD dst, immI0 zero) %{
  match(Set dst (Replicate2I zero));

//  emit( pxor(dst, dst));
  ins_pipe( fpu_reg_reg );
%}

// Replicate scalar to packed single precision floating point values in xmm
instruct Repl2F_reg(regD dst, regD src) %{
  match(Set dst (Replicate2F src));

//  emit( pshufd(dst, src, 0xe0));
  ins_pipe( fpu_reg_reg );
%}

// Replicate scalar to packed single precision floating point values in xmm
instruct Repl2F_regF(regD dst, regF src) %{
  match(Set dst (Replicate2F src));

//  emit( pshufd(dst, src, 0xe0));
  ins_pipe( fpu_reg_reg );
%}

// Replicate scalar to packed single precision floating point values in xmm
instruct Repl2F_immF0(regD dst, immF0 zero) %{
  match(Set dst (Replicate2F zero));

//  emit( pxor(dst, dst));
  ins_pipe( fpu_reg_reg );
%}


// =======================================================================
// fast clearing of an array
instruct rep_stos(rcx_RegL cnt, rdi_RegP base, rax_RegI zero, Universe dummy,
                  rFlagsReg cr)
%{
  match(Set dummy (ClearArray cnt base));
  effect(USE_KILL cnt, USE_KILL base, KILL zero, KILL cr);


//  emit(opc_reg_reg(0x33, RAX, RAX), // xorl %eax, %eax
  ins_pipe(pipe_slow);
%}

instruct string_compare(rdi_RegP str1, rsi_RegP str2, regD tmp1, regD tmp2,
                        rax_RegI tmp3, rbx_RegI tmp4, rcx_RegI result, rFlagsReg cr) %{
  match(Set result (StrComp str1 str2));
  effect(TEMP tmp1, TEMP tmp2, USE_KILL str1, USE_KILL str2, KILL tmp3, KILL tmp4, KILL cr);
ins_cost(500);
  emit %{
    Label RCX_GOOD_LABEL, LENGTH_DIFF_LABEL,
      POP_LABEL, DONE_LABEL, CONT_LABEL,
      WHILE_HEAD_LABEL;

    // Get the char arrays from the Strings.
    __ ldref_lvb( RInOuts::a, RAX, RCX, RKeepIns::a, RSI, java_lang_String::value_offset_in_bytes(), false );
    __ ldref_lvb( RInOuts::a, RBX, RCX, RKeepIns::a, RDI, java_lang_String::value_offset_in_bytes(), false );
    
    // Compute the minimum of the string lengths(rsi) and the
    // difference of the string lengths (stack)

    // do the conditional move stuff
    __ ldz4    (RDI, RBX, arrayOopDesc::length_offset_in_bytes());
    __ ldz4    (RSI, RAX, arrayOopDesc::length_offset_in_bytes());
    __ mov4    (RCX, RDI);
    __ sub4    (RDI, RSI);
__ push(RDI);
    __ cmov4le (RSI, RCX);

    // Is the minimum length zero?
__ bind(RCX_GOOD_LABEL);
    __ test4   (RSI,RSI);
    __ jze     (LENGTH_DIFF_LABEL);

    // Load first characters
    __ add8i   (RBX, arrayOopDesc::length_offset_in_bytes()+4);
    __ add8i   (RAX, arrayOopDesc::length_offset_in_bytes()+4);
    __ ldz2    (RCX, RBX, 0);
    __ ldz2    (RDI, RAX, 0);

    // Compare first characters
    __ sub4    (RCX, RDI);
    __ jnz     (POP_LABEL);
    __ dec4    (RSI);
    __ jze     (LENGTH_DIFF_LABEL);

    {
      // Check after comparing first character to see if strings are equivalent
      Label LSkip2;
      // Check if the strings start at same location
      __ cmp8  (RBX, RAX); // TODO: ptr comparison okay for us?
      __ jne   (LSkip2);

      // Check if the length difference is zero (from stack)
      __ cmp4i (RSP, 0, 0x0);
      __ jeq   (LENGTH_DIFF_LABEL);

      // Strings might not be equivalent
__ bind(LSkip2);
    }

    // Advance to next character
    __ add8i   (RAX, 2);
    __ add8i   (RBX, 2);

    // Shift RAX and RBX to the end of the arrays, negate min
    __ lea     (RAX, RAX, 0, RSI, 1);
    __ lea     (RBX, RBX, 0, RSI, 1);
    __ neg8    (RSI);

    // Compare the rest of the characters
__ bind(WHILE_HEAD_LABEL);
    __ ldz2    (RCX, RBX, 0, RSI, 1);
    __ ldz2    (RDI, RAX, 0, RSI, 1);
    __ sub4    (RCX, RDI);
    __ jnz     (POP_LABEL);
    __ inc8    (RSI);
    __ jnz     (WHILE_HEAD_LABEL);

    // Strings are equal up to min length.  Return the length difference.
__ bind(LENGTH_DIFF_LABEL);
__ pop(RCX);
__ jmp(DONE_LABEL);

    // Discard the stored length difference
__ bind(POP_LABEL);
    __ add8i   (RSP, 8);

    // That's it
__ bind(DONE_LABEL);
  %}
  ins_pipe( pipe_slow );
%}

instruct string_indexof(rsi_RegP str1, rdi_RegP str2, regD tmp1, rax_RegI tmp2,
                        rcx_RegI tmp3, rdx_RegI tmp4, rbx_RegI result, rFlagsReg cr)
%{
match(Set result(StrIndexOf str1 str2));
  effect(TEMP tmp1, USE_KILL str1, USE_KILL str2, KILL tmp2, KILL tmp3, KILL tmp4, KILL cr);


//  emit( enc_String_IndexOf(str1, str2, tmp1, tmp2, tmp3, tmp4, result) );
  ins_pipe( pipe_slow );
%}

// fast string equals
instruct string_equals(rRegP str1, rRegP str2, rRegI result,
                       rRegI tmp1, rRegI tmp2, rRegI tmp3, rRegI tmp4, regD xtmp1, regD xtmp2, rFlagsReg cr) %{
match(Set result(StrEquals str1 str2));
  effect(USE str1, USE str2, KILL cr, TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP xtmp1, TEMP xtmp2);
  emit %{
Label fail,done;
    // Get the char arrays from the Strings.
    __ ldref_lvb( RInOuts::a, $tmp1$, $tmp2$, RKeepIns::a, $str1$, java_lang_String::value_offset_in_bytes(), false );
    __ ldref_lvb( RInOuts::a, $tmp2$, $tmp3$, RKeepIns::a, $str2$, java_lang_String::value_offset_in_bytes(), false );
    __ prim_arrays_equal(2, RInOuts::a, $tmp1$, $tmp2$, $tmp3$, $tmp4$,
                         (FRegister)$xtmp1$, (FRegister)$xtmp2$, fail);
    __ mov8i($result$,1);            // Return 1 for success
    __ jmp  (done);
__ bind(fail);
    __ mov8i($result$,0);            // Hot fail path
__ bind(done);
  %}
  ins_pipe( pipe_slow );
%}

// fast array equals
instruct array_equals(rdi_RegP ary1, rsi_RegP ary2, regD tmp1, regD tmp2, rax_RegI tmp3,
rbx_RegI tmp4,rcx_RegI result,rFlagsReg cr)
%{
match(Set result(AryEq ary1 ary2));
  effect(TEMP tmp1, TEMP tmp2, USE_KILL ary1, USE_KILL ary2, KILL tmp3, KILL tmp4, KILL cr);
  //ins_cost(300);


//  emit( enc_Array_Equals(ary1, ary2, tmp1, tmp2, tmp3, tmp4, result) );
  ins_pipe( pipe_slow );
%}

//----------Control Flow Instructions------------------------------------------
// Signed compare Instructions

instruct compI_rReg(rFlagsReg cr,rRegI op1,rRegI op2)%{
  match(Set cr (CmpI op1 op2));
  effect(DEF cr, USE op1, USE op2);
  emit %{ __ cmp4($op1$,$op2$); %}
  ins_pipe(ialu_cr_reg_reg);
%}

instruct compI_rReg_imm(rFlagsReg cr,rRegI op1,immI op2)%{
  match(Set cr (CmpI op1 op2));
  emit %{ __ cmp4i($op1$,$op2$); %}
  ins_pipe(ialu_cr_reg_imm);
%}

instruct compI_rReg_mem(rFlagsReg cr,rRegI op1,memory mem)%{
match(Set cr(CmpI op1(LoadI mem)));
  ins_cost(125);
  emit %{ __ cmp4($op1$,$mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  %}
  ins_pipe(ialu_cr_reg_mem);
%}

instruct compI_mem_imm(rFlagsReg cr,memory mem,immI op2)%{
  match(Set cr (CmpI (LoadI mem) op2));
  ins_cost(125);
  emit %{ __ cmp4i($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,$op2$);  %}
ins_pipe(ialu_cr_mem_imm);
%}

instruct testI_reg(rFlagsReg cr,rRegI src,immI0 zero)%{
  match(Set cr (CmpI src zero));
  emit %{ __ test4($src$,$src$);  %}
  ins_pipe(ialu_cr_reg_imm);
%}

instruct testI_reg_imm(rFlagsReg cr,rRegI src,immI con,immI0 zero)%{
  match(Set cr (CmpI (AndI src con) zero));
  emit %{ __ testi($src$,$con$);  %}
  ins_pipe(ialu_cr_reg_imm);
%}

instruct testL_reg_imm_eq(rFlagsReg cr,rRegL src,immIPos con,immI0 zero)%{
  match(Set cr (CmpI (AndI (ConvL2I src) con) zero));
  emit %{ __ testi($src$,$con$);  %}
  ins_pipe(ialu_cr_reg_imm);
%}

instruct testI_reg_mem(rFlagsReg cr,rRegI src,memory mem,immI0 zero)%{
  match(Set cr (CmpI (AndI src (LoadI mem)) zero));
  ins_cost(125);
  emit %{ __ test4($src$,$mem$$base,$mem$$disp,$mem$$index,$mem$$scale); %}
  ins_pipe(ialu_cr_reg_mem);
%}

// Bit test match is a little odd, because of integer-math shaping operations.
// We expect to see small masks (like a single bit) shifted right until the
// lowest bit is set - hence making the mask small.  In this case, if the mask
// is a 1 we can swallow the shift also into the bit-test.
instruct btx4i(rFlagsRegEQ2Carry cr, rRegI src, immI shf, immI1 con1, immI0 zero) %{
  match(Set cr (CmpI (AndI (URShiftI src shf) con1 ) zero));
  emit %{ __ btx4i($src$,$shf$);  %}
ins_pipe(ialu_cr_reg_imm);
%}


// Unsigned compare Instructions; really, same as signed except they
// produce an rFlagsRegU instead of rFlagsReg.
instruct compU_rReg(rFlagsRegU cr,rRegI op1,rRegI op2)%{
  match(Set cr (CmpU op1 op2));
  emit %{ __ cmp4($op1$,$op2$); %}
  ins_pipe(ialu_cr_reg_reg);
%}

instruct compU_rReg_imm(rFlagsRegU cr,rRegI op1,immI op2)%{
  match(Set cr (CmpU op1 op2));
  emit %{ __ cmp4i($op1$,$op2$); %}
  ins_pipe(ialu_cr_reg_imm);
%}

instruct compU_rReg_mem(rFlagsRegU cr, rRegI src, memory mem) %{
match(Set cr(CmpU src(LoadRange mem)));
  ins_cost(125);
  emit %{ __ cmp4($src$,$mem$$base,$mem$$disp,$mem$$index,$mem$$scale); %}
  ins_pipe(ialu_cr_reg_mem);
%}

instruct testU_reg(rFlagsRegU cr,rRegI src,immI0 zero)%{
  match(Set cr (CmpU src zero));
  emit %{ __ test4($src$,$src$);  %}
  ins_pipe(ialu_cr_reg_imm);
%}

instruct compP_rReg(rFlagsRegU cr,rRegP op1,rRegP op2)%{
  match(Set cr (CmpP op1 op2));
  effect( DEF cr, USE op1, USE op2);
  emit %{ 
    // Klass-ptrs agree on KID-ness
    const TypeKlassPtr *k1 = in(1)->bottom_type()->isa_klassptr();
    const TypeKlassPtr *k2 = in(2)->bottom_type()->isa_klassptr();
    assert0( !k1 == !k2 );
    if( k1 ) assert0( k1->_is_kid == k2->_is_kid );
    if( k1 && k1->_is_kid ) {
      __ cmp4($op1$,$op2$);     // compare kids actually
    } else 
      __ cmp8($op1$,$op2$); 
  %}
  ins_pipe(ialu_cr_reg_reg);
%}

instruct compP_rReg_imm(rFlagsRegU cr,rRegP op1,immP op2)%{
  match(Set cr (CmpP op1 op2));
  predicate( n->in(1)->bottom_type()->isa_klassptr() &&
             n->in(1)->bottom_type()->is_klassptr()->_is_kid );
  emit %{
    const TypeKlassPtr *k1 = $op2$->is_klassptr();
    int idx = ((ciKlass*)k1->const_oop())->klassId();
    __ cmp4i($op1$,idx);
    __ record_constant_oop(idx);
  %}
  ins_pipe(ialu_cr_reg_imm);
%}

// This combo does not appear to help
//instruct cmp_kid(rFlagsRegU cr, rRegP src, immP op2, rRegP tmp) %{
//  match(Set cr (CmpP (GetKID src) op2));
//  effect( TEMP tmp );
//  predicate( n->in(1)->bottom_type()->isa_klassptr() &&
//             n->in(1)->bottom_type()->is_klassptr()->_is_kid );
//  emit %{ 
//    if( KIDInRef ) {
//      Unimplemented();
//    }
//    const TypeKlassPtr *k1 = $op2$->is_klassptr();
//    jlong idx = ((ciKlass*)k1->const_oop())->klassId();
//    __ record_constant_oop(idx);
//    __ ldz4 ($tmp$,$src$,oopDesc::mark_offset_in_bytes()+4);
//    __ shr4i($tmp$,markWord::kid_shift-32);
//    __ cmp4i($tmp$,idx);
//    // I tried a load/and/cmp combo vs a load/shift/cmp combo.
//    // No difference.
//    //__ and4i($tmp$,(markWord::kid_mask_in_place>>32));
//    //__ cmp4i($tmp$,(idx<<(markWord::kid_shift))>>32);
//  %}
//  ins_pipe(ialu_reg_reg);
//%}

// instruct compP_rReg_mem(rFlagsRegU cr, rRegP op1, memory mem) %{
//   match(Set cr (CmpP op1 (LoadP mem)));
//   ins_cost(125);
//   emit %{  
//     // No KIDs if loading from memory via 'LoadP' instead of 'LoadKlass'
//     const TypeKlassPtr *k1 = in(1)->bottom_type()->isa_klassptr();
//     const TypeKlassPtr *k2 = in(2)->bottom_type()->isa_klassptr();
//     assert0( !k1 == !k2 );
//     if( k1 ) assert0( !k1->_is_kid && !k2->_is_kid );
//     __ cmp8($op1$, $mem$$base,$mem$$disp,$mem$$index,$mem$$scale);  
//   %}
//   ins_pipe(ialu_cr_reg_mem);
// %}

// This will generate a signed flags result. This should be OK since
// any compare to a zero should be eq/neq.
instruct testP_reg(rFlagsReg cr,rRegP src,immP0 zero)%{
  match(Set cr (CmpP src zero));
effect(DEF cr,USE src);
  emit %{ 
    const TypeKlassPtr *k1 = in(1)->bottom_type()->isa_klassptr();
    if( k1 && k1->_is_kid ) {
Unimplemented();//kid-vs-0
    } else
      __ test8($src$,$src$);  
  %}
  ins_pipe(ialu_cr_reg_imm);
%}

// Yanked all unsigned pointer compare operations.
// Pointer compares are done with CmpP which is already unsigned.

instruct compL_rReg(rFlagsReg cr,rRegL op1,rRegL op2)%{
  match(Set cr (CmpL op1 op2));
  emit %{ __ cmp8($op1$,$op2$); %}
  ins_pipe(ialu_cr_reg_reg);
%}

instruct compL_rReg_imm(rFlagsReg cr,rRegL op1,immL32 op2)%{
  match(Set cr (CmpL op1 op2));
  emit %{ __ cmp8i($op1$,$op2$); %}
  ins_pipe(ialu_cr_reg_imm);
%}

instruct compL_rReg_mem(rFlagsReg cr,rRegL op1,memory op2)%{
  match(Set cr (CmpL op1 (LoadL op2)));
  ins_cost(125);
  emit %{ __ cmp8($op1$,$op2$$base,$op2$$disp,$op2$$index,$op2$$scale); %}
  ins_pipe(ialu_cr_reg_mem);
%}

instruct compL_mem_imm(rFlagsReg cr, memory mem, immL32 op2) %{
  match(Set cr (CmpL (LoadL mem) op2));
  ins_cost(125);
  emit %{ __ cmp8i($mem$$base,$mem$$disp,$mem$$index,$mem$$scale,$op2$);  %}
ins_pipe(ialu_cr_mem_imm);
%}

instruct testL_reg(rFlagsReg cr,rRegL src,immL0 zero)%{
  match(Set cr (CmpL src zero));
  emit %{ __ test8($src$,$src$); %}
  ins_pipe(ialu_cr_reg_imm);
%}

instruct testL_reg_imm(rFlagsReg cr,rRegL src,immL32 con,immL0 zero)%{
  match(Set cr (CmpL (AndL src con) zero));
  emit %{ __ testi($src$,$con$); %}
  ins_pipe(ialu_cr_reg_imm);
%}

instruct testL_reg_mem(rFlagsReg cr, rRegL src, memory mem, immL0 zero) %{
  match(Set cr (CmpL (AndL src (LoadL mem)) zero));
  ins_cost(125);
  emit %{ __ test8($src$,$mem$$base,$mem$$disp,$mem$$index,$mem$$scale); %}
  ins_pipe(ialu_cr_reg_mem);
%}

// Manifest a CmpL result in an integer register.  Very painful.
// This is the test to avoid.
instruct cmpL3_reg_reg(rRegI dst,rRegL src1,rRegL src2,rFlagsReg flags)%{
  match(Set dst (CmpL3 src1 src2));
  effect(KILL flags);
  ins_cost(275);
  emit %{
Label done;
    __ cmp8 ($src1$,$src2$); 
    __ mov8i($dst$,-1,false);
    __ jlt  (done);
    __ setnz($dst$);
    __ movsx81($dst$,$dst$);
__ bind(done);
  %}
  ins_pipe(pipe_slow);
%}

// Convert Pointer to Boolean
instruct testP_reg_expand(rFlagsReg cr, rRegP src1, rRegP src2) %{
match(Set cr(CmpL src1 src2));
effect(DEF cr,USE src1,USE src2);
  emit %{  __ test8($src1$,$src2$);   %}
  ins_pipe(ialu_cr_reg_imm);
%}

// Map zero to zero, all else to 1.
instruct setnz(rRegI dst,rFlagsRegU cr)%{
effect(USE_DEF dst,USE cr);
  emit %{  __ setnz($dst$);  %}
ins_pipe(ialu_reg);
%}

instruct convP2B(rRegI dst,rRegP src)%{
match(Set dst(Conv2B src));
  effect( DEF dst, USE src );
ins_cost(200);
  expand %{
rFlagsRegU cr;
loadConI0_expand(dst,cr);
testP_reg_expand(cr,src,src);
setnz(dst,cr);
  %}
  // Note that because of the way pointers are set-up at Azul, a slightly
  // possibly better instruction sequence is possible here:
  // dst = shr8i(neg8(src), 63), but shifts were apparently sub-optimal
  // on Pentium.
%}

// Convert Pointer to Boolean
instruct seteq(rRegI dst,rFlagsRegU cr)%{
effect(USE_DEF dst,USE cr);
  emit %{  __ setz($dst$);  %}
  ins_pipe(ialu_reg);
%}

 instruct convP2B_flip(rRegI dst, rRegP src, immI1 one) %{
match(Set dst(XorI(Conv2B src)one));
  effect( DEF dst, USE src );
ins_cost(200);
  expand %{
rFlagsRegU cr;
loadConI0_expand(dst,cr);
testP_reg_expand(cr,src,src);
seteq(dst,cr);
  %}
%}

//----------Max and Min--------------------------------------------------------
// Min Instructions

instruct cmovI_reg_g(rRegI dst,rRegI src,rFlagsReg cr)%{
  effect(USE_DEF dst, USE src, USE cr);
  emit %{ __ cmov4gt($dst$,$src$); %}
  ins_pipe(pipe_cmov_reg);
%}


instruct minI_rReg(rRegI dst,rRegI src)%{
  match(Set dst (MinI dst src));
  ins_cost(200);
  expand %{
    rFlagsReg cr;
    compI_rReg(cr, dst, src);
    cmovI_reg_g(dst, src, cr);
  %}
%}

instruct cmovI_reg_l(rRegI dst,rRegI src,rFlagsReg cr)%{
  effect(USE_DEF dst, USE src, USE cr);
  emit %{ __ cmov4lt($dst$,$src$); %}
  ins_pipe(pipe_cmov_reg);
%}


instruct maxI_rReg(rRegI dst,rRegI src)%{
  match(Set dst (MaxI dst src));
  ins_cost(200);
  expand %{
    rFlagsReg cr;
    compI_rReg(cr, dst, src);
    cmovI_reg_l(dst, src, cr);
  %}
%}

// ============================================================================
// Branch Instructions

// Jump Direct - Label defines a relative address from JMP+1
instruct jmpDir(label labl)%{
  match(Goto);
  effect(USE labl);
  ins_cost(300);
  emit %{
    __ jmp($labl$);
  %}
  ins_pipe(pipe_jmp);
%}

// Jump Direct Conditional - Label defines a relative address from Jcc+1
instruct jmpCon(cmpOp cop,rFlagsReg cr,label labl)%{
  match(If cop cr);
  effect(USE labl);
  ins_cost(300);
  emit %{
    switch( $cop$ ) {
    case BoolTest::eq:  __ jeq($labl$);  break;
    case BoolTest::ne:  __ jne($labl$);  break;
    case BoolTest::lt:  __ jlt($labl$);  break;
    case BoolTest::gt:  __ jgt($labl$);  break;
    case BoolTest::le:  __ jle($labl$);  break;
    case BoolTest::ge:  __ jge($labl$);  break;
    default: ShouldNotReachHere();
    }
  %}
  ins_pipe(pipe_jcc);
%}

// Jump based on 'testi reg,imm' which has the inverted sense
// of flags, so the jump sense is also inverted.
instruct jmpConEQ(cmpOpEQ cop,rFlagsRegEQ cr,label labl)%{
  match(If cop cr);
  effect(USE labl);
  ins_cost(300);
  emit %{
    switch( $cop$ ) {
    case BoolTest::eq:  __ jne($labl$);  break;
    case BoolTest::ne:  __ jeq($labl$);  break;
    default: ShouldNotReachHere();
    }
  %}
ins_pipe(pipe_jcc);
%}

// Jump based on 'btx4i reg,imm' which sets the carry
// flags, so the jump sense confused.
instruct jmpConEQviaCarry(cmpOpEQ cop,rFlagsRegEQ2Carry cr,label labl)%{
  match(If cop cr);
  effect(USE labl);
  ins_cost(300);
  emit %{
    switch( $cop$ ) {
    case BoolTest::eq:  __ jae($labl$);  break; // carry clear - so bit was 0 so was 'eq 0'
    case BoolTest::ne:  __ jbl($labl$);  break; // carry set   - so bit was 1 so was 'ne 0'
    default: ShouldNotReachHere();
    }
  %}
ins_pipe(pipe_jcc);
%}

// Jump Direct Conditional - Label defines a relative address from Jcc+1
instruct jmpLoopEnd(cmpOp cop,rFlagsReg cr,label labl)%{
  match(CountedLoopEnd cop cr);
  effect(USE labl);
  ins_cost(300);
  emit %{
    switch( $cop$ ) {
    case BoolTest::eq:  __ jeq($labl$);  break;
    case BoolTest::ne:  __ jne($labl$);  break;
    case BoolTest::lt:  __ jlt($labl$);  break;
    case BoolTest::gt:  __ jgt($labl$);  break;
    case BoolTest::le:  __ jle($labl$);  break;
    case BoolTest::ge:  __ jge($labl$);  break;
    default: ShouldNotReachHere();
    }
  %}
  ins_pipe(pipe_jcc);
%}

// Jump Direct Conditional - Label defines a relative address from Jcc+1
instruct jmpLoopEndU(cmpOpU cop,rFlagsRegU cmp,label labl)%{
  match(CountedLoopEnd cop cmp);
  effect(USE labl);

  ins_cost(300);

//  emit(Jcc(cop, labl));
  ins_pipe(pipe_jcc);
%}

instruct jmpLoopEndUCF(cmpOpUCF cop,rFlagsRegUCF cmp,label labl)%{
  match(CountedLoopEnd cop cmp);
  effect(USE labl);

ins_cost(200);

//  emit(Jcc(cop, labl));
ins_pipe(pipe_jcc);
%}

// Jump Direct Conditional - using unsigned comparison
instruct jmpConU(cmpOpU cop,rFlagsRegU cmp,label labl)%{
  match(If cop cmp);
  effect(USE labl);
  ins_cost(300);
  emit %{
    switch( $cop$ ) {
    case BoolTest::eq:  __ jeq($labl$);  break;
    case BoolTest::ne:  __ jne($labl$);  break;
    case BoolTest::lt:  __ jbl($labl$);  break;
    case BoolTest::gt:  __ jab($labl$);  break;
    case BoolTest::le:  __ jbe($labl$);  break;
    case BoolTest::ge:  __ jae($labl$);  break;
    default: ShouldNotReachHere();
    }
  %}
  ins_pipe(pipe_jcc);
%}

instruct jmpConUCF(cmpOpUCF cop,rFlagsRegUCF cmp,label labl)%{
  match(If cop cmp);
  effect(USE labl);
  ins_cost(200);
  emit %{
    switch( $cop$ ) {
    case BoolTest::eq:  __ jeq($labl$);  break;
    case BoolTest::ne:  __ jne($labl$);  break;
    case BoolTest::lt:  __ jbl($labl$);  break;
    case BoolTest::gt:  __ jab($labl$);  break;
    case BoolTest::le:  __ jbe($labl$);  break;
    case BoolTest::ge:  __ jae($labl$);  break;
    default: ShouldNotReachHere();
    }
  %}
ins_pipe(pipe_jcc);
%}

instruct jmpConUCF2(cmpOpUCF2 cop,rFlagsRegUCF cmp,label labl)%{
  match(If cop cmp);
  effect(USE labl);
  ins_cost(200);
  emit %{
Label done;
    switch( $cop$ ) {
    case BoolTest::eq: __ jpe(done  ); __ jeq($labl$); break;
    case BoolTest::ne: __ jpe($labl$); __ jne($labl$); break;
    default: ShouldNotReachHere();
    }
    __ bind(done);
  %}
ins_pipe(pipe_jcc);
%}

// ============================================================================
// The 2nd slow-half of a subtype check.  Scan the subklass's 2ndary
// superklass array for an instance of the superklass.  Set a hidden
// internal cache on a hit (cache is checked with exposed code in
// gen_subtype_check()).  Return NZ for a miss or zero for a hit.  The
// encoding ALSO sets flags.

instruct partialSubtypeCheck(rax_RegI result, r09_RegP sub, rax_RegP super, rFlagsReg cr) %{
  match( Set result (PartialSubtypeCheck sub super));
  effect(KILL cr);
  ins_cost(1100);  // slightly larger than the next version
  emit %{ __ call(StubRoutines::x86::partial_subtype_check()); %}
  ins_pipe(pipe_slow);
%}

//instruct partialSubtypeCheck_vs_zero(rFlagsReg cr, rax_RegI rax_res, r09_RegP sub, rax_RegP super, immI0 zero) %{
//  match( Set cr (CmpI (PartialSubtypeCheck sub super) zero));
//  effect(KILL rax_res);
//  ins_cost(1000);
//  emit %{ 
//    __ call(StubRoutines::x86::partial_subtype_check()); 
//    __ test4(RAX,RAX);
//  %}
//  ins_pipe(pipe_slow);
//%}

// ============================================================================
// inlined locking and unlocking

instruct cmpFastLock(rRegP object, label labl, rRegP Rtmp, rFlagsReg cr) %{
  match(FastLock object);
effect(USE labl,TEMP Rtmp,KILL cr);
  ins_cost(300);
  emit %{ 
    __ gettid($Rtmp$);
    __ shl4i($Rtmp$,markWord::lock_bits);
    __ cmp4 ($Rtmp$,$object$,oopDesc::mark_offset_in_bytes()); // compare only the low 4 bytes
    __ jne  ($labl$);           // slower path case
  %}
  ins_pipe(pipe_slow);
%}

instruct cmpFastUnlock(rRegP object, label labl, rRegP Rtmp, rFlagsReg cr) %{
  match(FastUnlock object);
effect(USE labl,TEMP Rtmp,KILL cr);
  ins_cost(300);
  emit %{ 
    __ gettid($Rtmp$);
    __ shl4i($Rtmp$,markWord::lock_bits);
    __ cmp4 ($Rtmp$,$object$,oopDesc::mark_offset_in_bytes()); // compare only the low 4 bytes
    __ jne  ($labl$);           // slower path case
  %}
  ins_pipe(pipe_slow);
%}

instruct callLock(method meth)%{
match(Lock);
  effect(USE meth);
  ins_cost(300);
  emit %{ 
    assert0( $meth$ == (address)SharedRuntime::monitorenter );
    // 'Lock' is treated as a function call by C2, so this whole template
    // follows standard X86 calling conventions.  In particular, RDI is always
    // the Object to lock, and RAX is always clobbered.
Label locked;
    __ call (StubRoutines::x86::c2_lock_entry());
    __ jeq  (locked); // CAS worked: self biased now
    __ call_native((address)SharedRuntime::monitorenter, RDI/*thr*/, in_bytes(JavaThread::last_Java_sp_offset()),0);
    __ add_oopmap(__ rel_pc(), _oop_map);
    add_debug_here(_oop_map);
__ bind(locked);
  %}
  ins_pipe(pipe_slow);
%}

instruct callUnlock(method meth)%{
match(Unlock);
  ins_cost(300);
  emit %{ 
    assert0( $meth$ == (address)StubRoutines::unlock_c2_entry() );
    __ ldz4(RSI,RDI,oopDesc::mark_offset_in_bytes());
    __ call(StubRoutines::unlock_c2_entry());  // unlock
  %}
  ins_pipe(pipe_slow);
%}



// ============================================================================
// This name is KNOWN by the ADLC and cannot be changed.
// The ADLC forces a 'TypeRawPtr::BOTTOM' output type
// for this guy.
instruct tlsLoadP(rRegP rThr,rFlagsReg cr)%{
match(Set rThr(ThreadLocal));
effect(DEF rThr,KILL cr);
  emit %{  __ getthr($rThr$);  %}
  ins_pipe(ialu_reg_reg);
%}

// Polling already happened in the ideal graph
instruct safePoint(rFlagsReg cr)%{
  effect(KILL cr);
  match(SafePoint);
ins_cost(500);
  emit %{
    __ call (StubRoutines::safepoint_trap_handler());  
    __ add_oopmap(__ rel_pc(), _oop_map);
    add_debug_here(_oop_map);
  %}
ins_pipe(ialu_reg_mem);
%}


 instruct fastAllocObj( rax_RegP oop, rsi_RegP kid, rdx_RegL siz, rcx_RegI len, r09_RegI r09, f15_RegD f15, rFlagsReg cr ) %{
  match( Set oop (FastAlloc kid siz) );
effect(KILL r09,KILL len,KILL f15,KILL cr);
  emit %{
    if( UseSBA ) Unimplemented();
    __ call(StubRoutines::new_fast());
  %}
  ins_pipe(pipe_slow);
%}

instruct fastAllocAry( rax_RegP oop, rsi_RegP kid, rdx_RegL siz, rcx_RegL len_ekid, r09_RegI r09, f15_RegD f15, rFlagsReg cr ) %{
  match( Set oop (FastAlloc kid (Binary siz len_ekid) ) );
effect(KILL r09,KILL f15,KILL cr);
  emit %{
    if( UseSBA ) Unimplemented();
    __ call(StubRoutines::new_fast_array());
  %}
  ins_pipe(pipe_slow);
%}


// Call allocation milli-code
instruct allocateSlowpath(rFlagsReg cr)%{
match(Allocate);
  effect( KILL cr );
  ins_cost(300);
  emit %{
    if( UseSBA ) Unimplemented();
    // RDI=thr, RSI=KID, RDX=size
    __ mov8i(R08,0);            // sba hint
    // RDI=thr, RSI=kid, RDX=size, RCX=len, R08=sba
    __ call_native((address)SharedRuntime::_new, RDI/*thr*/, in_bytes(JavaThread::last_Java_sp_offset()),0);
    __ add_oopmap(__ rel_pc(), _oop_map);
    add_debug_here(_oop_map);
  %}
  ins_pipe(pipe_slow);
%}

instruct allocateArraySlowpath(rFlagsReg cr)%{
match(AllocateArray);
  effect( KILL cr );
  ins_cost(300);
  emit %{
    if( UseSBA ) Unimplemented();
    // RDI=thr, RSI=KID, RDX=size, RCX=length+ekid
    __ mov8i(R08,0);            // sba hint
    // RDI=thr, RSI=kid, RDX=size, RCX=length+ekid, R08=sba
    __ call_native((address)SharedRuntime::_new, RDI/*thr*/, in_bytes(JavaThread::last_Java_sp_offset()),0);
    __ add_oopmap(__ rel_pc(), _oop_map);
    add_debug_here(_oop_map);
  %}
  ins_pipe(pipe_slow);
%}

// used by get_kid
instruct ld_kid(rRegP kid, rRegP src) %{
  match(Set kid (GetKID src)); // set ideal_Op
  predicate( false );
effect(DEF kid,USE src);
ins_cost(999);
  emit %{ __ ldz4 ($kid$,$src$,oopDesc::mark_offset_in_bytes()+4);  %}
  ins_pipe(ialu_reg_mem);
%}

// used by get_kid
instruct shf_kid(rRegP kid,rFlagsReg cr)%{
  match(Set kid (GetKID kid)); // set ideal_Op
  predicate( false );
  effect( KILL cr );
ins_cost(999);
  emit %{ __ shr4i($kid$,markWord::kid_shift-32); %}
  ins_pipe(ialu_reg_reg);
%}

instruct verify_kid(rRegP kid,rFlagsReg cr)%{
  match(Set kid (GetKID kid)); // set ideal_Op
  predicate( false );
  effect( KILL cr );
ins_cost(999);
  emit %{ __ verify_kid($kid$); %}
  ins_pipe(ialu_reg_reg);
%}

// Get a KID from an object.  Weirdly typed as a RegP because we retain strong
// klass type knowledge about this plain olde 32-bit int.
instruct get_kid(rRegP kid, rRegP src) %{
match(Set kid(GetKID src));
predicate(!KIDInRef);
  expand %{
    rFlagsReg cr;
    // Expand rule to let the load & shift schedule apart.
    // The load often misses.
    ld_kid(kid,src);
    shf_kid(kid,cr);
    verify_kid(kid,cr);
  %}
%}

// ============================================================================
// Procedure Call/Return Instructions
// Java Static Call
instruct callStaticJavaDirect(method meth)%{
  match(CallStaticJava);
  effect(USE meth);
  ins_cost(300);
  emit %{
    __ aligned_patchable_call($meth$);  
    __ add_oopmap(__ rel_pc(), _oop_map);
    add_debug_here(_oop_map);
  %}
  ins_pipe(pipe_slow);
%}

// Java Inline-Cache Call
instruct callDynamicJavaDirect(method meth)%{
  match(CallDynamicJava);
  effect(USE meth);
  ins_cost(300);
  emit %{
    __ ref2kid_no_npe(RAX, RDI);
    NativeInlineCache::fill( &ra_->C->_masm );  
    __ add_oopmap(__ rel_pc(), _oop_map);
    add_debug_here(_oop_map);
  %}
  ins_pipe(pipe_slow);
%}

// Call Runtime Instruction
instruct CallRuntimeDirect(method meth)%{
  match(CallRuntime);
  effect(USE meth);
  ins_cost(300);
  emit %{ 
    // Args should already be setup.  Just arrange for the stack to crawlable.
    __ call_native($meth$, RDI, in_bytes(JavaThread::last_Java_sp_offset()), 0);
    __ add_oopmap(__ rel_pc(), _oop_map);
    add_debug_here(_oop_map);
  %}
  ins_pipe(pipe_slow);
%}

// Call runtime without safepoint
instruct callLeafDirect(method meth)%{
  match(CallLeaf);
  effect(USE meth);
  ins_cost(300);
  emit %{ __ call($meth$); %}
  ins_pipe(pipe_slow);
%}

// Call runtime without safepoint, and does not blow the FP registers
instruct CallLeafNoFPDirect(method meth) %{
  match(CallLeafNoFP);
  effect(USE meth);
  ins_cost(300);
  emit %{ __ call($meth$); %}
  ins_pipe(pipe_slow);
%}

// Return Instruction
// Remove the return address & jump to it.
// Notice: We always emit a nop after a ret to make sure there is room
// for safepoint patching
instruct Ret()%{
  match(Return);
  emit %{ __ ret(); %}
  ins_pipe(pipe_jmp);
%}

// Rethrow exception:
// The exception oop will come in thread->_pending_exception.
// Then JUMP (not call) to the rethrow stub code.
instruct RethrowException()%{
  match(Rethrow);
  emit %{ __ jmp(StubRoutines::forward_exception_entry());  %}
  ins_pipe(pipe_jmp);
%}


//----------PEEPHOLE RULES-----------------------------------------------------
// These must follow all instruction definitions as they use the names
// defined in the instructions definitions.
//
// peepmatch ( root_instr_name [preceding_instruction]* );
//
// peepconstraint %{
// (instruction_number.operand_name relational_op instruction_number.operand_name
//  [, ...] );
// // instruction numbers are zero-based using left to right order in peepmatch
//
// peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
// // provide an instruction_number.operand_name for each operand that appears
// // in the replacement instruction's match rule
//
// ---------VM FLAGS---------------------------------------------------------
//
// All peephole optimizations can be turned off using -XX:-OptoPeephole
//
// Each peephole rule is given an identifying number starting with zero and
// increasing by one in the order seen by the parser.  An individual peephole
// can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
// on the command-line.
//
// ---------CURRENT LIMITATIONS----------------------------------------------
//
// Only match adjacent instructions in same basic block
// Only equality constraints
// Only constraints between operands, not (0.dest_reg == RAX_enc)
// Only one replacement instruction
//
// ---------EXAMPLE----------------------------------------------------------
//
// // pertinent parts of existing instructions in architecture description
// instruct movI(rRegI dst, rRegI src)
// %{
//   match(Set dst (CopyI src));
// %}
//
// instruct incI_rReg(rRegI dst, immI1 src, rFlagsReg cr)
// %{
//   match(Set dst (AddI dst src));
//   effect(KILL cr);
// %}
//
// // Change (inc mov) to lea
// peephole %{
//   // increment preceeded by register-register move
//   peepmatch ( incI_rReg movI );
//   // require that the destination register of the increment
//   // match the destination register of the move
//   peepconstraint ( 0.dst == 1.dst );
//   // construct a replacement instruction that sets
//   // the destination to ( move's source register + one )
//   peepreplace ( leaI_rReg_immI( 0.dst 1.src 0.src ) );
// %}
//

// Implementation no longer uses movX instructions since
// machine-independent system no longer uses CopyX nodes.
//
// peephole
// %{
//   peepmatch (incI_rReg movI);
//   peepconstraint (0.dst == 1.dst);
//   peepreplace (leaI_rReg_immI(0.dst 1.src 0.src));
// %}

// peephole
// %{
//   peepmatch (decI_rReg movI);
//   peepconstraint (0.dst == 1.dst);
//   peepreplace (leaI_rReg_immI(0.dst 1.src 0.src));
// %}

// peephole
// %{
//   peepmatch (addI_rReg_imm movI);
//   peepconstraint (0.dst == 1.dst);
//   peepreplace (leaI_rReg_immI(0.dst 1.src 0.src));
// %}

// peephole
// %{
//   peepmatch (incL_rReg movL);
//   peepconstraint (0.dst == 1.dst);
//   peepreplace (leaL_rReg_immL(0.dst 1.src 0.src));
// %}

// peephole
// %{
//   peepmatch (decL_rReg movL);
//   peepconstraint (0.dst == 1.dst);
//   peepreplace (leaL_rReg_immL(0.dst 1.src 0.src));
// %}

// peephole
// %{
//   peepmatch (addL_rReg_imm movL);
//   peepconstraint (0.dst == 1.dst);
//   peepreplace (leaL_rReg_immL(0.dst 1.src 0.src));
// %}

// peephole
// %{
//   peepmatch (addP_rReg_imm movP);
//   peepconstraint (0.dst == 1.dst);
//   peepreplace (leaP_rReg_imm(0.dst 1.src 0.src));
// %}

// // Change load of spilled value to only a spill
// instruct storeI(memory mem, rRegI src)
// %{
//   match(Set mem (StoreI mem src));
// %}
//
// instruct loadI(rRegI dst, memory mem)
// %{
//   match(Set dst (LoadI mem));
// %}
//

peephole %{
  peepmatch (loadI storeI);
  peepconstraint (1.src == 0.dst, 1.mem == 0.mem);
  peepreplace (storeI(1.mem 1.mem 1.src));
%}

peephole %{
  peepmatch (loadL storeL);
  peepconstraint (1.src == 0.dst, 1.mem == 0.mem);
  peepreplace (storeL(1.mem 1.mem 1.src));
%}

// Fast-path alloc pre-sets flags, no need for a following test.
//peephole %{
//  peepmatch( testP_reg MachProj SCMemProj MachProj fastAllocAry );
//  peepconstraint( 0.src == 4.oop );
//  peepreplace (MachProj SCMemProj MachProj fastAllocAry(4.kid 4.siz 4.len));
//%}

//peephole %{
//  peepmatch( testP_reg fastAllocObj );
//  peepconstraint( 0.src == 1.oop );
//  peepreplace (fastAllocAry(1.oop 1.kid 1.siz 1.len 1.r09));
//%}
